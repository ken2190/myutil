<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>utilmy.sspark.src package &mdash; utilmy 1.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="utilmy.sspark.src.afpgrowth package" href="utilmy.sspark.src.afpgrowth.html" />
    <link rel="prev" title="utilmy.sspark package" href="utilmy.sspark.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
            <a href="index.html" class="icon icon-home"> utilmy
          </a>
              <div class="version">
                zdocs_y23487teg65f6
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">utilmy</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="utilmy.html">utilmy package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="utilmy.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="utilmy.configs.html">utilmy.configs package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.deeplearning.html">utilmy.deeplearning package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.docs.html">utilmy.docs package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.excel.html">utilmy.excel package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.images.html">utilmy.images package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.nlp.html">utilmy.nlp package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.optim.html">utilmy.optim package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.prepro.html">utilmy.prepro package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.recsys.html">utilmy.recsys package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="utilmy.sspark.html">utilmy.sspark package</a><ul class="current">
<li class="toctree-l5 current"><a class="reference internal" href="utilmy.sspark.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l6 current"><a class="current reference internal" href="#">utilmy.sspark.src package</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l8"><a class="reference internal" href="utilmy.sspark.src.afpgrowth.html">utilmy.sspark.src.afpgrowth package</a></li>
<li class="toctree-l8"><a class="reference internal" href="utilmy.sspark.src.functions.html">utilmy.sspark.src.functions package</a></li>
<li class="toctree-l8"><a class="reference internal" href="utilmy.sspark.src.tables.html">utilmy.sspark.src.tables package</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src.util_hadoop">utilmy.sspark.src.util_hadoop module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src.util_models">utilmy.sspark.src.util_models module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src.util_spark">utilmy.sspark.src.util_spark module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src.util_sparkml">utilmy.sspark.src.util_sparkml module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#utilmy-sspark-src-util-trick-module">utilmy.sspark.src.util_trick module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src.utils">utilmy.sspark.src.utils module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.sspark.src">Module contents</a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="utilmy.sspark.tests.html">utilmy.sspark.tests package</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.sspark.html#submodules">Submodules</a></li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.sspark.html#utilmy-sspark-main-module">utilmy.sspark.main module</a></li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.sspark.html#utilmy-sspark-setup-module">utilmy.sspark.setup module</a></li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.sspark.html#module-utilmy.sspark">Module contents</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.stats.html">utilmy.stats package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tabular.html">utilmy.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.templates.html">utilmy.templates package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tools.html">utilmy.tools package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tseries.html">utilmy.tseries package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.viz.html">utilmy.viz package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.webscraper.html">utilmy.webscraper package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.adatasets">utilmy.adatasets module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.cli">utilmy.cli module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.data">utilmy.data module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.dates">utilmy.dates module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.debug">utilmy.debug module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.decorators">utilmy.decorators module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.distributed">utilmy.distributed module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.graph">utilmy.graph module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.iio">utilmy.iio module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.nnumpy">utilmy.nnumpy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.oos">utilmy.oos module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.parallel">utilmy.parallel module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.ppandas">utilmy.ppandas module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.ppolars">utilmy.ppolars module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_batch">utilmy.util_batch module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_colab">utilmy.util_colab module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_conda">utilmy.util_conda module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#utilmy-util-cpu-module">utilmy.util_cpu module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_download">utilmy.util_download module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_zip">utilmy.util_zip module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.utilmy">utilmy.utilmy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.utils">utilmy.utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.z_test">utilmy.z_test module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.zdocstring">utilmy.zdocstring module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">utilmy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">utilmy</a> &raquo;</li>
          <li><a href="utilmy.html">utilmy package</a> &raquo;</li>
          <li><a href="utilmy.sspark.html">utilmy.sspark package</a> &raquo;</li>
      <li>utilmy.sspark.src package</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/maltfield/rtd-github-pages/blob/master/docs/utilmy.sspark.src.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="utilmy-sspark-src-package">
<h1>utilmy.sspark.src package<a class="headerlink" href="#utilmy-sspark-src-package" title="Permalink to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="utilmy.sspark.src.afpgrowth.html">utilmy.sspark.src.afpgrowth package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.afpgrowth.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.afpgrowth.html#module-utilmy.sspark.src.afpgrowth.main">utilmy.sspark.src.afpgrowth.main module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.afpgrowth.html#module-utilmy.sspark.src.afpgrowth">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utilmy.sspark.src.functions.html">utilmy.sspark.src.functions package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.functions.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html">utilmy.sspark.src.functions.pandas_udfs package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#utilmy-sspark-src-functions-pandas-udfs-datetime-udfs-module">utilmy.sspark.src.functions.pandas_udfs.datetime_udfs module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#module-utilmy.sspark.src.functions.pandas_udfs.datetime_udfs_base_functions">utilmy.sspark.src.functions.pandas_udfs.datetime_udfs_base_functions module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#utilmy-sspark-src-functions-pandas-udfs-general-udfs-module">utilmy.sspark.src.functions.pandas_udfs.general_udfs module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#module-utilmy.sspark.src.functions.pandas_udfs.general_udfs_base_functions">utilmy.sspark.src.functions.pandas_udfs.general_udfs_base_functions module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#utilmy-sspark-src-functions-pandas-udfs-general-udfs-base-functions-test-module">utilmy.sspark.src.functions.pandas_udfs.general_udfs_base_functions_test module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#utilmy-sspark-src-functions-pandas-udfs-timeseries-module">utilmy.sspark.src.functions.pandas_udfs.timeseries module</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.pandas_udfs.html#module-contents">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.sspark.src.functions.spark_udfs.html">utilmy.sspark.src.functions.spark_udfs package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.src.functions.spark_udfs.html#module-contents">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.functions.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.functions.html#utilmy-sspark-src-functions-getfamiliesfromuseragent-module">utilmy.sspark.src.functions.GetFamiliesFromUserAgent module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.functions.html#utilmy-sspark-src-functions-dim-datetime-utilities-module">utilmy.sspark.src.functions.dim_datetime_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.functions.html#module-utilmy.sspark.src.functions">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utilmy.sspark.src.tables.html">utilmy.sspark.src.tables package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-predict-session-length-module">utilmy.sspark.src.tables.table_predict_session_length module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-predict-url-unique-module">utilmy.sspark.src.tables.table_predict_url_unique module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-predict-volume-module">utilmy.sspark.src.tables.table_predict_volume module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-user-log-module">utilmy.sspark.src.tables.table_user_log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-user-session-log-module">utilmy.sspark.src.tables.table_user_session_log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#utilmy-sspark-src-tables-table-user-session-stats-module">utilmy.sspark.src.tables.table_user_session_stats module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.sspark.src.tables.html#module-utilmy.sspark.src.tables">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-utilmy.sspark.src.util_hadoop">
<span id="utilmy-sspark-src-util-hadoop-module"></span><h2>utilmy.sspark.src.util_hadoop module<a class="headerlink" href="#module-utilmy.sspark.src.util_hadoop" title="Permalink to this heading"></a></h2>
<p>Hadoop, hive related.
Doc:</p>
<blockquote>
<div><p>sspark  spark_config_check</p>
<p>HDFS command
cat: Copies source paths to stdout.
Usage: hdfs dfs -cat URI [URI ?]</p>
<dl class="simple">
<dt>Example:</dt><dd><p>hdfs dfs -cat hdfs://&lt;path&gt;/file1
hdfs dfs -cat file:///file2 /user/hadoop/file3</p>
</dd>
</dl>
<p>chgrp: Changes the group association of files. With -R, makes the change recursively by way of the directory structure. The user must be the file owner or the superuser.
Usage: hdfs dfs -chgrp [-R] GROUP URI [URI ?]</p>
<p>chmod: Changes the permissions of files. With -R, makes the change recursively by way of the directory structure. The user must be the file owner or the superuser
Usage: hdfs dfs -chmod [-R] &lt;MODE[,MODE]? | OCTALMODE&gt; URI [URI ?]
Example: hdfs dfs -chmod 777 test/data1.txt</p>
<p>chown: Changes the owner of files. With -R, makes the change recursively by way of the directory structure. The user must be the superuser.
Usage: hdfs dfs -chown [-R] [OWNER][:[GROUP]] URI [URI ]
Example: hdfs dfs -chown -R hduser2 /opt/hadoop/logs</p>
<p>copyFromLocal: Works similarly to the put command, except that the source is restricted to a local file reference.
Usage: hdfs dfs -copyFromLocal &lt;localsrc&gt; URI
Example: hdfs dfs -copyFromLocal input/docs/data2.txt hdfs://localhost/user/rosemary/data2.txt</p>
<p>copyToLocal: Works similarly to the get command, except that the destination is restricted to a local file reference.
Usage: hdfs dfs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;
Example: hdfs dfs -copyToLocal data2.txt data2.copy.txt</p>
<p>count: Counts the number of directories, files, and bytes under the paths that match the specified file pattern.
Usage: hdfs dfs -count [-q] &lt;paths&gt;
Example: hdfs dfs -count hdfs://nn1.example.com/file1 hdfs://nn2.example.com/file2</p>
<p>cp: Copies one or more files from a specified source to a specified destination. If you specify multiple sources, the specified destination must be a directory.
Usage: hdfs dfs -cp URI [URI ?] &lt;dest&gt;
Example: hdfs dfs -cp /user/hadoop/file1 /user/hadoop/file2 /user/hadoop/dir</p>
<p>du: Displays the size of the specified file, or the sizes of files and directories that are contained in the specified directory. If you specify the -s option, displays an aggregate summary of file sizes rather than individual file sizes. If you specify the -h option, formats the file sizes in a �ghuman-readable�h way.
Usage: hdfs dfs -du [-s] [-h] URI [URI ?]
Example: hdfs dfs -du /user/hadoop/dir1 /user/hadoop/file1</p>
<p>dus: Displays a summary of file sizes; equivalent to hdfs dfs -du ?s.
Usage: hdfs dfs -dus &lt;args&gt;</p>
<p>expunge: Empties the trash. When you delete a file, it isn�ft removed immediately from HDFS, but is renamed to a file in the /trash directory. As long as the file remains there, you can undelete it if you change your mind, though only the latest copy of the deleted file can be restored.
Usage: hdfs dfs ?expunge</p>
<p>get: Copies files to the local file system. Files that fail a cyclic redundancy check (CRC) can still be copied if you specify the ?ignorecrc option. The CRC is a common technique for detecting data transmission errors. CRC checksum files have the .crc extension and are used to verify the data integrity of another file. These files are copied if you specify the -crc option.
Usage: hdfs dfs -get [-ignorecrc] [-crc] &lt;src&gt; &lt;localdst&gt;
Example: hdfs dfs -get /user/hadoop/file3 localfile</p>
<p>getmerge: Concatenates the files in src and writes the result to the specified local destination file. To add a newline character at the end of each file, specify the addnl option.
Usage: hdfs dfs -getmerge &lt;src&gt; &lt;localdst&gt; [addnl]
Example: hdfs dfs -getmerge /user/hadoop/mydir/ ~/result_file addnl</p>
<p>ls: Returns statistics for the specified files or directories.
Usage: hdfs dfs -ls &lt;args&gt;
Example: hdfs dfs -ls /user/hadoop/file1</p>
<p>lsr: Serves as the recursive version of ls; similar to the Unix command ls -R.
Usage: hdfs dfs -lsr &lt;args&gt;
Example: hdfs dfs -lsr /user/hadoop</p>
<p>mkdir: Creates directories on one or more specified paths. Its behavior is similar to the Unix mkdir -p command, which creates all directories that lead up to the specified directory if they don�ft exist already.
Usage: hdfs dfs -mkdir &lt;paths&gt;
Example: hdfs dfs -mkdir /user/hadoop/dir5/temp</p>
<p>moveFromLocal: Works similarly to the put command, except that the source is deleted after it is copied.
Usage: hdfs dfs -moveFromLocal &lt;localsrc&gt; &lt;dest&gt;
Example: hdfs dfs -moveFromLocal localfile1 localfile2 /user/hadoop/hadoopdir</p>
<p>mv: Moves one or more files from a specified source to a specified destination. If you specify multiple sources, the specified destination must be a directory. Moving files across file systems isn�ft permitted.
Usage: hdfs dfs -mv URI [URI ?] &lt;dest&gt;
Example: hdfs dfs -mv /user/hadoop/file1 /user/hadoop/file2</p>
<p>put: Copies files from the local file system to the destination file system. This command can also read input from stdin and write to the destination file system.
Usage: hdfs dfs -put &lt;localsrc&gt; ? &lt;dest&gt;
Example: hdfs dfs -put localfile1 localfile2 /user/hadoop/hadoopdir; hdfs dfs -put ? /user/hadoop/hadoopdir (reads input from stdin)</p>
<p>rm: Deletes one or more specified files. This command doesn�ft delete empty directories or files. To bypass the trash (if it�fs enabled) and delete the specified files immediately, specify the -skipTrash option.
Usage: hdfs dfs -rm [-skipTrash] URI [URI ?]
Example: hdfs dfs -rm hdfs://nn.example.com/file9</p>
<p>rmr: Serves as the recursive version of ?rm.
Usage: hdfs dfs -rmr [-skipTrash] URI [URI ?]
Example: hdfs dfs -rmr /user/hadoop/dir</p>
<p>setrep: Changes the replication factor for a specified file or directory. With ?R, makes the change recursively by way of the directory structure.
Usage: hdfs dfs -setrep &lt;rep&gt; [-R] &lt;path&gt;</p>
<p>Example: hdfs dfs -setrep 3 -R /user/hadoop/dir1
stat: Displays information about the specified path.</p>
<p>Usage: hdfs dfs -stat URI [URI ?]
Example: hdfs dfs -stat /user/hadoop/dir1
tail: Displays the last kilobyte of a specified file to stdout. The syntax supports the Unix -f option, which enables the specified file to be monitored. As new lines are added to the file by another process, tail updates the display.</p>
<p>Usage: hdfs dfs -tail [-f] URI
Example: hdfs dfs -tail /user/hadoop/dir1</p>
<p>test: Returns attributes of the specified file or directory. Specifies ?e to determine whether the file or directory exists; -z to determine whether the file or directory is empty; and -d to determine whether the URI is a directory.
Usage: hdfs dfs -test -[ezd] URI
Example: hdfs dfs -test /user/hadoop/dir1</p>
<p>text: Outputs a specified source file in text format. Valid input file formats are zip and TextRecordInputStream.
Usage: hdfs dfs -text &lt;src&gt;
Example: hdfs dfs -text /user/hadoop/file8.zip</p>
<p>touchz: Creates a new, empty file of size 0 in the specified path.
Usage: hdfs dfs -touchz &lt;path&gt;
Example: hdfs dfs -touchz /user/hadoop/file12</p>
</div></blockquote>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.date_format">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">date_format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datestr</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'%Y%m%d'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_days</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_hours</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timezone</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Asia/Tokyo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'%Y-%m-%d'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">returnval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'str,int,datetime'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.date_format" title="Permalink to this definition"></a></dt>
<dd><p>One liner for date Formatter
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">datestr</span><span class="p">:</span> <span class="mi">2012</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">12</span>  <span class="ow">or</span> <span class="s2">&quot;&quot;</span>  <span class="n">emptry</span> <span class="n">string</span> <span class="k">for</span> <span class="n">today</span><span class="s1">&#39;s date.</span>
<span class="n">fmt</span><span class="p">:</span>     <span class="n">output</span> <span class="nb">format</span> <span class="c1"># &quot;%Y-%m-%d %H:%M:%S %Z%z&quot;</span>

<span class="n">date_format</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="s2">&quot;20200519&quot;</span>
<span class="n">date_format</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="s2">&quot;2020-05-19&quot;</span>
<span class="n">date_format</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">add_days</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">returnval</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="mi">20200518</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hadoop_print_config">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hadoop_print_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hadoop_print_config" title="Permalink to this definition"></a></dt>
<dd><p>Print configuration variable for Hadoop, Spark</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_copy_fromlocal">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_copy_fromlocal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hdfs_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_copy_fromlocal" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_copy_tolocal">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_copy_tolocal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hdfs_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">local_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_copy_tolocal" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_dir_exists">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_dir_exists</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_dir_exists" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_dir_info">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_dir_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_dir_info" title="Permalink to this definition"></a></dt>
<dd><p>HDFS DIR : {“last_modified”:last_modified,”format”:format1 ‘size’}</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_dir_list">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_dir_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recursive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_dir_list" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_dir_rm">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_dir_rm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_dir_rm" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_dir_stats">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_dir_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_dir_stats" title="Permalink to this definition"></a></dt>
<dd><p>HDFS DIR : {“last_modified”:last_modified,”format”:format1 ‘size’}</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_download">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_download</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_download" title="Permalink to this definition"></a></dt>
<dd><p>Donwload files in parallel using pyarrow
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">path_glob</span><span class="p">:</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">HDFS</span> <span class="n">pattern</span><span class="p">,</span> <span class="ow">or</span> <span class="n">sep</span> <span class="n">by</span> <span class="s2">&quot;;&quot;</span>
<span class="p">:</span><span class="k">return</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_file_exists">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_file_exists</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_file_exists" title="Permalink to this definition"></a></dt>
<dd><p>Return True when indicated file exists on HDFS.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_help">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_help</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_help" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_ls">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_ls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_ls" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_mkdir">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_mkdir</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hdfs_dir</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_mkdir" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_pd_read_csv">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_pd_read_csv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirlist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirlevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concat_sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_duplicates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gzip'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">','</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">header</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_bad_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'skip'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_pd_read_csv" title="Permalink to this definition"></a></dt>
<dd><p>Read file in parallel from HDFS using pyarrow
Docs:</p>
<blockquote>
<div><p>Require: export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath –glob`</p>
<p>dirin = “hdfs:///mypat/”
df = pd_read_csv_hdfs(dirlist=dirin, nfile=5000, n_pool=8, dirlevel=1, ignore_index=True,  cols=None, verbose=False, nrows=-1, ,</p>
<blockquote>
<div><p>drop_duplicates=None, col_filter=None,  col_filter_val=None, dtype=None)</p>
</div></blockquote>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_pd_read_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_pd_read_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirlist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concat_sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_duplicates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_pd_read_parquet" title="Permalink to this definition"></a></dt>
<dd><p>Read file in parallel from HDFS : very Fast
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Require: export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`

dirin = &quot;hdfs:///mypat/myparquet/&quot;
df = pd_read_csv_hdfs(dirlist=dirin, nfile=5000, n_pool=8, dirlevel=1, ignore_index=True,  cols=None, verbose=False, nrows=-1, concat_sort=True,
        drop_duplicates=None, col_filter=None,  col_filter_val=None, dtype=None)
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hdfs_pd_write_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hdfs_pd_write_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hdfs_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hdfs:///user/pppp/clean_v01.parquet/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_rows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hdfs_pd_write_parquet" title="Permalink to this definition"></a></dt>
<dd><p>Pandas to HDFS
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pyarrow</span><span class="o">.</span><span class="n">parquet</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">row_group_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span> <span class="n">use_dictionary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;snappy&#39;</span><span class="p">,</span> <span class="n">write_statistics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_deprecated_int96_timestamps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coerce_timestamps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_truncated_timestamps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">data_page_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">flavor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">filesystem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compression_level</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_byte_stream_split</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">data_page_version</span><span class="o">=</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arrow</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">generated</span><span class="o">/</span><span class="n">pyarrow</span><span class="o">.</span><span class="n">parquet</span><span class="o">.</span><span class="n">write_to_dataset</span><span class="o">.</span><span class="n">html</span><span class="c1">#pyarrow.parquet.write_to_dataset</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_csv_tohive">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_csv_tohive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tablename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ztmp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tableref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nono2.table2'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_csv_tohive" title="Permalink to this definition"></a></dt>
<dd><p>Local CSV to Hive table</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_df_tohive">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_df_tohive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tableref</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nono2.table2'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_df_tohive" title="Permalink to this definition"></a></dt>
<dd><p>Export Dataframe to Hive table</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_exec">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_exec</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nohup</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dry</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_exception</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_exec" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_get_partitions">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_get_partitions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">user</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'myuser_hadoop'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mydb.mytable'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'myexport/'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_get_partitions" title="Permalink to this definition"></a></dt>
<dd><p>Export Hive partition names on disk
get_partitions</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_run">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logdir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ztmp/loghive/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'v01'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dry</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nohup</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">explain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_run" title="Permalink to this definition"></a></dt>
<dd><p>HIVE SQL RUN
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">Box</span><span class="p">(</span><span class="n">ConfigReader</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
<span class="n">logdir</span>   <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">log_hive</span>
<span class="n">start_dt</span> <span class="o">=</span> <span class="n">date_now</span><span class="p">(</span><span class="s1">&#39;now&#39;</span><span class="p">,</span> <span class="n">add_days</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">start_dt</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">7</span> <span class="k">else</span> <span class="n">start_dt</span>
<span class="n">end_dt</span>   <span class="o">=</span> <span class="n">date_now</span><span class="p">(</span><span class="s1">&#39;now&#39;</span><span class="p">,</span> <span class="n">add_days</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>    <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">end_dt</span><span class="p">)</span>   <span class="o">&lt;</span> <span class="mi">7</span> <span class="k">else</span> <span class="n">end_dt</span>

<span class="n">cv_start_dt</span> <span class="o">=</span> <span class="n">date_now</span><span class="p">(</span><span class="s1">&#39;now&#39;</span><span class="p">,</span> <span class="n">add_days</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">120</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="n">qq</span> <span class="o">=</span> <span class="n">os_file_read</span><span class="p">(</span><span class="s1">&#39;queries/myhive.sql&#39;</span><span class="p">)</span>
<span class="n">qq</span> <span class="o">=</span> <span class="n">qq</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start_dt</span><span class="o">=</span><span class="n">start_dt</span><span class="p">,</span> <span class="n">end_dt</span><span class="o">=</span><span class="n">end_dt</span><span class="p">,</span>  <span class="p">)</span>
<span class="n">hive_run</span><span class="p">(</span><span class="n">qq</span><span class="p">,</span> <span class="n">dry</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span> <span class="n">logdir</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_schema">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_schema" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_sql_todf">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_sql_todf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sql</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">header_hive_sql</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_sql_todf" title="Permalink to this definition"></a></dt>
<dd><p>Load SQL Query result to pandas dataframe</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hive_update_partitions_table">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hive_update_partitions_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table_name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hive_update_partitions_table" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hivemall_getdefinition">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hivemall_getdefinition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./define-all.hive'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hivemall_getdefinition" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.hivemall_getsqlheader">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">hivemall_getsqlheader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dir_hivemall_jar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/mypath/hivemall/hivemall-all-0.6.0.jar'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir_hivemall_conf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/mypath/define-all.hive</span> <span class="pre">'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.hivemall_getsqlheader" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.log">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.log" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.os_makedirs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">os_makedirs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.os_makedirs" title="Permalink to this definition"></a></dt>
<dd><p>function os_makedirs in HDFS or local</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.os_rename_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">os_rename_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dir0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.os_rename_parquet" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.os_subprocess">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">os_subprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stdout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stderr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.os_subprocess" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.os_system">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">os_system</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cmd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.os_system" title="Permalink to this definition"></a></dt>
<dd><p>os.system  and retrurn stdout, stderr values</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.parquet_to_hive_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">parquet_to_hive_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.parquet_to_hive_parquet" title="Permalink to this definition"></a></dt>
<dd><p>Need Pyarrow 3.0 to make it work.
hive 1.2</p>
<p>CREATE EXTERNAL TABLE n=st (
siid   ,
)
STORED AS PARQUET TBLPROPERTIES (“parquet.compression”=”SNAPPY”)   ;</p>
<p>hadoop dfs -put  /a/adigd_ranid_v15_140m_fast.parquet   /usload/</p>
<p>hive -e “LOAD DATA LOCAL INPATH   ‘/us40m_fast.parquet’  OVERWRITE INTO TABLE  n  ;”</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.parquet_to_hive_parquet2">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">parquet_to_hive_parquet2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/ztmp_hive_parquet/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.parquet_to_hive_parquet2" title="Permalink to this definition"></a></dt>
<dd><p>Hive parquet needs special headers  NEED PYARROW 3.0  for Hive compatibility
Bug in fastparquet, cannot save float, int.,</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.pd_read_csv_hdfs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">pd_read_csv_hdfs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirlist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirlevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concat_sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_duplicates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gzip'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">','</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">header</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_bad_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'skip'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.pd_read_csv_hdfs" title="Permalink to this definition"></a></dt>
<dd><p>Read file in parallel from HDFS using pyarrow
Docs:</p>
<blockquote>
<div><p>Require: export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath –glob`</p>
<p>dirin = “hdfs:///mypat/”
df = pd_read_csv_hdfs(dirlist=dirin, nfile=5000, n_pool=8, dirlevel=1, ignore_index=True,  cols=None, verbose=False, nrows=-1, ,</p>
<blockquote>
<div><p>drop_duplicates=None, col_filter=None,  col_filter_val=None, dtype=None)</p>
</div></blockquote>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.pd_read_json_hdfs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">pd_read_json_hdfs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirlist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concat_sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_duplicates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compression</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gzip'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'utf-8'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_bad_lines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'skip'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirlevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.pd_read_json_hdfs" title="Permalink to this definition"></a></dt>
<dd><p>Read file in parallel from HDFS : very Fast using pyarrwo
Docs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">:</span><span class="n">param</span> <span class="n">dir_list</span><span class="p">:</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">pattern</span><span class="p">,</span> <span class="ow">or</span> <span class="n">sep</span> <span class="n">by</span> <span class="s2">&quot;;&quot;</span>
<span class="p">:</span><span class="k">return</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.pd_read_parquet_hdfs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">pd_read_parquet_hdfs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirlist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">concat_sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_pool</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_duplicates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_filter_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.pd_read_parquet_hdfs" title="Permalink to this definition"></a></dt>
<dd><p>Read file in parallel from HDFS : very Fast
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Require: export CLASSPATH=`$HADOOP_HOME/bin/hdfs classpath --glob`

dirin = &quot;hdfs:///mypat/myparquet/&quot;
df = pd_read_csv_hdfs(dirlist=dirin, nfile=5000, n_pool=8, dirlevel=1, ignore_index=True,  cols=None, verbose=False, nrows=-1, concat_sort=True,
        drop_duplicates=None, col_filter=None,  col_filter_val=None, dtype=None)
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.pd_read_parquet_schema">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">pd_read_parquet_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">uri</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.pd_read_parquet_schema" title="Permalink to this definition"></a></dt>
<dd><p>Return a Pandas dataframe corresponding to the schema of a local URI of a parquet file.</p>
<p>The returned dataframe has the columns: column, pa_dtype</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.pd_write_parquet_hdfs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">pd_write_parquet_hdfs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hdfs_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hdfs:///user/pppp/clean_v01.parquet/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_rows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">partition_cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.pd_write_parquet_hdfs" title="Permalink to this definition"></a></dt>
<dd><p>Pandas to HDFS
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pyarrow</span><span class="o">.</span><span class="n">parquet</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">where</span><span class="p">,</span> <span class="n">row_group_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span> <span class="n">use_dictionary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;snappy&#39;</span><span class="p">,</span> <span class="n">write_statistics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_deprecated_int96_timestamps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">coerce_timestamps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">allow_truncated_timestamps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">data_page_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">flavor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">filesystem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compression_level</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_byte_stream_split</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">data_page_version</span><span class="o">=</span><span class="s1">&#39;1.0&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arrow</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">generated</span><span class="o">/</span><span class="n">pyarrow</span><span class="o">.</span><span class="n">parquet</span><span class="o">.</span><span class="n">write_to_dataset</span><span class="o">.</span><span class="n">html</span><span class="c1">#pyarrow.parquet.write_to_dataset</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.query_clean">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">query_clean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">q</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.query_clean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.query_clean_quote">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">query_clean_quote</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.query_clean_quote" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_hadoop.to_file">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_hadoop.</span></span><span class="sig-name descname"><span class="pre">to_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">txt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'a'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_hadoop.to_file" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-utilmy.sspark.src.util_models">
<span id="utilmy-sspark-src-util-models-module"></span><h2>utilmy.sspark.src.util_models module<a class="headerlink" href="#module-utilmy.sspark.src.util_models" title="Permalink to this heading"></a></h2>
<ol class="arabic simple" start="6">
<li><p>Predict the session length for a given IP</p></li>
</ol>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.ExtractFeatureImp">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">ExtractFeatureImp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">featureImp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">featuresCol</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.ExtractFeatureImp" title="Permalink to this definition"></a></dt>
<dd><p>Takes in a feature importance from a random forest / GBT model and map it to the column names
Output as a pandas dataframe for easy reading</p>
<p>rf = RandomForestClassifier(featuresCol=”features”)
mod = rf.fit(train)
ExtractFeatureImp(mod.featureImportances, train, “features”)</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">FeatureImpSelector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">selectorType</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'numTopFeatures'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numTopFeatures</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputCol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'features'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Estimator</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">HasOutputCol</span></code></p>
<p>Uses feature importance score to select features for training
Takes either the top n features or those above a certain threshold score
estimator should either be a DecisionTreeClassifier, RandomForestClassifier or GBTClassifier
featuresCol is inferred from the estimator</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.estimator">
<span class="sig-name descname"><span class="pre">estimator</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Param(parent='undefined',</span> <span class="pre">name='estimator',</span> <span class="pre">doc='estimator</span> <span class="pre">to</span> <span class="pre">be</span> <span class="pre">cross-validated')</span></em><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.estimator" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.getEstimator">
<span class="sig-name descname"><span class="pre">getEstimator</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.getEstimator" title="Permalink to this definition"></a></dt>
<dd><p>Gets the value of estimator or its default value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.getNumTopFeatures">
<span class="sig-name descname"><span class="pre">getNumTopFeatures</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.getNumTopFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Gets the value of numTopFeatures or its default value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.getSelectorType">
<span class="sig-name descname"><span class="pre">getSelectorType</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.getSelectorType" title="Permalink to this definition"></a></dt>
<dd><p>Gets the value of selectorType or its default value.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.getThreshold">
<span class="sig-name descname"><span class="pre">getThreshold</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.getThreshold" title="Permalink to this definition"></a></dt>
<dd><p>Gets the value of threshold or its default value.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.numTopFeatures">
<span class="sig-name descname"><span class="pre">numTopFeatures</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Param(parent='undefined',</span> <span class="pre">name='numTopFeatures',</span> <span class="pre">doc='Number</span> <span class="pre">of</span> <span class="pre">features</span> <span class="pre">that</span> <span class="pre">selector</span> <span class="pre">will</span> <span class="pre">select,</span> <span class="pre">ordered</span> <span class="pre">by</span> <span class="pre">descending</span> <span class="pre">feature</span> <span class="pre">imp</span> <span class="pre">score.</span> <span class="pre">If</span> <span class="pre">the</span> <span class="pre">number</span> <span class="pre">of</span> <span class="pre">features</span> <span class="pre">is</span> <span class="pre">&lt;</span> <span class="pre">numTopFeatures,</span> <span class="pre">then</span> <span class="pre">this</span> <span class="pre">will</span> <span class="pre">select</span> <span class="pre">all</span> <span class="pre">features.')</span></em><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.numTopFeatures" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.selectorType">
<span class="sig-name descname"><span class="pre">selectorType</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Param(parent='undefined',</span> <span class="pre">name='selectorType',</span> <span class="pre">doc='The</span> <span class="pre">selector</span> <span class="pre">type</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">FeatureImpSelector.</span> <span class="pre">Supported</span> <span class="pre">options:</span> <span class="pre">numTopFeatures</span> <span class="pre">(default),</span> <span class="pre">threshold')</span></em><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.selectorType" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.setEstimator">
<span class="sig-name descname"><span class="pre">setEstimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.setEstimator" title="Permalink to this definition"></a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#utilmy.sspark.src.util_models.FeatureImpSelector.estimator" title="utilmy.sspark.src.util_models.FeatureImpSelector.estimator"><code class="xref py py-attr docutils literal notranslate"><span class="pre">estimator</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.setNumTopFeatures">
<span class="sig-name descname"><span class="pre">setNumTopFeatures</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.setNumTopFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#utilmy.sspark.src.util_models.FeatureImpSelector.numTopFeatures" title="utilmy.sspark.src.util_models.FeatureImpSelector.numTopFeatures"><code class="xref py py-attr docutils literal notranslate"><span class="pre">numTopFeatures</span></code></a>.
Only applicable when selectorType = “numTopFeatures”.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.setParams">
<span class="sig-name descname"><span class="pre">setParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">selectorType</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'numTopFeatures'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numTopFeatures</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputCol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'features'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.setParams" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>setParams(self, estimator = None, selectorType = “numTopFeatures”,</dt><dd><p>numTopFeatures = 20, threshold = 0.01, outputCol = “features”)</p>
</dd>
</dl>
<p>Sets params for this ChiSqSelector.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.setSelectorType">
<span class="sig-name descname"><span class="pre">setSelectorType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.setSelectorType" title="Permalink to this definition"></a></dt>
<dd><p>Sets the value of <a class="reference internal" href="#utilmy.sspark.src.util_models.FeatureImpSelector.selectorType" title="utilmy.sspark.src.util_models.FeatureImpSelector.selectorType"><code class="xref py py-attr docutils literal notranslate"><span class="pre">selectorType</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.setThreshold">
<span class="sig-name descname"><span class="pre">setThreshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.setThreshold" title="Permalink to this definition"></a></dt>
<dd><p>Sets the value of <code class="xref py py-attr docutils literal notranslate"><span class="pre">Threshold</span></code>.
Only applicable when selectorType = “threshold”.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.FeatureImpSelector.threshold">
<span class="sig-name descname"><span class="pre">threshold</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">Param(parent='undefined',</span> <span class="pre">name='threshold',</span> <span class="pre">doc='The</span> <span class="pre">lowest</span> <span class="pre">feature</span> <span class="pre">imp</span> <span class="pre">score</span> <span class="pre">for</span> <span class="pre">features</span> <span class="pre">to</span> <span class="pre">be</span> <span class="pre">kept.')</span></em><a class="headerlink" href="#utilmy.sspark.src.util_models.FeatureImpSelector.threshold" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.Predict">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">Predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.Predict" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># this performs model training</span>
<span class="c1"># this calls the machine-learning algorithms of Spark ML library</span>
<span class="c1"># creating labels for machine-learning</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">spark</span><span class="p">:</span>  <span class="n">SparkSession</span>
    <span class="n">df</span><span class="p">:</span>  <span class="n">Spark</span> <span class="n">Dataframe</span> <span class="n">Vector</span> <span class="n">Assembler</span>
    <span class="n">features</span><span class="p">:</span> <span class="n">column</span> <span class="n">features</span>
    <span class="n">regressor</span><span class="p">:</span>  <span class="n">model</span> <span class="n">name</span>
    <span class="n">path</span><span class="p">:</span>  <span class="n">model</span> <span class="n">path</span>
    <span class="n">conf_model</span><span class="p">:</span>  <span class="n">conf</span> <span class="ow">in</span> <span class="nb">dict</span><span class="o">.</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.TimeSeriesSplit">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">TimeSeriesSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splitRatio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparksession</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.TimeSeriesSplit" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Splitting data into train and test</span>
<span class="c1"># we maintain the time-order while splitting</span>
<span class="c1"># if split ratio = 0.7 then first 70% of data is train data</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">df_m</span><span class="p">:</span>
    <span class="n">splitRatio</span><span class="p">:</span>
    <span class="n">sparksession</span><span class="p">:</span>

<span class="n">Returns</span><span class="p">:</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.Train">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">Train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.Train" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># this performs model training</span>
<span class="c1"># this calls the machine-learning algorithms of Spark ML library</span>
<span class="c1"># creating labels for machine-learning</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">spark</span><span class="p">:</span> <span class="n">Sparksession</span>
    <span class="n">df_m</span><span class="p">:</span> <span class="n">Spark</span> <span class="n">Dataframe</span> <span class="n">Vector</span> <span class="n">Assembler</span>
    <span class="n">features</span><span class="p">:</span>  <span class="n">column</span> <span class="n">names</span>
    <span class="n">regressor</span><span class="p">:</span>  <span class="n">model</span> <span class="n">name</span>
    <span class="n">path</span><span class="p">:</span>  <span class="n">model</span> <span class="n">to</span> <span class="n">save</span>
    <span class="n">conf_model</span><span class="p">:</span>  <span class="n">config</span> <span class="ow">in</span> <span class="nb">dict</span>

<span class="n">Returns</span><span class="p">:</span> <span class="n">training</span> <span class="n">resuls</span> <span class="n">split</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.log">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.log" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_models.os_makedirs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_models.</span></span><span class="sig-name descname"><span class="pre">os_makedirs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_models.os_makedirs" title="Permalink to this definition"></a></dt>
<dd><p>function os_makedirs.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">path</span> <span class="p">(</span> <span class="nb">str</span> <span class="p">)</span> <span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="module-utilmy.sspark.src.util_spark">
<span id="utilmy-sspark-src-util-spark-module"></span><h2>utilmy.sspark.src.util_spark module<a class="headerlink" href="#module-utilmy.sspark.src.util_spark" title="Permalink to this heading"></a></h2>
<p>Spark Utils
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">utilmy</span>
<span class="n">OR</span> <span class="n">git</span> <span class="n">clone</span> <span class="o">...</span>    <span class="o">&amp;&amp;</span> <span class="n">cd</span> <span class="n">myutil</span> <span class="o">&amp;&amp;</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>   <span class="c1">### Dev mode</span>

<span class="c1">####  CLI Access</span>
<span class="n">sspark</span> <span class="n">h</span>
<span class="n">sspark</span> <span class="n">spark_config_check</span>


<span class="c1">#### In Python Code</span>
<span class="kn">from</span> <span class="nn">utilmy.sspark.src.util_spark</span> <span class="kn">import</span>   <span class="n">spark_config_check</span>

<span class="c1">### Require</span>
   <span class="n">pyspark</span>
   <span class="n">conda</span>  <span class="n">install</span> <span class="n">libhdfs3</span> <span class="n">pyarrow</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">stackoverflow</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">questions</span><span class="o">/</span><span class="mi">53087752</span><span class="o">/</span><span class="n">unable</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">load</span><span class="o">-</span><span class="n">libhdfs</span><span class="o">-</span><span class="n">when</span><span class="o">-</span><span class="n">using</span><span class="o">-</span><span class="n">pyarrow</span>



<span class="n">utilmy</span><span class="o">/</span><span class="n">sspark</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">util_spark</span><span class="o">.</span><span class="n">py</span>
<span class="o">-------------------------</span><span class="n">functions</span><span class="o">----------------------</span>
<span class="n">analyze_parquet</span><span class="p">(</span><span class="n">dirin</span><span class="p">,</span> <span class="n">dirout</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">nfiles</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">minimal</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">random_sample</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">config_parser_yaml</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">date_get_month_days</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
<span class="n">date_get_timekey</span><span class="p">(</span><span class="n">unix_ts</span><span class="p">)</span>
<span class="n">date_get_unix_day_from_datetime</span><span class="p">(</span><span class="n">dt_with_timezone</span><span class="p">)</span>
<span class="n">date_get_unix_from_datetime</span><span class="p">(</span><span class="n">dt_with_timezone</span><span class="p">)</span>
<span class="n">date_now</span><span class="p">(</span><span class="n">datenow</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">fmt</span> <span class="o">=</span> <span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">add_days</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">add_hours</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">timezone</span> <span class="o">=</span> <span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">,</span> <span class="n">fmt_input</span> <span class="o">=</span> <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">force_dayofmonth</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="c1">###  01 first of monthforce_dayofweek = -1, force_hourofday = -1, returnval = &#39;str,int,datetime/unix&#39;)</span>
<span class="n">hdfs_dir_stats</span><span class="p">(</span><span class="n">dirin</span><span class="p">,</span> <span class="n">recursive</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">hive_check_table</span><span class="p">(</span><span class="n">tables</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">add_jar_cmd</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">hive_db_dumpall</span><span class="p">()</span>
<span class="n">hive_get_dblist</span><span class="p">()</span>
<span class="n">hive_get_tablechema</span><span class="p">(</span><span class="n">tablename</span><span class="p">)</span>
<span class="n">hive_get_tabledetails</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
<span class="n">hive_get_tablelist</span><span class="p">(</span><span class="n">dbname</span><span class="p">)</span>
<span class="n">hive_run_sql</span><span class="p">(</span><span class="n">query_or_sqlfile</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nohup</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">end0</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">json_compress</span><span class="p">(</span><span class="n">raw_obj</span><span class="p">)</span>
<span class="n">json_decompress</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">show_parquet</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">nfiles</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nrows</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">spark_add_jar</span><span class="p">(</span><span class="n">sparksession</span><span class="p">,</span> <span class="n">hive_jar_cmd</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">spark_config_check</span><span class="p">()</span>
<span class="n">spark_config_create</span><span class="p">(</span><span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">dirout</span> <span class="o">=</span> <span class="s2">&quot;./conf_spark/&quot;</span><span class="p">)</span>
<span class="n">spark_config_print</span><span class="p">(</span><span class="n">sparksession</span><span class="p">)</span>
<span class="n">spark_df_check</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="s2">&quot;check&quot;</span><span class="p">,</span> <span class="n">conf</span><span class="p">:</span><span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dirout</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span>  <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nsample</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">save</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">returnval</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">spark_df_filter_mostrecent</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">colid</span> <span class="o">=</span> <span class="s1">&#39;userid&#39;</span><span class="p">,</span> <span class="n">col_orderby</span> <span class="o">=</span> <span class="s1">&#39;date&#39;</span><span class="p">,</span> <span class="n">decreasing</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rank</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">spark_df_sampleover</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">coltarget</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">major_label</span><span class="p">,</span> <span class="n">minor_label</span><span class="p">,</span> <span class="n">target_ratio</span><span class="p">,</span> <span class="p">)</span>
<span class="n">spark_df_sample</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">fraction</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">col_stratify</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">with_replace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">spark_df_stats_all</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">cols</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">sample_fraction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">metric_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;null&#39;</span><span class="p">,</span> <span class="s1">&#39;n5&#39;</span><span class="p">,</span> <span class="s1">&#39;n95&#39;</span> <span class="p">],</span> <span class="n">doprint</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">spark_df_stats_null</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">cols</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">sample_fraction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">doprint</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">spark_df_timeseries_split</span><span class="p">(</span><span class="n">df_m</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">splitRatio</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span> <span class="n">sparksession</span><span class="p">:</span><span class="nb">object</span><span class="p">)</span>
<span class="n">spark_df_sampleunder</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">coltarget</span><span class="p">,</span> <span class="n">major_label</span><span class="p">,</span> <span class="n">minor_label</span><span class="p">,</span> <span class="n">target_ratio</span><span class="p">,</span> <span class="p">)</span>
<span class="n">spark_df_write</span><span class="p">(</span><span class="n">df</span><span class="p">:</span><span class="n">sp_dataframe</span><span class="p">,</span> <span class="n">dirout</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span>  <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">show</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">npartitions</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span>  <span class="s2">&quot;append&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span>  <span class="s2">&quot;parquet&quot;</span><span class="p">)</span>
<span class="n">spark_get_session</span><span class="p">(</span><span class="n">config</span><span class="p">:</span><span class="nb">dict</span><span class="p">,</span> <span class="n">config_key_name</span> <span class="o">=</span> <span class="s1">&#39;spark_config&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">spark_metrics_classifier_summary</span><span class="p">(</span><span class="n">df_labels_preds</span><span class="p">)</span>
<span class="n">spark_metrics_roc_summary</span><span class="p">(</span><span class="n">labels_and_predictions_df</span><span class="p">)</span>
<span class="n">spark_read</span><span class="p">(</span><span class="n">sparksession</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dirin</span><span class="o">=</span><span class="s2">&quot;hdfs = &quot;</span><span class="n">hdfs</span><span class="p">:</span><span class="o">//</span><span class="s2">&quot;, **kw)</span>
<span class="n">spark_run_sqlfile</span><span class="p">(</span><span class="n">sparksession</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">spark_config</span><span class="p">:</span><span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">sql_path</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">map_sql_variables</span><span class="p">:</span><span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">os_file_replace</span><span class="p">(</span><span class="n">dirin</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;myfolder/**/*.sh&quot;</span><span class="p">,</span> <span class="s2">&quot;myfolder/**/*.conf&quot;</span><span class="p">,</span> <span class="p">],</span> <span class="n">textold</span> <span class="o">=</span> <span class="s1">&#39;/mypath2/&#39;</span><span class="p">,</span> <span class="n">textnew</span> <span class="o">=</span> <span class="s1">&#39;/mypath2/&#39;</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">os_subprocess</span><span class="p">(</span><span class="n">args_list</span><span class="p">,</span> <span class="n">stdout</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="n">stderr</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
<span class="n">os_system</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">doprint</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">run_cli_sspark</span><span class="p">()</span>


<span class="c1">### More docs:</span>
   <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">arita37</span><span class="o">/</span><span class="n">myutil</span><span class="o">/</span><span class="n">issues</span><span class="o">/</span><span class="mi">502</span>

<span class="c1">### Docker available:</span>
  <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">hub</span><span class="o">.</span><span class="n">docker</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">r</span><span class="o">/</span><span class="n">artia37</span><span class="o">/</span><span class="n">spark243</span><span class="o">-</span><span class="n">hdp27</span>
</pre></div>
</div>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.analyze_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">analyze_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.analyze_parquet" title="Permalink to this definition"></a></dt>
<dd><p>Make report in HTML from HDFS parquer files
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span><span class="o">-</span><span class="n">profiling</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.config_load">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">config_load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.config_load" title="Permalink to this definition"></a></dt>
<dd><p>Load Config filt yaml into a dict</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.config_parser_yaml">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">config_parser_yaml</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.config_parser_yaml" title="Permalink to this definition"></a></dt>
<dd><p>Parse string YAML
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">master</span>                       <span class="p">:</span> <span class="s1">&#39;local[1]&#39;</span>   <span class="c1"># &#39;spark://virtual:7077&#39;</span>
<span class="n">spark</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">name</span>                     <span class="p">:</span> <span class="s1">&#39;logprocess&#39;</span>
<span class="n">spark</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">maxResultSize</span>         <span class="p">:</span> <span class="s1">&#39;10g&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.date_get_month_days">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">date_get_month_days</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.date_get_month_days" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.date_get_timekey">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">date_get_timekey</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unix_ts</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.date_get_timekey" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.date_now">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">date_now</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">datenow</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">datetime</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'%Y%m%d'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_days</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_hours</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timezone</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Asia/Tokyo'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fmt_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'%Y-%m-%d'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_dayofmonth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_dayofweek</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_hourofday</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">returnval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'str,int,datetime/unix'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.date_now" title="Permalink to this definition"></a></dt>
<dd><p>One liner for date Formatter
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">datenow</span><span class="p">:</span> <span class="mi">2012</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">12</span>  <span class="ow">or</span> <span class="s2">&quot;&quot;</span>  <span class="n">emptry</span> <span class="n">string</span> <span class="k">for</span> <span class="n">today</span><span class="s1">&#39;s date.</span>
<span class="n">fmt</span><span class="p">:</span>     <span class="n">output</span> <span class="nb">format</span> <span class="c1"># &quot;%Y-%m-%d %H:%M:%S %Z%z&quot;</span>

<span class="n">date_now</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="s2">&quot;20200519&quot;</span>   <span class="c1">## Today date in YYYMMDD</span>
<span class="n">date_now</span><span class="p">(</span><span class="n">timezone</span><span class="o">=</span><span class="s1">&#39;Asia/Tokyo&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="s2">&quot;2020-05-19&quot;</span>
<span class="n">date_now</span><span class="p">(</span><span class="s1">&#39;2021-10-05&#39;</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">add_days</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="n">returnval</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="mi">20211001</span>
<span class="n">date_now</span><span class="p">(</span><span class="mi">20211005</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fmt_input</span><span class="o">=</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">returnval</span><span class="o">=</span><span class="s1">&#39;str&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="s1">&#39;2021-10-05&#39;</span>

<span class="n">date_now</span><span class="p">(</span><span class="mi">20211005</span><span class="p">,</span>  <span class="n">fmt_input</span><span class="o">=</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">returnval</span><span class="o">=</span><span class="s1">&#39;unix&#39;</span><span class="p">)</span>    <span class="o">--&gt;</span>  <span class="mi">1634324632848</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.help">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">help</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.help" title="Permalink to this definition"></a></dt>
<dd><p>function help</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_check_table">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_check_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tables</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_jar_cmd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_check_table" title="Permalink to this definition"></a></dt>
<dd><p>Check Hive table using Hive
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tables</span> <span class="o">=</span> <span class="p">[</span>  <span class="s1">&#39;mydb.mytable&#39;</span>   <span class="p">]</span>
<span class="n">OR</span>
<span class="n">myalias</span> <span class="p">:</span> <span class="n">mydb</span><span class="o">.</span><span class="n">mytable</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_db_dumpall">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_db_dumpall</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_db_dumpall" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_get_dblist">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_get_dblist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_get_dblist" title="Permalink to this definition"></a></dt>
<dd><p>Get  databases</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_get_tablechema">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_get_tablechema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tablename</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_get_tablechema" title="Permalink to this definition"></a></dt>
<dd><p>Get  databases</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_get_tabledetails">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_get_tabledetails</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_get_tabledetails" title="Permalink to this definition"></a></dt>
<dd><p>Doc::
describe formatted table</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_get_tablelist">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_get_tablelist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dbname</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_get_tablelist" title="Permalink to this definition"></a></dt>
<dd><p>Get Hive tables from database_name</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.hive_run_sql">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">hive_run_sql</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">query_or_sqlfile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nohup</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.hive_run_sql" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.json_compress">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">json_compress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">raw_obj</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.json_compress" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.json_decompress">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">json_decompress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.json_decompress" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.os_file_replace">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">os_file_replace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dirin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['myfolder/**/*.sh',</span> <span class="pre">'myfolder/**/*.conf']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">textold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/mypath2/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">textnew</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'/mypath2/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.os_file_replace" title="Permalink to this definition"></a></dt>
<dd><p>Replace string in config files.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sspark</span> <span class="n">os_file_replace</span> <span class="o">--</span><span class="n">dirin</span> <span class="n">spark</span><span class="o">/</span><span class="n">conf</span>  <span class="o">--</span><span class="n">textold</span> <span class="s1">&#39;mydir1/&#39;</span> <span class="o">--</span><span class="n">textnew</span> <span class="s1">&#39;mydir2/&#39;</span>  <span class="o">--</span><span class="n">test</span> <span class="mi">1</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.os_subprocess">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">os_subprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">args_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stdout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stderr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.os_subprocess" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.os_system">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">os_system</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cmd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.os_system" title="Permalink to this definition"></a></dt>
<dd><p>os.system and retrurn stdout, stderr values</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.run_cli_sspark">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">run_cli_sspark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.run_cli_sspark" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.show_parquet">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">show_parquet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nrows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.show_parquet" title="Permalink to this definition"></a></dt>
<dd><p>Us pyarrow
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span>  <span class="n">install</span> <span class="n">libhdfs3</span> <span class="n">pyarrow</span>
<span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">stackoverflow</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">questions</span><span class="o">/</span><span class="mi">53087752</span><span class="o">/</span><span class="n">unable</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">load</span><span class="o">-</span><span class="n">libhdfs</span><span class="o">-</span><span class="n">when</span><span class="o">-</span><span class="n">using</span><span class="o">-</span><span class="n">pyarrow</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_add_jar">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_add_jar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparksession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hive_jar_cmd</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_add_jar" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_config_check">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_config_check</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_config_check" title="Permalink to this definition"></a></dt>
<dd><p>Check if files are misisng !!! Very useful for new spark install.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>    <span class="o">//</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">utilmy</span>
<span class="n">sspark</span> <span class="n">spark_config_check</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_config_create">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_config_create</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./conf_spark/'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_config_create" title="Permalink to this definition"></a></dt>
<dd><p>Dump template Spark config into a folder.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_config_print">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_config_print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparksession</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_config_print" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_check">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'check'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">returnval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_check" title="Permalink to this definition"></a></dt>
<dd><p>Check dataframe for debugging
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">conf</span><span class="p">:</span>  <span class="n">Configuration</span> <span class="ow">in</span> <span class="nb">dict</span>
    <span class="n">df</span><span class="p">:</span>
    <span class="n">dirout</span><span class="p">:</span>
    <span class="n">nsample</span><span class="p">:</span>
    <span class="n">save</span><span class="p">:</span>
    <span class="n">verbose</span><span class="p">:</span>
    <span class="n">returnval</span><span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_filter_mostrecent">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_filter_mostrecent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colid</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'userid'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_orderby</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'date'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decreasing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_filter_mostrecent" title="Permalink to this definition"></a></dt>
<dd><p>get most recent (ie date desc, rank=1) record for each userid</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_isempty">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_isempty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_isempty" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_sample">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fraction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_stratify</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_replace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_sample" title="Permalink to this definition"></a></dt>
<dd><p>sample
Docs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">((</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">))</span>
<span class="n">sampled</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sampleBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="n">fractions</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">},</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sampled</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_sampleover">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_sampleover</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coltarget</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'animal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">major_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dog'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minor_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'frog'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_sampleover" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_sampleunder">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_sampleunder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">coltarget</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'animal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">major_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'dog'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minor_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'frog'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_sampleunder" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_split_timeseries">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_split_timeseries</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splitRatio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparksession</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_split_timeseries" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Splitting data into train and test</span>
<span class="c1"># we maintain the time-order while splitting</span>
<span class="c1"># if split target_ratio = 0.7 then first 70% of data is train data</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">df_m</span><span class="p">:</span>
    <span class="n">splitRatio</span><span class="p">:</span>
    <span class="n">sparksession</span><span class="p">:</span>

<span class="n">Returns</span><span class="p">:</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_stats_all">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_stats_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['null',</span> <span class="pre">'n5',</span> <span class="pre">'n95']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_stats_all" title="Permalink to this definition"></a></dt>
<dd><p>TODO: get stats 5%, 95% for each column</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_stats_freq">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_stats_freq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols_cat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_stats_freq" title="Permalink to this definition"></a></dt>
<dd><p>get the percentage of value absent and most frequent and least frequent value  in the column</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_stats_null">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_stats_null</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cols</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">doprint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_stats_null" title="Permalink to this definition"></a></dt>
<dd><p>get the percentage of value absent and most frequent and least frequent value  in the column</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_df_write">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_df_write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">npartitions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'overwrite'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'parquet'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_df_write" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Doc::</dt><dd><p>mode: append, overwrite, ignore, error
format: parquet, csv, json …</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_get_session">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_get_session</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_key_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'spark_config'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_get_session" title="Permalink to this definition"></a></dt>
<dd><p>Generic Spark session creation
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="p">:</span>  <span class="n">path</span> <span class="n">on</span> <span class="n">disk</span> <span class="n">OR</span> <span class="n">dictionnary</span>

<span class="n">config_key_name</span><span class="o">=</span><span class="s1">&#39;spark_config&#39;</span>  <span class="k">for</span> <span class="n">sub</span><span class="o">-</span><span class="n">folder</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_get_session_local">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_get_session_local</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'/default.yaml'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keyfield</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sparkconfig'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_get_session_local" title="Permalink to this definition"></a></dt>
<dd><p>Start Local session for debugging
Docs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sparksession</span> <span class="o">=</span> <span class="n">spark_get_session_local</span><span class="p">()</span>

<span class="n">sparksession</span> <span class="o">=</span> <span class="n">spark_get_session_local</span><span class="p">(</span><span class="s1">&#39;mypath/conffig.yaml)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_metrics_classifier_summary">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_metrics_classifier_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df_labels_preds</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_metrics_classifier_summary" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_metrics_roc_summary">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_metrics_roc_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels_and_predictions_df</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_metrics_roc_summary" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_read">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_read</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparksession</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dirin</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'hdfs://'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_read" title="Permalink to this definition"></a></dt>
<dd><p>Universal HDFS file reader
Doc::
format: parquet, csv, json, orc …</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_read_subfolder">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_read_subfolder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparksession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir_parent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nfile_past</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">24</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_pattern</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kw</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_read_subfolder" title="Permalink to this definition"></a></dt>
<dd><p>subfolder
doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dir_parent</span><span class="o">/</span><span class="mi">2021</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">03</span><span class="o">/</span><span class="n">file1</span><span class="o">.</span><span class="n">csv</span>
<span class="n">dir_parent</span><span class="o">/</span><span class="mi">2021</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">04</span><span class="o">/</span><span class="n">file1</span><span class="o">.</span><span class="n">csv</span>
<span class="n">dir_parent</span><span class="o">/</span><span class="mi">2021</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">05</span><span class="o">/</span><span class="n">file1</span><span class="o">.</span><span class="n">csv</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.spark_run_sqlfile">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">spark_run_sqlfile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparksession</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spark_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sql_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_sql_variables</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#utilmy.sspark.src.util_spark.spark_run_sqlfile" title="Permalink to this definition"></a></dt>
<dd><p>Execute SQL
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">map_sql_variables</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;start_dt&#39;</span><span class="p">:</span>  <span class="s1">&#39;2020-01-01&#39;</span><span class="p">,</span>  <span class="p">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.test1">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">test1</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.test1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.test2">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">test2</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.test2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.test_all">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">test_all</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.test_all" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_spark.test_get_dataframe_fake">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_spark.</span></span><span class="sig-name descname"><span class="pre">test_get_dataframe_fake</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'city'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_spark.test_get_dataframe_fake" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-utilmy.sspark.src.util_sparkml">
<span id="utilmy-sspark-src-util-sparkml-module"></span><h2>utilmy.sspark.src.util_sparkml module<a class="headerlink" href="#module-utilmy.sspark.src.util_sparkml" title="Permalink to this heading"></a></h2>
<ol class="arabic simple" start="6">
<li><p>Predict the session length for a given IP</p></li>
</ol>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_sparkml.Predict">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_sparkml.</span></span><span class="sig-name descname"><span class="pre">Predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_sparkml.Predict" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># this performs model training</span>
<span class="c1"># this calls the machine-learning algorithms of Spark ML library</span>
<span class="c1"># creating labels for machine-learning</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">spark</span><span class="p">:</span>  <span class="n">SparkSession</span>
    <span class="n">df</span><span class="p">:</span>  <span class="n">Spark</span> <span class="n">Dataframe</span> <span class="n">Vector</span> <span class="n">Assembler</span>
    <span class="n">features</span><span class="p">:</span> <span class="n">column</span> <span class="n">features</span>
    <span class="n">regressor</span><span class="p">:</span>  <span class="n">model</span> <span class="n">name</span>
    <span class="n">path</span><span class="p">:</span>  <span class="n">model</span> <span class="n">path</span>
    <span class="n">conf_model</span><span class="p">:</span>  <span class="n">conf</span> <span class="ow">in</span> <span class="nb">dict</span><span class="o">.</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_sparkml.TimeSeriesSplit">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_sparkml.</span></span><span class="sig-name descname"><span class="pre">TimeSeriesSplit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splitRatio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparksession</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">object</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_sparkml.TimeSeriesSplit" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Splitting data into train and test</span>
<span class="c1"># we maintain the time-order while splitting</span>
<span class="c1"># if split ratio = 0.7 then first 70% of data is train data</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">df_m</span><span class="p">:</span>
    <span class="n">splitRatio</span><span class="p">:</span>
    <span class="n">sparksession</span><span class="p">:</span>

<span class="n">Returns</span><span class="p">:</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_sparkml.Train">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_sparkml.</span></span><span class="sig-name descname"><span class="pre">Train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df_m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regressor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_sparkml.Train" title="Permalink to this definition"></a></dt>
<dd><p>.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># this performs model training</span>
<span class="c1"># this calls the machine-learning algorithms of Spark ML library</span>
<span class="c1"># creating labels for machine-learning</span>
<span class="n">Args</span><span class="p">:</span>
    <span class="n">spark</span><span class="p">:</span> <span class="n">Sparksession</span>
    <span class="n">df_m</span><span class="p">:</span> <span class="n">Spark</span> <span class="n">Dataframe</span> <span class="n">Vector</span> <span class="n">Assembler</span>
    <span class="n">features</span><span class="p">:</span>  <span class="n">column</span> <span class="n">names</span>
    <span class="n">regressor</span><span class="p">:</span>  <span class="n">model</span> <span class="n">name</span>
    <span class="n">path</span><span class="p">:</span>  <span class="n">model</span> <span class="n">to</span> <span class="n">save</span>
    <span class="n">conf_model</span><span class="p">:</span>  <span class="n">config</span> <span class="ow">in</span> <span class="nb">dict</span>

<span class="n">Returns</span><span class="p">:</span> <span class="n">training</span> <span class="n">resuls</span> <span class="n">split</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_sparkml.log">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_sparkml.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_sparkml.log" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.util_sparkml.os_makedirs">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.util_sparkml.</span></span><span class="sig-name descname"><span class="pre">os_makedirs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.util_sparkml.os_makedirs" title="Permalink to this definition"></a></dt>
<dd><p>function os_makedirs.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">path</span> <span class="p">(</span> <span class="nb">str</span> <span class="p">)</span> <span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="utilmy-sspark-src-util-trick-module">
<h2>utilmy.sspark.src.util_trick module<a class="headerlink" href="#utilmy-sspark-src-util-trick-module" title="Permalink to this heading"></a></h2>
</section>
<section id="module-utilmy.sspark.src.utils">
<span id="utilmy-sspark-src-utils-module"></span><h2>utilmy.sspark.src.utils module<a class="headerlink" href="#module-utilmy.sspark.src.utils" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.config_load">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">config_load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.config_load" title="Permalink to this definition"></a></dt>
<dd><p>Load Config file into a dict
:param config_path: path of config</p>
<p>Returns: dict config</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.log">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.log" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.log2">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">log2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.log2" title="Permalink to this definition"></a></dt>
<dd><p>function log2</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.log3">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">log3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.log3" title="Permalink to this definition"></a></dt>
<dd><p>function log3</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.log_sample">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">log_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.log_sample" title="Permalink to this definition"></a></dt>
<dd><p>function log_sample</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.logger_setdefault">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">logger_setdefault</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.logger_setdefault" title="Permalink to this definition"></a></dt>
<dd><p>Returns:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.spark_check">
<span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">spark_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nsample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">returnval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.spark_check" title="Permalink to this definition"></a></dt>
<dd><p>Snapshot checkpoint for dataframe
:param conf: Configuration in dict
:param df:
:param path:
:param nsample:
:param save:
:param verbose:
:param returnval:</p>
<p>Returns:</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.sspark.src.utils.to_namespace">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.sspark.src.utils.</span></span><span class="sig-name descname"><span class="pre">to_namespace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">d</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.sspark.src.utils.to_namespace" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

</section>
<section id="module-utilmy.sspark.src">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-utilmy.sspark.src" title="Permalink to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="utilmy.sspark.html" class="btn btn-neutral float-left" title="utilmy.sspark package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="utilmy.sspark.src.afpgrowth.html" class="btn btn-neutral float-right" title="utilmy.sspark.src.afpgrowth package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: zdocs_y23487teg65f6
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      
      <dl>
        <dt>Languages</dt>
        
           <strong> 
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/">en</a></dd>
           </strong> 
        
          
          <dd><a href="/myutil/es/zdocs_y23487teg65f6/">es</a></dd>
          
        
      </dl>
      
      
      <dl>
        <dt>Versions</dt>
        
           <strong> 
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/">zdocs_y23487teg65f6</a></dd>
           </strong> 
        
      </dl>
      
      
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/utilmy-docs_en_zdocs_y23487teg65f6.pdf">pdf</a></dd>
        
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/utilmy-docs_en_zdocs_y23487teg65f6.epub">epub</a></dd>
        
      </dl>
      
      
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.
 
    </div>
  </div>

 <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-XXXXXXXXXX', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>
<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>utilmy.stats.hypothesis package &mdash; utilmy 1.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="utilmy.stats.hypothesis.tests package" href="utilmy.stats.hypothesis.tests.html" />
    <link rel="prev" title="utilmy.stats package" href="utilmy.stats.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
            <a href="index.html" class="icon icon-home"> utilmy
          </a>
              <div class="version">
                zdocs_y23487teg65f6
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">utilmy</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="utilmy.html">utilmy package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="utilmy.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="utilmy.configs.html">utilmy.configs package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.deeplearning.html">utilmy.deeplearning package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.docs.html">utilmy.docs package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.excel.html">utilmy.excel package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.images.html">utilmy.images package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.nlp.html">utilmy.nlp package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.optim.html">utilmy.optim package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.prepro.html">utilmy.prepro package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.recsys.html">utilmy.recsys package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.sspark.html">utilmy.sspark package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="utilmy.stats.html">utilmy.stats package</a><ul class="current">
<li class="toctree-l5 current"><a class="reference internal" href="utilmy.stats.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l6 current"><a class="current reference internal" href="#">utilmy.stats.hypothesis package</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l8"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html">utilmy.stats.hypothesis.tests package</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.aov">utilmy.stats.hypothesis.aov module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#one-way-analysis-of-variance">One-Way Analysis of Variance</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.contingency">utilmy.stats.hypothesis.contingency module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#contingency-tables">Contingency Tables</a></li>
<li class="toctree-l8"><a class="reference internal" href="#other-functions">Other Functions</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.critical">utilmy.stats.hypothesis.critical module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#critical-value-lookup-functions">Critical Value Lookup Functions</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.descriptive">utilmy.stats.hypothesis.descriptive module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#correlation">Correlation</a></li>
<li class="toctree-l8"><a class="reference internal" href="#variance-and-covariance">Variance and Covariance</a></li>
<li class="toctree-l8"><a class="reference internal" href="#id1">Other Functions</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.fa">utilmy.stats.hypothesis.fa module</a></li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.gof">utilmy.stats.hypothesis.gof module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#goodness-of-fit">Goodness-of-fit</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.hypothesis">utilmy.stats.hypothesis.hypothesis module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#hypothesis-testing">Hypothesis Testing</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.nonparametric">utilmy.stats.hypothesis.nonparametric module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#nonparametric-inference-methods">Nonparametric Inference Methods</a></li>
<li class="toctree-l8"><a class="reference internal" href="#id2">Other Functions</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis.posthoc">utilmy.stats.hypothesis.posthoc module</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#post-hoc-analysis">Post-Hoc Analysis</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#module-utilmy.stats.hypothesis">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.stats.html#submodules">Submodules</a></li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.stats.html#module-utilmy.stats.statistics">utilmy.stats.statistics module</a></li>
<li class="toctree-l5"><a class="reference internal" href="utilmy.stats.html#module-utilmy.stats">Module contents</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tabular.html">utilmy.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.templates.html">utilmy.templates package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tools.html">utilmy.tools package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.tseries.html">utilmy.tseries package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.viz.html">utilmy.viz package</a></li>
<li class="toctree-l4"><a class="reference internal" href="utilmy.webscraper.html">utilmy.webscraper package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.adatasets">utilmy.adatasets module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.cli">utilmy.cli module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.data">utilmy.data module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.dates">utilmy.dates module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.debug">utilmy.debug module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.decorators">utilmy.decorators module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.distributed">utilmy.distributed module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.graph">utilmy.graph module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.iio">utilmy.iio module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.nnumpy">utilmy.nnumpy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.oos">utilmy.oos module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.parallel">utilmy.parallel module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.ppandas">utilmy.ppandas module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.ppolars">utilmy.ppolars module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_batch">utilmy.util_batch module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_colab">utilmy.util_colab module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_conda">utilmy.util_conda module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#utilmy-util-cpu-module">utilmy.util_cpu module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_download">utilmy.util_download module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.util_zip">utilmy.util_zip module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.utilmy">utilmy.utilmy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.utils">utilmy.utils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.z_test">utilmy.z_test module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy.zdocstring">utilmy.zdocstring module</a></li>
<li class="toctree-l3"><a class="reference internal" href="utilmy.html#module-utilmy">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: white" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">utilmy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">utilmy</a> &raquo;</li>
          <li><a href="utilmy.html">utilmy package</a> &raquo;</li>
          <li><a href="utilmy.stats.html">utilmy.stats package</a> &raquo;</li>
      <li>utilmy.stats.hypothesis package</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/maltfield/rtd-github-pages/blob/master/docs/utilmy.stats.hypothesis.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="utilmy-stats-hypothesis-package">
<h1>utilmy.stats.hypothesis package<a class="headerlink" href="#utilmy-stats-hypothesis-package" title="Permalink to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html">utilmy.stats.hypothesis.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#utilmy-stats-hypothesis-tests-test-aov-module">utilmy.stats.hypothesis.tests.test_aov module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_contingency">utilmy.stats.hypothesis.tests.test_contingency module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_critical_values">utilmy.stats.hypothesis.tests.test_critical_values module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_descriptive">utilmy.stats.hypothesis.tests.test_descriptive module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_factor_analysis">utilmy.stats.hypothesis.tests.test_factor_analysis module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_gof">utilmy.stats.hypothesis.tests.test_gof module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#utilmy-stats-hypothesis-tests-test-hypothesis-module">utilmy.stats.hypothesis.tests.test_hypothesis module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests.test_internal">utilmy.stats.hypothesis.tests.test_internal module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#utilmy-stats-hypothesis-tests-test-nonparametric-module">utilmy.stats.hypothesis.tests.test_nonparametric module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#utilmy-stats-hypothesis-tests-test-posthoc-module">utilmy.stats.hypothesis.tests.test_posthoc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utilmy.stats.hypothesis.tests.html#module-utilmy.stats.hypothesis.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-utilmy.stats.hypothesis.aov">
<span id="utilmy-stats-hypothesis-aov-module"></span><h2>utilmy.stats.hypothesis.aov module<a class="headerlink" href="#module-utilmy.stats.hypothesis.aov" title="Permalink to this heading"></a></h2>
<p>Functions for performing one-way analysis of variance (ANOVA) and multivariate analysis of variance (MANOVA).</p>
<section id="one-way-analysis-of-variance">
<h3>One-Way Analysis of Variance<a class="headerlink" href="#one-way-analysis-of-variance" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<p>Andrews, D. F., and Herzberg, A. M. (1985), Data, New York: Springer-Verlag.</p>
<dl class="simple">
<dt>Dobson, A. J. (1983) An Introduction to Statistical Modelling.</dt><dd><p>London: Chapman and Hall.</p>
</dd>
</dl>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<dl class="simple">
<dt>Rencher, A. (n.d.). Methods of Multivariate Analysis (2nd ed.).</dt><dd><p>Brigham Young University: John Wiley &amp; Sons, Inc.</p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.aov.</span></span><span class="sig-name descname"><span class="pre">AnovaOneWay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs one-way ANOVA. One-way ANOVA (Analysis of Variance) is used to analyze and test
the differences of two or more groups have the same population mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector(s).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.group_names">
<span class="sig-name descname"><span class="pre">group_names</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.group_names" title="Permalink to this definition"></a></dt>
<dd><p>Numpy array of the group names.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.k" title="Permalink to this definition"></a></dt>
<dd><p>The number of groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.group_degrees_of_freedom">
<span class="sig-name descname"><span class="pre">group_degrees_of_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.group_degrees_of_freedom" title="Permalink to this definition"></a></dt>
<dd><p>The group degrees of freedom, <code class="code docutils literal notranslate"><span class="pre">k</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.residual_degrees_of_freedom">
<span class="sig-name descname"><span class="pre">residual_degrees_of_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.residual_degrees_of_freedom" title="Permalink to this definition"></a></dt>
<dd><p>The residual degrees of freedom, “code:<cite>n - k</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.group_sum_squares">
<span class="sig-name descname"><span class="pre">group_sum_squares</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.group_sum_squares" title="Permalink to this definition"></a></dt>
<dd><p>The computed group (treatment) sum of squares, typically denoted <span class="math notranslate nohighlight">\(SST\)</span> or <span class="math notranslate nohighlight">\(SSH\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.group_mean_squares">
<span class="sig-name descname"><span class="pre">group_mean_squares</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.group_mean_squares" title="Permalink to this definition"></a></dt>
<dd><p>The ‘within’ sample, or treatment, mean sum of squares, typically denoted <span class="math notranslate nohighlight">\(MST\)</span> or <span class="math notranslate nohighlight">\(MSH\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.residual_sum_squares">
<span class="sig-name descname"><span class="pre">residual_sum_squares</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.residual_sum_squares" title="Permalink to this definition"></a></dt>
<dd><p>The residual sum of squares, usually denoted <span class="math notranslate nohighlight">\(SSE\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.residual_mean_squares">
<span class="sig-name descname"><span class="pre">residual_mean_squares</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.residual_mean_squares" title="Permalink to this definition"></a></dt>
<dd><p>The ‘between’ sample, or error mean sum of squares, usually denoted <span class="math notranslate nohighlight">\(MSE\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.f_statistic">
<span class="sig-name descname"><span class="pre">f_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.f_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The computed <span class="math notranslate nohighlight">\(F\)</span> statistic found by <span class="math notranslate nohighlight">\(\frac{MST}{MSE}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The p-value from the <span class="math notranslate nohighlight">\(F\)</span> distribution given the calculated <span class="math notranslate nohighlight">\(F\)</span> statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.AnovaOneWay.analysis_type">
<span class="sig-name descname"><span class="pre">analysis_type</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.AnovaOneWay.analysis_type" title="Permalink to this definition"></a></dt>
<dd><p>Name of the analysis performed, currently only reutns ‘One-Way ANOVA’</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>One-way ANOVA can be considered an extension of the t-test when more than two groups
are being tested. The factor, or categorical variable, is often referred to as the
‘treatment’ in the ANOVA setting. ANOVA involves partitioning the data’s total
variation into variation between and within groups. This procedure is thus known as
Analysis of Variance as sources of variation are examined separately.</p>
<p>The data is assumed to be normally distributed with mean <span class="math notranslate nohighlight">\(\mu_i\)</span> and standard
deviation <span class="math notranslate nohighlight">\(\sigma^2_i\)</span>. Stating the hypothesis is also similar to previous
examples when there were only two samples of interest. The hypothesis can be defined
formally as:</p>
<p><span class="math notranslate nohighlight">\(H_O: \mu_1 = \mu_2 = \cdots = \mu_k\)</span>
<span class="math notranslate nohighlight">\(H_A:\)</span> Not all population means are equal</p>
<p>The one-way ANOVA splits the data’s variation into two sources which are in turn used
to calculate the F-statistic. The F-statistic is determined by the F-test, which is
done by dividing the variance between groups by the variance within groups. The sum of
squares for treatments is defined as <span class="math notranslate nohighlight">\(SST\)</span>, for error as <span class="math notranslate nohighlight">\(SSE\)</span> and the total
<span class="math notranslate nohighlight">\(TotalSS\)</span>. The mean squares are calculated by dividing the sum of squares by the
degrees of freedom.</p>
<p>Each sum of squares can be defined as:</p>
<div class="math notranslate nohighlight">
\[SST = \sum_{i=1}^k n_i(\bar{y_{i}} - \bar{y})^2\]</div>
<div class="math notranslate nohighlight">
\[SSE = \sum_{i=1}^k (n_i - 1)s_i^2\]</div>
<div class="math notranslate nohighlight">
\[TotalSS = \sum_{i=1}^k \sum_{j=1}^{n_i} (y_{ij} - \bar{y})^2\]</div>
<p>The mean squares are the sum of squares divided by the degrees of freedom.</p>
<div class="math notranslate nohighlight">
\[MST = \frac{SST}{k - 1}\]</div>
<div class="math notranslate nohighlight">
\[MSE = \frac{SSE}{n - k}\]</div>
<p>The F-statistic is defined as:</p>
<div class="math notranslate nohighlight">
\[f = \frac{MST}{MSE}\]</div>
<p class="rubric">Examples</p>
<p>There are several ways to perform a one-way ANOVA with the <code class="code docutils literal notranslate"><span class="pre">one_way_anova</span></code> function.
Perhaps the simplest approach is to pass a group vector with the <code class="code docutils literal notranslate"><span class="pre">group</span></code> parameter
and the corresponding observation vector as below.</p>
<p>The data used in this example is a subset of the data obtained from the plant growth
dataset given in Dobson (1983).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">group_vector</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ctrl&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;trt1&#39;</span><span class="p">,</span> <span class="s1">&#39;trt1&#39;</span><span class="p">,</span> <span class="s1">&#39;trt1&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;trt2&#39;</span><span class="p">,</span> <span class="s1">&#39;trt2&#39;</span><span class="p">,</span> <span class="s1">&#39;trt2&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">observation_vec</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.17</span><span class="p">,</span> <span class="mf">5.58</span><span class="p">,</span> <span class="mf">5.18</span><span class="p">,</span>
<span class="gp">... </span>                   <span class="mf">4.81</span><span class="p">,</span> <span class="mf">4.17</span><span class="p">,</span> <span class="mf">4.41</span><span class="p">,</span>
<span class="gp">... </span>                   <span class="mf">5.31</span><span class="p">,</span> <span class="mf">5.12</span><span class="p">,</span> <span class="mf">5.54</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aov</span> <span class="o">=</span> <span class="n">AnovaOneWay</span><span class="p">(</span><span class="n">observation_vec</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">group_vector</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aov</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;F-statistic&#39;: 2.4895587076438104,</span>
<span class="go"> &#39;Group DoF&#39;: 2,</span>
<span class="go"> &#39;Group Mean Squares&#39;: 0.5616444444444436,</span>
<span class="go"> &#39;Group Sum of Squares&#39;: 1.1232888888888872,</span>
<span class="go"> &#39;Group statistics&#39;: {&#39;Group Means&#39;: [(&#39;ctrl&#39;, 4.976666666666667),</span>
<span class="go">   (&#39;trt1&#39;, 4.463333333333334),</span>
<span class="go">   (&#39;trt2&#39;, 5.323333333333333)],</span>
<span class="go">  &#39;Group Observations&#39;: [(&#39;ctrl&#39;, 3), (&#39;trt1&#39;, 3), (&#39;trt2&#39;, 3)],</span>
<span class="go">  &#39;Group Variance&#39;: [(&#39;ctrl&#39;, 0.5280333333333334),</span>
<span class="go">   (&#39;trt1&#39;, 0.10453333333333321),</span>
<span class="go">   (&#39;trt2&#39;, 0.04423333333333332)]},</span>
<span class="go"> &#39;Residual DoF&#39;: 6,</span>
<span class="go"> &#39;Residual Mean Squares&#39;: 0.2256,</span>
<span class="go"> &#39;Residual Sum of Squares&#39;: 1.3536,</span>
<span class="go"> &#39;Test description&#39;: &#39;One-Way ANOVA&#39;,</span>
<span class="go"> &#39;p-value&#39;: 0.163211765340447}</span>
</pre></div>
</div>
<p>The other approach is to pass each group sample vector similar to the below.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ctrl</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.17</span><span class="p">,</span> <span class="mf">5.58</span><span class="p">,</span> <span class="mf">5.18</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trt1</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.81</span><span class="p">,</span> <span class="mf">4.17</span><span class="p">,</span> <span class="mf">4.41</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trt2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.31</span><span class="p">,</span> <span class="mf">5.12</span><span class="p">,</span> <span class="mf">5.54</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aov1</span> <span class="o">=</span> <span class="n">AnovaOneWay</span><span class="p">(</span><span class="n">ctrl</span><span class="p">,</span> <span class="n">trt1</span><span class="p">,</span> <span class="n">trt2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">aov1</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;F-statistic&#39;: 2.4895587076438104,</span>
<span class="go"> &#39;Group DoF&#39;: 2,</span>
<span class="go"> &#39;Group Mean Squares&#39;: 0.5616444444444436,</span>
<span class="go"> &#39;Group Sum of Squares&#39;: 1.1232888888888872,</span>
<span class="go"> &#39;Group statistics&#39;: {&#39;Group Means&#39;: [(&#39;ctrl&#39;, 4.976666666666667),</span>
<span class="go">   (&#39;trt1&#39;, 4.463333333333334),</span>
<span class="go">   (&#39;trt2&#39;, 5.323333333333333)],</span>
<span class="go">  &#39;Group Observations&#39;: [(&#39;ctrl&#39;, 3), (&#39;trt1&#39;, 3), (&#39;trt2&#39;, 3)],</span>
<span class="go">  &#39;Group Variance&#39;: [(&#39;ctrl&#39;, 0.5280333333333334),</span>
<span class="go">   (&#39;trt1&#39;, 0.10453333333333321),</span>
<span class="go">   (&#39;trt2&#39;, 0.04423333333333332)]},</span>
<span class="go"> &#39;Residual DoF&#39;: 6,</span>
<span class="go"> &#39;Residual Mean Squares&#39;: 0.2256,</span>
<span class="go"> &#39;Residual Sum of Squares&#39;: 1.3536,</span>
<span class="go"> &#39;Test description&#39;: &#39;One-Way ANOVA&#39;,</span>
<span class="go"> &#39;p-value&#39;: 0.163211765340447}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Dobson, A. J. (1983) An Introduction to Statistical Modelling.</dt><dd><p>London: Chapman and Hall.</p>
</dd>
<dt>Rencher, A. (n.d.). Methods of Multivariate Analysis (2nd ed.).</dt><dd><p>Brigham Young University: John Wiley &amp; Sons, Inc.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.aov.</span></span><span class="sig-name descname"><span class="pre">BartlettsTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Bartlett’s Test for Homogenity of Variances of two or more sample groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector(s).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of samples in all groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.test_statistic">
<span class="sig-name descname"><span class="pre">test_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.test_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The computed Levene’s Test statistic, typically denoted <span class="math notranslate nohighlight">\(\chi^2\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The associated p-value of the <span class="math notranslate nohighlight">\(\chi^2\)</span> test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.test_description">
<span class="sig-name descname"><span class="pre">test_description</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.test_description" title="Permalink to this definition"></a></dt>
<dd><p>Description of the type of test performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.BartlettsTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.BartlettsTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>Bartlett’s test, similar to Levene’s Test and the Brown-Forsythe Test, is another procedure for determining if
two or more sample groups have equal variances. These tests are commonly referred to as ‘tests for homogenity of
variance’. Bartlett’s test is known to be sensitive when the samples are not normally distributed as the test uses
mean square of the groups’ deviations, also known as the pooled variance. Levene’s Test and the Brown-Forsythe test
are therefore alternatives to Bartlett’s Test that are more performant when samples may depart from normality.</p>
<p>The test statistic is approximately chi-square distributed with <span class="math notranslate nohighlight">\(k - 1\)</span> degrees of freedom, where <span class="math notranslate nohighlight">\(k\)</span>
is the number of sample groups. The chi-square approximation does not hold sufficiently when the sample size of
a group is <span class="math notranslate nohighlight">\(n_i &gt; 5\)</span>.</p>
<p>The test statistic, <span class="math notranslate nohighlight">\(\chi^2\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \frac{(n - k) \ln(S^2_p) - \sum^k_{i=1} (n_i - 1) \ln(S^2_i)}{1 + \frac{1}{3(k - 1)} \left(\sum^k_{i=1} (\frac{1}{n_i - 1}) - \frac{1}{n - k} \right)}\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the total number of samples across all groups, <span class="math notranslate nohighlight">\(k\)</span> is the number of groups, <span class="math notranslate nohighlight">\(S^2_i\)</span>
are the sample variances.</p>
<p><span class="math notranslate nohighlight">\(S^2_p\)</span>, the pooled estimate of the samples’ variance, is defined as:</p>
<div class="math notranslate nohighlight">
\[S^2_p = \frac{1}{n - k} \sum_i (n_i - 1) S^2_i\]</div>
<p class="rubric">Examples</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>NIST/SEMATECH e-Handbook of Statistical Methods. Available online, URL:</dt><dd><p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm">https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm</a></p>
</dd>
<dt>Snedecor, George W. and Cochran, William G. (1989), Statistical Methods, Eighth Edition,</dt><dd><p>Iowa State University Press.</p>
</dd>
<dt>Wikipedia contributors. “Bartlett’s test.” Wikipedia, The Free Encyclopedia.</dt><dd><p>Wikipedia, The Free Encyclopedia, 17 Feb. 2020. Web. 13 Mar. 2020.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.aov.</span></span><span class="sig-name descname"><span class="pre">LevenesTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'median'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Levene’s Test for Homogenity of Variances of two or more sample groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector(s).</p></li>
<li><p><strong>location</strong> (<em>str</em><em>, </em><em>{'median'</em><em>, </em><em>'mean'}</em>) – Specifies the procedure used to calculate Levene’s Test. The default ‘median’, performs the standard Levene’s
Test while ‘mean’ will perform the Brown-Forsythe test for equality of variances.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of samples in all groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.location">
<span class="sig-name descname"><span class="pre">location</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.location" title="Permalink to this definition"></a></dt>
<dd><p>The location parameter specifying which procedure to perform.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.test_statistic">
<span class="sig-name descname"><span class="pre">test_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.test_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The computed Levene’s Test statistic, typically denoted <span class="math notranslate nohighlight">\(W\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The associated p-value of the <span class="math notranslate nohighlight">\(W\)</span> test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.test_description">
<span class="sig-name descname"><span class="pre">test_description</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.test_description" title="Permalink to this definition"></a></dt>
<dd><p>Description of the type of test performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.LevenesTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.LevenesTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – Raised if <code class="code docutils literal notranslate"><span class="pre">location</span></code> parameter is not one of ‘median’ or ‘mean’.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The test statistic, <span class="math notranslate nohighlight">\(W\)</span> used in Levene’s test is defined as:</p>
<div class="math notranslate nohighlight">
\[W = \frac{(N - k)}{(k - 1)} \frac{\sum^k_{i=1} n_i (Z_{i.} - Z_{..})^2}{\sum^k_{i=1} \sum^{n_i}_{j=1} (Z_{ij} - Z_{i.})^2}\]</div>
<p>where,</p>
<ul class="simple">
<li><dl class="field-list simple">
<dt class="field-odd">math</dt>
<dd class="field-odd"><p><cite>k</cite> is the number of groups</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">math</dt>
<dd class="field-odd"><p><cite>n_i</cite> is the number of samples belonging to the i-th group.</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">math</dt>
<dd class="field-odd"><p><cite>N</cite> is the total number of samples.</p>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(Y_{ij}\)</span> is the jth observation from the ith group.</p></li>
</ul>
<p>and,</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Z_{i.} = \frac{1}{n_i} \sum^{n_i}_{j=1} Z_{ij}\\Z_{..} = \frac{1}{N} \sum^k_{i=1} \sum^{n_i}_{j=1} Z_{ij}\end{aligned}\end{align} \]</div>
<p>are the mean of the calculated <span class="math notranslate nohighlight">\(Z_{ij}\)</span> for group i and mean of all <span class="math notranslate nohighlight">\(Z_{ij}\)</span>, respectively.</p>
<p>In Levene’s Test, <span class="math notranslate nohighlight">\(Z_{ij}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[|Y_{ij} - \tilde{Y}_i|\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{Y}_i\)</span> is the median of the ith group.</p>
<p>In the case of the Brown-Forsythe test, <span class="math notranslate nohighlight">\(Z_{ij}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[|Y_{ij} - \bar{Y}_i|\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{Y}_i\)</span> is the mean of the ith group.</p>
<p>The <span class="math notranslate nohighlight">\(W\)</span> test statistic is approximately <span class="math notranslate nohighlight">\(F\)</span>-distributed with <span class="math notranslate nohighlight">\(k - 1\)</span> and <span class="math notranslate nohighlight">\(n - k\)</span> degrees
of freedom, <span class="math notranslate nohighlight">\(F(\alpha, k-1, n-k)\)</span></p>
<p class="rubric">Examples</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>NIST/SEMATECH e-Handbook of Statistical Methods. Available online, URL:</dt><dd><p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm">https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm</a></p>
</dd>
<dt>Snedecor, George W. and Cochran, William G. (1989), Statistical Methods, Eighth Edition,</dt><dd><p>Iowa State University Press.</p>
</dd>
<dt>Wikipedia contributors. “Levene’s test.” Wikipedia, The Free Encyclopedia.</dt><dd><p>Wikipedia, The Free Encyclopedia, 28 Apr. 2019. Web. 13 Mar. 2020.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.aov.</span></span><span class="sig-name descname"><span class="pre">ManovaOneWay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs multivariate analysis of variance, also known as MANOVA. Multivariate analysis of variance is
the extension of the ANOVA procedure for two or more dependent variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector. If only one sample vector is passed with a group
variable, one-way MANOVA will be performed.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector. If only one sample vector is passed with a group
variable, one-way MANOVA will be performed.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector. If only one sample vector is passed with a group
variable, one-way MANOVA will be performed.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.group_names">
<span class="sig-name descname"><span class="pre">group_names</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.group_names" title="Permalink to this definition"></a></dt>
<dd><p>Numpy array of the group names.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.k" title="Permalink to this definition"></a></dt>
<dd><p>The number of groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.group_stats">
<span class="sig-name descname"><span class="pre">group_stats</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.group_stats" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing group means, number of observations and data for each
dependent variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.observation_stats">
<span class="sig-name descname"><span class="pre">observation_stats</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.observation_stats" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of overall dependent variable means and number of observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.hypothesis_matrix">
<span class="sig-name descname"><span class="pre">hypothesis_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.hypothesis_matrix" title="Permalink to this definition"></a></dt>
<dd><p>The calculated hypothesis matrix, <span class="math notranslate nohighlight">\(H\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.error_matrix">
<span class="sig-name descname"><span class="pre">error_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.error_matrix" title="Permalink to this definition"></a></dt>
<dd><p>The error matrix, <span class="math notranslate nohighlight">\(E\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.degrees_of_freedom">
<span class="sig-name descname"><span class="pre">degrees_of_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.degrees_of_freedom" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the group and residual degrees of freedom.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.numerator_dof">
<span class="sig-name descname"><span class="pre">numerator_dof</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.numerator_dof" title="Permalink to this definition"></a></dt>
<dd><p>The numerator (group) degrees of freedom.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.denominator_dof">
<span class="sig-name descname"><span class="pre">denominator_dof</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.denominator_dof" title="Permalink to this definition"></a></dt>
<dd><p>The denominator (residual) degrees of freedom.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.pillai_statistic">
<span class="sig-name descname"><span class="pre">pillai_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.pillai_statistic" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the Pillai statistic, and the corresponding F-statistic and p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.wilks_lambda">
<span class="sig-name descname"><span class="pre">wilks_lambda</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.wilks_lambda" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the Wilk’s Lambda statistic, and the corresponding F-statistic and p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.roys_statistic">
<span class="sig-name descname"><span class="pre">roys_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.roys_statistic" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing Roy’s statistic, and the corresponding F-statistic and p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.hotelling_t2_statistic">
<span class="sig-name descname"><span class="pre">hotelling_t2_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.hotelling_t2_statistic" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the Lawey-Hotelling <span class="math notranslate nohighlight">\(T^2\)</span> statistic, and the corresponding
F-statistic and p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.aov.ManovaOneWay.analysis_type">
<span class="sig-name descname"><span class="pre">analysis_type</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.aov.ManovaOneWay.analysis_type" title="Permalink to this definition"></a></dt>
<dd><p>String denoting the type of analysis performed. Currently only returns ‘One-Way MANOVA’</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>MANOVA, or Multiple Analysis of Variance, is an extension of Analysis of
Variance (ANOVA) to several dependent variables. The approach to MANOVA
is similar to ANOVA in many regards and requires the same assumptions
(normally distributed dependent variables with equal covariance matrices).</p>
<p>In the MANOVA setting, each observation vector can have a model denoted as:</p>
<div class="math notranslate nohighlight">
\[y_{ij} = \mu_i + \epsilon_{ij} \qquad i = 1, 2, \cdots, k; \qquad j = 1, 2, \cdots, n\]</div>
<p>An ‘observation vector’ is a set of observations measured over several variables.
With <span class="math notranslate nohighlight">\(p\)</span> variables, <span class="math notranslate nohighlight">\(y_{ij}\)</span> becomes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} y_{ij1} \\ y_{ij2} \\ \vdots \\ y_{ijp} \end{bmatrix} = \begin{bmatrix}
\mu_{i1} \\ \mu_{i2} \\ \vdots \\ \mu_{ip} \end{bmatrix} + \begin{bmatrix} \epsilon_{ij1}
\\ \epsilon_{ij2} \\ \vdots \\ \epsilon_{ijp} \end{bmatrix}\end{split}\]</div>
<p>As before in ANOVA, the goal is to compare the groups to see if there are any significant
differences. However, instead of a single variable, the comparisons will be made with the
mean vectors of the samples. The null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> can be formalized the same
way in MANOVA:</p>
<div class="math notranslate nohighlight">
\[H_0: \mu_1 = \mu_2 = \dots = \mu_k\]</div>
<p>With an alternative hypothesis <span class="math notranslate nohighlight">\(H_a\)</span> that at least two <span class="math notranslate nohighlight">\(\mu\)</span> are unequal.
There are <span class="math notranslate nohighlight">\(p(k - 1)\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the number of groups in the data,
equalities that must be true for <span class="math notranslate nohighlight">\(H_0\)</span> to be accepted.</p>
<p>Similar to ANOVA, we are interested in partitioning the data’s total variation into
variation between and within groups. In the case of ANOVA, this partitioning is done
by calculating <span class="math notranslate nohighlight">\(SSH\)</span> and <span class="math notranslate nohighlight">\(SSE\)</span>; however, in the multivariate case, we must
extend this to encompass the variation in all the <span class="math notranslate nohighlight">\(p\)</span> variables. Therefore, we
must compute the between and within sum of squares for each possible comparison. This
procedure results in the <span class="math notranslate nohighlight">\(H\)</span> “hypothesis matrix” and <span class="math notranslate nohighlight">\(E\)</span> “error matrix.”</p>
<p>The <span class="math notranslate nohighlight">\(H\)</span> matrix is a square <span class="math notranslate nohighlight">\(p \times p\)</span> with the form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}H = \begin{bmatrix} SSH_{11} &amp; SPH_{21} &amp; \dots &amp; SPH_{1p} \\
SPH_{12} &amp; SSH_{22} &amp; \dots &amp; SPH_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\
SPH_{1p} &amp; SPH_{2p} &amp; \cdots &amp; SSH_{pp} \end{bmatrix}\end{split}\]</div>
<p>The error matrix <span class="math notranslate nohighlight">\(E\)</span> is also <span class="math notranslate nohighlight">\(p \times p\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}E = \begin{bmatrix} SSE_{11} &amp; SPE_{12} &amp; \cdots &amp; SPE_{1p} \\
SPE_{12} &amp; SSE_{22} &amp; \cdots &amp; SPE_{2p} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\
SPE_{1p} &amp; SPE_{2p} &amp; \cdots &amp; SSE_{pp} \end{bmatrix}\end{split}\]</div>
<p>Once the <span class="math notranslate nohighlight">\(H\)</span> and <span class="math notranslate nohighlight">\(E\)</span> matrices are constructed, the mean vectors can be
compared to determine if significant differences exist. There are several test
statistics, of which the most common are Wilk’s lambda, Roy’s test, Pillai, and
Lawley-Hotelling, that can be employed to test for significant differences. Each test
statistic has specific properties and power.</p>
<p class="rubric">Examples</p>
<p>The data used in this example is a subset of the rootstock dataset used in Rencher (n.d.).
The rootstock data contains four dependent variables and a group variable described as follows:</p>
<ol class="arabic simple">
<li><p>tree_number: group membership indicator column</p></li>
<li><p>trunk_girth_four_years: trunk girth at four years (mm <span class="math notranslate nohighlight">\(\times\)</span> 100)</p></li>
<li><p>ext_growth_four_years: extension growth at four years (m)</p></li>
<li><p>trunk_girth_fifteen_years: trunk girth at 15 years (mm <span class="math notranslate nohighlight">\(\times\)</span> 100)</p></li>
<li><p>weight_above_ground_fifteen_years: weight of tree above ground at 15 years (lb <span class="math notranslate nohighlight">\(\times\)</span> 1000)</p></li>
</ol>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tree_number</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trunk_girth_four_years</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.11</span><span class="p">,</span> <span class="mf">1.19</span><span class="p">,</span> <span class="mf">1.09</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="mf">1.05</span><span class="p">,</span> <span class="mf">1.17</span><span class="p">,</span> <span class="mf">1.11</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="mf">1.07</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mf">1.06</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="mf">1.22</span><span class="p">,</span> <span class="mf">1.03</span><span class="p">,</span> <span class="mf">1.14</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="mf">0.91</span><span class="p">,</span> <span class="mf">1.15</span><span class="p">,</span> <span class="mf">1.14</span><span class="p">,</span>
<span class="gp">... </span>                          <span class="mf">1.11</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ext_growth_four_years</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.569</span><span class="p">,</span> <span class="mf">2.928</span><span class="p">,</span> <span class="mf">2.865</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">2.074</span><span class="p">,</span> <span class="mf">2.885</span><span class="p">,</span> <span class="mf">3.378</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">2.505</span><span class="p">,</span> <span class="mf">2.315</span><span class="p">,</span> <span class="mf">2.667</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">2.838</span><span class="p">,</span> <span class="mf">2.351</span><span class="p">,</span> <span class="mf">3.001</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">1.532</span><span class="p">,</span> <span class="mf">2.552</span><span class="p">,</span> <span class="mf">3.083</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="mf">2.813</span><span class="p">,</span> <span class="mf">0.840</span><span class="p">,</span> <span class="mf">2.199</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trunk_girth_fifteen_years</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.58</span><span class="p">,</span> <span class="mf">3.75</span><span class="p">,</span> <span class="mf">3.93</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="mf">4.09</span><span class="p">,</span> <span class="mf">4.87</span><span class="p">,</span> <span class="mf">4.98</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="mf">3.76</span><span class="p">,</span> <span class="mf">4.44</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="mf">3.89</span><span class="p">,</span> <span class="mf">4.05</span><span class="p">,</span> <span class="mf">4.05</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="mf">4.04</span><span class="p">,</span> <span class="mf">4.16</span><span class="p">,</span> <span class="mf">4.79</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="mf">3.76</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">,</span> <span class="mf">3.75</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight_above_ground_fifteen_years</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.760</span><span class="p">,</span> <span class="mf">0.821</span><span class="p">,</span> <span class="mf">0.928</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="mf">1.036</span><span class="p">,</span> <span class="mf">1.094</span><span class="p">,</span> <span class="mf">1.635</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="mf">0.912</span><span class="p">,</span> <span class="mf">1.398</span><span class="p">,</span> <span class="mf">1.197</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="mf">0.944</span><span class="p">,</span> <span class="mf">1.241</span><span class="p">,</span> <span class="mf">1.023</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="mf">1.084</span><span class="p">,</span> <span class="mf">1.151</span><span class="p">,</span> <span class="mf">1.381</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="mf">0.800</span><span class="p">,</span> <span class="mf">0.606</span><span class="p">,</span> <span class="mf">0.790</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maov</span> <span class="o">=</span> <span class="n">ManovaOneWay</span><span class="p">(</span><span class="n">trunk_girth_four_years</span><span class="p">,</span> <span class="n">ext_growth_four_years</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">trunk_girth_fifteen_years</span><span class="p">,</span> <span class="n">weight_above_ground_fifteen_years</span><span class="p">,</span>
<span class="gp">... </span>                      <span class="n">group</span><span class="o">=</span><span class="n">tree_number</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">maov</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Dependent variable num.&#39;: 4,</span>
<span class="go"> &#39;Group Means&#39;: array([[1.13      , 2.78733333, 3.75333333, 0.83633333],</span>
<span class="go">        [1.11      , 2.779     , 4.64666667, 1.255     ],</span>
<span class="go">        [1.04      , 2.49566667, 4.19333333, 1.169     ],</span>
<span class="go">        [1.13      , 2.73      , 3.99666667, 1.06933333],</span>
<span class="go">        [1.06666667, 2.389     , 4.33      , 1.20533333],</span>
<span class="go">        [0.97      , 1.95066667, 3.55      , 0.732     ]]),</span>
<span class="go"> &#39;Group Num. Observations&#39;: [3, 3, 3, 3, 3, 3],</span>
<span class="go"> &#39;Hotellings T^2&#39;: {&#39;Hotellings T^2 F-value&#39;: 13.787005512065765,</span>
<span class="go">  &#39;Hotellings T^2 Statistic&#39;: 5.743438210016407,</span>
<span class="go">  &#39;Hotellings T^2 p-value&#39;: 0.0001270639867039236},</span>
<span class="go"> &#39;Observation Total Means&#39;: array([1.07444444, 2.52194444, 4.07833333, 1.0445    ]),</span>
<span class="go"> &#39;Observations&#39;: {&#39;x means&#39;: array([1.07444444, 2.52194444, 4.07833333, 1.0445    ]),</span>
<span class="go">  &#39;x observations&#39;: 4},</span>
<span class="go"> &#39;Pillai Statistic&#39;: {&#39;Pillai F-value&#39;: 1.5309502494809615,</span>
<span class="go">  &#39;Pillai Statistic&#39;: 1.557842406866489,</span>
<span class="go">  &#39;Pillai p-value&#39;: 0.2522352735968698},</span>
<span class="go"> &#39;Roys Statistic&#39;: {&#39;Roys Statistic&#39;: 4.595030059073131,</span>
<span class="go">  &#39;Roys Statistic F-value&#39;: 93.73861320509187,</span>
<span class="go">  &#39;Roys Statistic p-value&#39;: 3.4357116041050517e-09},</span>
<span class="go"> &#39;Test Description&#39;: &#39;One-Way MANOVA&#39;,</span>
<span class="go"> &#39;Wilks Lambda&#39;: {&#39;Wilks Lambda&#39;: 0.07218625211663433,</span>
<span class="go">  &#39;Wilks Lambda F-value&#39;: 1.861776394897166,</span>
<span class="go">  &#39;Wilks Lambda p-value&#39;: 0.17516209487139456},</span>
<span class="go"> &#39;degrees of freedom&#39;: {&#39;Denominator Degrees of Freedom&#39;: 12,</span>
<span class="go">  &#39;Numerator Degrees of Freedom&#39;: 5.0}}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Andrews, D. F., and Herzberg, A. M. (1985), Data, New York: Springer-Verlag.</p>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<dl class="simple">
<dt>Rencher, A. (n.d.). Methods of Multivariate Analysis (2nd ed.).</dt><dd><p>Brigham Young University: John Wiley &amp; Sons, Inc.</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.contingency">
<span id="utilmy-stats-hypothesis-contingency-module"></span><h2>utilmy.stats.hypothesis.contingency module<a class="headerlink" href="#module-utilmy.stats.hypothesis.contingency" title="Permalink to this heading"></a></h2>
<p>Functions related to the analysis of contingency tables.</p>
<section id="contingency-tables">
<h3>Contingency Tables<a class="headerlink" href="#contingency-tables" title="Permalink to this heading"></a></h3>
</section>
<section id="other-functions">
<h3>Other Functions<a class="headerlink" href="#other-functions" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<dl class="simple">
<dt>Fagerland, M. W., Lydersen, S., &amp; Laake, P. (2013).</dt><dd><p>The McNemar test for binary matched-pairs data: Mid-p and asymptotic are better than exact conditional.
Retrieved April 14, 2018, from <a class="reference external" href="http://www.biomedcentral.com/1471-2288/13/91">http://www.biomedcentral.com/1471-2288/13/91</a></p>
</dd>
</dl>
<p>Gibbons, J. D., &amp; Chakraborti, S. (2010). Nonparametric statistical inference. London: Chapman &amp; Hall.</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Weisstein, Eric W. “Fisher’s Exact Test.” From MathWorld–A Wolfram Web Resource.</dt><dd><p><a class="reference external" href="http://mathworld.wolfram.com/FishersExactTest.html">http://mathworld.wolfram.com/FishersExactTest.html</a></p>
</dd>
<dt>Wikipedia contributors. (2017, August 8). Cochran’s Q test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 15:05, August 26, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Cochran%27s_Q_test&amp;oldid=794571272">https://en.wikipedia.org/w/index.php?title=Cochran%27s_Q_test&amp;oldid=794571272</a></p>
</dd>
<dt>Wikipedia contributors. (2018, May 20). Fisher’s exact test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:46, August 14, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Fisher%27s_exact_test&amp;oldid=842100719">https://en.wikipedia.org/w/index.php?title=Fisher%27s_exact_test&amp;oldid=842100719</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.contingency.</span></span><span class="sig-name descname"><span class="pre">ChiSquareContingency</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the Chi-square test of independence of variables in an r x c table.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observed</strong> (<em>array-like</em>) – One-dimensional array-like object (list, numpy array, pandas DataFrame or pandas Series) containing
the observed sample values.</p></li>
<li><p><strong>expected</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array-like object (list, numpy array, pandas DataFrame or pandas Series) containing
the observed sample values. If not passed, the expected frequencies are calculated using the
<code class="code docutils literal notranslate"><span class="pre">expected_frequencies</span></code> function.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True and degrees of freedom is equal to 1, Yates’s continuity correction is applied.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.observed">
<span class="sig-name descname"><span class="pre">observed</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.observed" title="Permalink to this definition"></a></dt>
<dd><p>The passed observation vector</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.expected">
<span class="sig-name descname"><span class="pre">expected</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.expected" title="Permalink to this definition"></a></dt>
<dd><p>The passed expected frequencies vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.continuity" title="Permalink to this definition"></a></dt>
<dd><p>If True and degrees of freedom is equal to 1, Yates’s continuity correction is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.degrees_freedom">
<span class="sig-name descname"><span class="pre">degrees_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.degrees_freedom" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom, calculated as <span class="math notranslate nohighlight">\(dof = (k - 1)(r - 1)\)</span> where <span class="math notranslate nohighlight">\(k\)</span> is the number of columns
and <span class="math notranslate nohighlight">\(r\)</span> is the number of rows in the contingency table.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of samples</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.chi_square">
<span class="sig-name descname"><span class="pre">chi_square</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.chi_square" title="Permalink to this definition"></a></dt>
<dd><p>The calculated chi-square value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The associated p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.cramers_v">
<span class="sig-name descname"><span class="pre">cramers_v</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.cramers_v" title="Permalink to this definition"></a></dt>
<dd><p>Cramer’s V measure of association (dependence) inherent in the data contingency table.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.contingency_coefficient">
<span class="sig-name descname"><span class="pre">contingency_coefficient</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.contingency_coefficient" title="Permalink to this definition"></a></dt>
<dd><p>Contingency coefficient measure of association.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.phi_coefficient">
<span class="sig-name descname"><span class="pre">phi_coefficient</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.phi_coefficient" title="Permalink to this definition"></a></dt>
<dd><p>Phi coefficient of association in the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.tschuprows_coefficient">
<span class="sig-name descname"><span class="pre">tschuprows_coefficient</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.tschuprows_coefficient" title="Permalink to this definition"></a></dt>
<dd><p>Tschuprows coefficient for measure of association in the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.ChiSquareContingency.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.ChiSquareContingency.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>A dictionary containing the relevant test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If the observed and expected arrays are not of the same shape (if an expected array is passed).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">observed</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">10</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">7.3</span><span class="p">,</span> <span class="mf">30.3</span><span class="p">,</span> <span class="mf">38.0</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">18.6</span><span class="p">,</span> <span class="mf">77.5</span><span class="p">,</span> <span class="mf">97.1</span><span class="p">,</span> <span class="mf">13.8</span><span class="p">],</span> <span class="p">[</span><span class="mf">9.1</span><span class="p">,</span> <span class="mf">38.2</span><span class="p">,</span> <span class="mf">47.9</span><span class="p">,</span> <span class="mf">6.8</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ChiSquareContingency</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;association measures&#39;: {&#39;C&#39;: 0.38790213046235816,</span>
<span class="go"> &#39;Cramers V&#39;: 0.2975893000268341,</span>
<span class="go"> &#39;phi-coefficient&#39;: 0.4208548241150648},</span>
<span class="go"> &#39;chi-square&#39;: 69.07632536255964,</span>
<span class="go"> &#39;continuity&#39;: True,</span>
<span class="go"> &#39;degrees of freedom&#39;: 6,</span>
<span class="go"> &#39;p-value&#39;: 6.323684774702373e-13}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span> <span class="o">=</span> <span class="n">ChiSquareContingency</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;association measures&#39;: {&#39;C&#39;: 0.3886475108354606,</span>
<span class="go"> &#39;Cramers V&#39;: 0.29826276547053077,</span>
<span class="go"> &#39;phi-coefficient&#39;: 0.4218072480793303},</span>
<span class="go"> &#39;chi-square&#39;: 69.3893282675805,</span>
<span class="go"> &#39;continuity&#39;: True,</span>
<span class="go"> &#39;degrees of freedom&#39;: 6,</span>
<span class="go"> &#39;p-value&#39;: 5.455268702303084e-13}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c2</span><span class="o">.</span><span class="n">expected</span>
<span class="go">array([[ 7.26923077, 30.32307692, 38.00769231,  5.4       ],</span>
<span class="go">       [18.57692308, 77.49230769, 97.13076923, 13.8       ],</span>
<span class="go">       [ 9.15384615, 38.18461538, 47.86153846,  6.8       ]])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The chi-square test is often used to assess the significance (if any) of the differences among <span class="math notranslate nohighlight">\(k\)</span> different
groups. The null hypothesis of the test, <span class="math notranslate nohighlight">\(H_0\)</span> is typically that there is no significant difference between
two or more groups.</p>
<p>The chi-square test statistic, denoted <span class="math notranslate nohighlight">\(\chi^2\)</span>, is defined as the following:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum^r_{i=1} \sum^k_{j=1} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(O_{ij}\)</span> is the ith observed frequency in the jth group and <span class="math notranslate nohighlight">\(E_{ij}\)</span> is the corresponding
expected frequency. The degrees of freedom is calculated as <span class="math notranslate nohighlight">\(dof = (k - 1)(r - 1)\)</span> where <span class="math notranslate nohighlight">\(k\)</span> is
the number of columns and <span class="math notranslate nohighlight">\(r\)</span> is the number of rows in the contingency table. In the case of a 2x2
contingency table, Yates’s continuity correction may be applied to reduce the error in approximation of using
the chi-square distribution to calculate the test statistics. The continuity correction changes the
computation of <span class="math notranslate nohighlight">\(\chi^2\)</span> to the following:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum^r_{i=1} \sum^k_{j=1} \frac{(|O_{ij} - E_{ij}| - 0.5)^2}{E_{ij}}\]</div>
<p>In addition to the test statistics, several measures of association are also provided. The first is the
phi coefficient, defined as:</p>
<div class="math notranslate nohighlight">
\[\phi = \pm \sqrt{\frac{\chi^2}{N}}\]</div>
<p>The contingency coefficient, denoted as <span class="math notranslate nohighlight">\(C\)</span>, is defined as:</p>
<div class="math notranslate nohighlight">
\[C = \sqrt{\frac{\chi^2}{N + \chi^2}}\]</div>
<p>Cramer’s V is defined as:</p>
<div class="math notranslate nohighlight">
\[V = \sqrt{\frac{\chi^2}{N(k-1}}\]</div>
<p>Lastly, Tschuprow’s T is defined as:</p>
<div class="math notranslate nohighlight">
\[T = \sqrt{\frac{\phi^2}{\sqrt{(r - 1)(c - 1)}}} = \sqrt{\frac{\frac{\chi^2}{n}}{\sqrt{(r - 1)(c - 1)}}}\]</div>
<p class="rubric">References</p>
<p>Gibbons, J. D., &amp; Chakraborti, S. (2010). Nonparametric statistical inference. London: Chapman &amp; Hall.</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, August 15). Contingency table. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:08, August 28, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Contingency_table&amp;oldid=854973657">https://en.wikipedia.org/w/index.php?title=Contingency_table&amp;oldid=854973657</a></p>
</dd>
<dt>Wikipedia contributors. (2020, April 14). Cramér’s V. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 13:41, August 12, 2020,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Cram%C3%A9r%27s_V&amp;oldid=950837942">https://en.wikipedia.org/w/index.php?title=Cram%C3%A9r%27s_V&amp;oldid=950837942</a></p>
</dd>
<dt>Wikipedia contributors. (2020, August 9). Phi coefficient. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 13:40, August 12, 2020,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Phi_coefficient&amp;oldid=971906217">https://en.wikipedia.org/w/index.php?title=Phi_coefficient&amp;oldid=971906217</a></p>
</dd>
<dt>Wikipedia contributors. (2019, January 14). Tschuprow’s T. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 13:40, August 12, 2020,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Tschuprow%27s_T&amp;oldid=878279875">https://en.wikipedia.org/w/index.php?title=Tschuprow%27s_T&amp;oldid=878279875</a></p>
</dd>
<dt>Wikipedia contributors. (2017, October 20). Yates’s correction for continuity. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:23, September 1, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Yates%27s_correction_for_continuity&amp;oldid=806197753">https://en.wikipedia.org/w/index.php?title=Yates%27s_correction_for_continuity&amp;oldid=806197753</a></p>
</dd>
</dl>
<p><a class="reference external" href="https://www.empirical-methods.hslu.ch/decisiontree/relationship/chi-square-contingency/">https://www.empirical-methods.hslu.ch/decisiontree/relationship/chi-square-contingency/</a></p>
<p><a class="reference external" href="http://stats.lse.ac.uk/bergsma/pdf/cramerV3.pdf">http://stats.lse.ac.uk/bergsma/pdf/cramerV3.pdf</a></p>
<p><a class="reference external" href="http://uregina.ca/~gingrich/ch11a.pdf">http://uregina.ca/~gingrich/ch11a.pdf</a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.CochranQ">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.contingency.</span></span><span class="sig-name descname"><span class="pre">CochranQ</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posthoc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.CochranQ" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Cochran’s Q test</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample1</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample must be of the same length.</p></li>
<li><p><strong>sample2</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample must be of the same length.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample must be of the same length.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.CochranQ.degrees_freedom">
<span class="sig-name descname"><span class="pre">degrees_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.CochranQ.degrees_freedom" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom is calculated as the number of samples minus 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.CochranQ.q_statistic">
<span class="sig-name descname"><span class="pre">q_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.CochranQ.q_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The calculated Q test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.CochranQ.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.CochranQ.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The p-value of the test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.CochranQ.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.CochranQ.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the relevant test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">r1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cq</span> <span class="o">=</span> <span class="n">CochranQ</span><span class="p">(</span><span class="n">r1</span><span class="p">,</span> <span class="n">r2</span><span class="p">,</span> <span class="n">r3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cq</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;degrees of freedom&#39;: 2,</span>
<span class="go"> &#39;p-value&#39;: 0.00024036947641951404,</span>
<span class="go"> &#39;q-statistic&#39;: 16.666666666666668}</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Cochran’s Q test is an extension of McNemar’s test for two-way randomized block design experiments in which the
response variable is binary (can only take one of two possible outcomes).</p>
<p>Cochran’s Q test is performed by arranging the group sample observation vectors into a two-way table consisting
of <span class="math notranslate nohighlight">\(n\)</span> rows and <span class="math notranslate nohighlight">\(k\)</span> columns, where the binary responses are tallied as 1s (“successes”) and 0s
(“failures”). The <span class="math notranslate nohighlight">\(Q\)</span> test statistic can then be calculated per the following definition:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{(k - 1) \bigg[k \sum^k_{j=1} G_j^2 - \Big(\sum^k_{j=1} G_j \Big)^2 \bigg]}{k \sum^n_{i=1} L_i - \sum^n_{i=1} L_i^2\]</div>
<p>Where <span class="math notranslate nohighlight">\(G_j\)</span> is the sum of 1s (“successess”) in the jth sample and <span class="math notranslate nohighlight">\(L_i\)</span> is the sum of 1s (“successes”)
in the ith row.</p>
<p>The distribution of <span class="math notranslate nohighlight">\(Q\)</span> is approximated by the chi-square distribution with <span class="math notranslate nohighlight">\(df = k - 1\)</span>.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
<p><a class="reference external" href="https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Cochrans_Q_Test.pdf">https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Cochrans_Q_Test.pdf</a></p>
<dl class="simple">
<dt>Wikipedia contributors. (2017, August 8). Cochran’s Q test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 15:05, August 26, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Cochran%27s_Q_test&amp;oldid=794571272">https://en.wikipedia.org/w/index.php?title=Cochran%27s_Q_test&amp;oldid=794571272</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.contingency.</span></span><span class="sig-name descname"><span class="pre">McNemarTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Computes the McNemar Test for two related samples in a 2x2 contingency table.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>table</strong> (<em>array-like</em>) – Array-like object representing a 2x2 paired contingency table.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>True</em>) – Use continuity-corrected version of McNemar’s chi-square test statistic as proposed by Edwards. Defaults to
False as simulations performed by Fagerland (et al.) have shown the continuity-corrected version of
McNemar’s test to be overly conservative compared to the original McNemar test statistic.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.table">
<span class="sig-name descname"><span class="pre">table</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.table" title="Permalink to this definition"></a></dt>
<dd><p>Array-like object representing a 2x2 paired contingency table.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.continuity" title="Permalink to this definition"></a></dt>
<dd><p>Apply continuity-corrected version of McNemar’s chi-square statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.mcnemar_x2_statistic">
<span class="sig-name descname"><span class="pre">mcnemar_x2_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.mcnemar_x2_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The McNemar chi-square test statistic. If the parameter continuity is True, this value will be the
continuity corrected version of the test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.z_asymptotic_statistic">
<span class="sig-name descname"><span class="pre">z_asymptotic_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.z_asymptotic_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The test statistic of the asymptotic McNemar test. If the continuity parameter is True, the continuity
corrected version of the asymptotic McNemar test as proposed by Edwards will be performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.mcnemar_p_value">
<span class="sig-name descname"><span class="pre">mcnemar_p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.mcnemar_p_value" title="Permalink to this definition"></a></dt>
<dd><p>The p-value of the McNemar test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.exact_p_value">
<span class="sig-name descname"><span class="pre">exact_p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.exact_p_value" title="Permalink to this definition"></a></dt>
<dd><p>The exact p-value of the McNemar test. The exact p-value is generally more accurate when the sample sizes
of the data is small.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.mid_p_value">
<span class="sig-name descname"><span class="pre">mid_p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.mid_p_value" title="Permalink to this definition"></a></dt>
<dd><p>The mid p-value of the McNemar test.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.McNemarTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.McNemarTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing relevant returned test statistics and entered parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – raised if the passed table has more than 2 columns or rows.</p></li>
<li><p><strong>ValueError</strong> – raised if the table contains negative values.</p></li>
<li><p><strong>ValueError</strong> – raised when table cell n_12 and n_21 are both 0.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>McNemar’s test is a test for paired data as in the case of 2x2 contingency tables with a dichotomous trait. The
McNemar test determines if the row and column marginal frequencies are equal, which is also known as marginal
homogeneity. For example, McNemar’s test can be used when comparing postive/negative results for two tests,
surgery vs. non-surgery in siblings and non-siblings, and other instances. The test was developed by Quinn
McNemar in 1947.</p>
<p>Consider a 2x2 contingency table with four cells where each cell and its position is denoted <span class="math notranslate nohighlight">\(n_{rc}\)</span>
where <span class="math notranslate nohighlight">\(r = row\)</span> and <span class="math notranslate nohighlight">\(c = column\)</span>. The appropriate null hypothesis states the marginal probabilities
of each outcome are the same.</p>
<div class="math notranslate nohighlight">
\[n_{11} + n_{12} = n_{11} + n_{21}
n_{12} + n_{22} = n_{21} + n_{22}\]</div>
<p>The above simplifies to <span class="math notranslate nohighlight">\(n_{12} = n_{21}\)</span>. Therefore the null hypothesis can be stated more simply as:</p>
<div class="math notranslate nohighlight">
\[H_0: n_{12} = n_{21}\]</div>
<p>The null hypothesis can also be stated as the off-diagonal probabilities of the 2x2 contingency table are the
same, with the alternative hypothesis stating the probabilities are not equal. To test this hypothesis, the
McNemar test can be used, which is defined as:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \frac{(n_{12} - n_{21})^2}{n_{12} + n_{21}}\]</div>
<p>This is also known as the asymptotic McNemar test. With an adequate number of samples, the McNemar test
statistic, <span class="math notranslate nohighlight">\(\chi^2\)</span> has a chi-square distribution with one degree of freedom.</p>
<p>Continuity correction can be applied to the asymptotic McNemar test as proposed by Edwards [1]. The continuity
corrected version of the asymptotic McNemar test approximates the McNemar exact conditional test which is
described below. The asymptotic McNemar test with continuity correction is defined as:</p>
<div class="math notranslate nohighlight">
\[z = \frac{|n_{12} - n_{21}| - 1}{\sqrt{n_{12} + n_{21}}}\]</div>
<p>Fagerland et al [1] recommend the asymptotic McNemar test in most cases. The continuity corrected version is
not recommended as it has been shown to be overly conservative.</p>
<p>There also exists several variations of the original McNemar test that may have better performance in specific
cases.</p>
<p>Variations of the McNemar Test</p>
<p>When the sample sizes of cells <span class="math notranslate nohighlight">\(n_{12}\)</span> or <cite>n_{21}</cite> are small (small being subjective, but generally
assumed to be &lt; 30), an exact binomial test can be used to calculate McNemar’s test. This is known as the
McNemar exact conditional test. The one-sided test is defined as the following:</p>
<div class="math notranslate nohighlight">
\[p_{exact} = \sum^n_{i=n_{12}} \binom{n}{i} \frac{1}{2}^i (1 - \frac{1}{2})^{n - i}\]</div>
<p>The two-sided p-value can also be easily found by multiplying <span class="math notranslate nohighlight">\(p_{exact}\)</span> by <span class="math notranslate nohighlight">\(2\)</span>.</p>
<p>Fagerland et al[2] do not recommend the exact conditional test as it was found to have least the performance
Type 1 error and power of other McNemar test variations.</p>
<p>The McNemar mid-p test is calculated by subtracting half the point probability of the observed <span class="math notranslate nohighlight">\(n_{12}\)</span>
cell of the contingency table from the one-sided <span class="math notranslate nohighlight">\(p_{exact}\)</span> value using the equation above. The
resulting p-value is then doubled to obtain the two-sided mid-p-value. Stated more formally, the McNemar
mid-p test is defined as:</p>
<div class="math notranslate nohighlight">
\[p_{mid} = 2 \large(\sum^n_{i=b} \binom{n}{i} \frac{1}{2}^i (1 - \frac{1}{2})^{n - i} -
\frac{1}{2} \binom{n}{b} \frac{1}{2}^b (1 - \frac{1}{2}^{n -b } \large)\]</div>
<p>According to Fagerland et al [2], the McNemar mid-p test has much higher performance compared to the
McNemar exact conditional test and is considerable alternative to the McNemar exact unconditional test which
is significantly more complex.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">McNemarTest</span><span class="p">([[</span><span class="mi">59</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">80</span><span class="p">]],</span> <span class="n">continuity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Asymptotic z-statistic&#39;: 2.1320071635561044,</span>
<span class="go"> &#39;Exact p-value&#39;: 0.052478790283203125,</span>
<span class="go"> &#39;McNemar p-value&#39;: 0.03300625766123255,</span>
<span class="go"> &#39;McNemar x2-statistic&#39;: 4.545454545454546,</span>
<span class="go"> &#39;Mid p-value&#39;: 0.034689664840698256,</span>
<span class="go"> &#39;N&#39;: 161,</span>
<span class="go"> &#39;continuity&#39;: False}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m2</span> <span class="o">=</span> <span class="n">McNemarTest</span><span class="p">([[</span><span class="mi">59</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">80</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m2</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Asymptotic z-statistic&#39;: 1.9188064472004938,</span>
<span class="go"> &#39;Exact p-value&#39;: 0.052478790283203125,</span>
<span class="go"> &#39;McNemar p-value&#39;: 0.055008833629265896,</span>
<span class="go"> &#39;McNemar x2-statistic&#39;: 3.6818181818181817,</span>
<span class="go"> &#39;Mid p-value&#39;: 0.034689664840698256,</span>
<span class="go"> &#39;N&#39;: 161,</span>
<span class="go"> &#39;continuity&#39;: True}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Edwards AL: Note on the “correction for continuity” in testing the</dt><dd><p>significance of the difference between correlated proportions.
Psychometrika 1948, 13(3):185–187.</p>
</dd>
<dt>Fagerland, M. W., Lydersen, S., &amp; Laake, P. (2013).</dt><dd><p>The McNemar test for binary matched-pairs data: Mid-p and asymptotic are better than exact conditional.
Retrieved April 14, 2018, from <a class="reference external" href="http://www.biomedcentral.com/1471-2288/13/91">http://www.biomedcentral.com/1471-2288/13/91</a></p>
</dd>
</dl>
<p>Gibbons, J. D., &amp; Chakraborti, S. (2010). Nonparametric statistical inference. London: Chapman &amp; Hall.</p>
<dl class="simple">
<dt>Wikipedia contributors. (2018, April 29). McNemar’s test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:24, August 15, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=McNemar%27s_test&amp;oldid=838855782">https://en.wikipedia.org/w/index.php?title=McNemar%27s_test&amp;oldid=838855782</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.expected_frequencies">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.contingency.</span></span><span class="sig-name descname"><span class="pre">expected_frequencies</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observed</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.expected_frequencies" title="Permalink to this definition"></a></dt>
<dd><p>Computes the expected frequencies of a given contingency table with observed frequencies.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>observed</strong> (<em>array-like</em>) – A one or two-dimensional array object.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – the dimension of the <code class="code docutils literal notranslate"><span class="pre">observed</span></code> parameter cannot be greater than two.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>exp_freq</strong> – Array of the expected frequencies</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>array-like</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">expected_frequencies</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="go">array([[13.33333333, 13.33333333, 13.33333333],</span>
<span class="go">       [16.66666667, 16.66666667, 16.66666667]])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The expected frequency, here denoted as <span class="math notranslate nohighlight">\(E_{cr}\)</span>, where <span class="math notranslate nohighlight">\(c\)</span> is the column index and <span class="math notranslate nohighlight">\(r\)</span> is the
row index. Stated more formally, the expected frequency is defined as:</p>
<div class="math notranslate nohighlight">
\[E_{cr} = \frac{(\sum^{n_r}_{i=0} r_i)(\sum^{n_c}_{i=0} c_i)}{n}\]</div>
<p>Where <span class="math notranslate nohighlight">\(n\)</span> is the total sample size and <span class="math notranslate nohighlight">\(n_c, n_r\)</span> are the number of cells in row and column,
respectively. The expected frequency is calculated for each ‘cell’ in the given array.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Stover, Christopher. “Contingency Table.”</dt><dd><p>From MathWorld–A Wolfram Web Resource, created by Eric W. Weisstein.
<a class="reference external" href="http://mathworld.wolfram.com/ContingencyTable.html">http://mathworld.wolfram.com/ContingencyTable.html</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.contingency.table_margins">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.contingency.</span></span><span class="sig-name descname"><span class="pre">table_margins</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.contingency.table_margins" title="Permalink to this definition"></a></dt>
<dd><p>Computes the marginal sums of a given array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>table</strong> (<em>array-like</em>) – A one or two-dimensional array-like object.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – The given array must be either a one or two-dimensional array.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>r, c</strong> – A tuple containing the total sums of the table rows and the total sums of the table columns.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">table_margins</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
</pre></div>
</div>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.critical">
<span id="utilmy-stats-hypothesis-critical-module"></span><h2>utilmy.stats.hypothesis.critical module<a class="headerlink" href="#module-utilmy.stats.hypothesis.critical" title="Permalink to this heading"></a></h2>
<p>Functions for finding the critical value of a particular test statistic given the necessary parameters. Critical
value tables implemented as dictionaries are also provided.</p>
<section id="critical-value-lookup-functions">
<h3>Critical Value Lookup Functions<a class="headerlink" href="#critical-value-lookup-functions" title="Permalink to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.critical.chi_square_critical_value">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.critical.</span></span><span class="sig-name descname"><span class="pre">chi_square_critical_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dof</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.critical.chi_square_critical_value" title="Permalink to this definition"></a></dt>
<dd><p>function chi_square_critical_value.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">alpha</span><span class="p">:</span>
    <span class="n">dof</span><span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.critical.d_critical_value">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.critical.</span></span><span class="sig-name descname"><span class="pre">d_critical_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.critical.d_critical_value" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.critical.r_critical_value">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.critical.</span></span><span class="sig-name descname"><span class="pre">r_critical_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.critical.r_critical_value" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.critical.u_critical_value">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.critical.</span></span><span class="sig-name descname"><span class="pre">u_critical_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.critical.u_critical_value" title="Permalink to this definition"></a></dt>
<dd><p>Finds the Mann-Whitney <span class="math notranslate nohighlight">\(U\)</span>-statistic critical value for small sample sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – Number of observations in first sample group.</p></li>
<li><p><strong>m</strong> (<em>int</em>) – Number of observations in second sample group.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>{0.10</em><em>, </em><em>0.05</em><em>, </em><em>0.025</em><em>, </em><em>0.01}</em>) – Alpha-level. Must be one of 0.10, 0.05, 0.025, or 0.01.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>u_crit</strong> – The Mann-Whitney U-statistic critical value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If parameters <code class="code docutils literal notranslate"><span class="pre">n</span></code> or <code class="code docutils literal notranslate"><span class="pre">m</span></code> are greater than 20.</p></li>
<li><p><strong>ValueError</strong> – If parameter <code class="code docutils literal notranslate"><span class="pre">alpha</span></code> is not one of 0.10, 0.05, 0.025, or 0.01.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">u_critical_value</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="go">24</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u_critical_value</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">)</span>
<span class="go">19</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.critical.w_critical_value">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.critical.</span></span><span class="sig-name descname"><span class="pre">w_critical_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternative</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.critical.w_critical_value" title="Permalink to this definition"></a></dt>
<dd><p>Finds the <span class="math notranslate nohighlight">\(W\)</span>-statistic critical value given the input parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n</strong> (<em>int</em>) – The number of sample observations. Critical values are only given for <span class="math notranslate nohighlight">\(n \geq 30\)</span>.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>{'one-tail': {0.05</em><em>, </em><em>0.025</em><em>, </em><em>0.01</em><em>, </em><em>0.005}</em><em>, </em><em>'two-tail': {0.10</em><em>, </em><em>0.05</em><em>, </em><em>0.02</em><em>, </em><em>0.01}}</em>) – Given alpha level.</p></li>
<li><p><strong>alternative</strong> (<em>str</em>) – Alternative hypothesis. Must be one of ‘one-tail’ or ‘two-tail’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>w_crit</strong> – The <span class="math notranslate nohighlight">\(W\)</span>-statistic critical value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – If parameter <code class="code docutils literal notranslate"><span class="pre">n</span></code> is greater than 30.</p></li>
<li><p><strong>ValueError</strong> – If parameter <code class="code docutils literal notranslate"><span class="pre">alpha</span></code> is not one of 0.05 or 0.01.</p></li>
<li><p><strong>ValueError</strong> – If parameter <code class="code docutils literal notranslate"><span class="pre">alternative</span></code> is not one of ‘one-tail’ or ‘two-tail’.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w_critical_value</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;one-tail&#39;</span><span class="p">)</span>
<span class="go">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w_critical_value</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;two-tail&#39;</span><span class="p">)</span>
<span class="go">5</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.descriptive">
<span id="utilmy-stats-hypothesis-descriptive-module"></span><h2>utilmy.stats.hypothesis.descriptive module<a class="headerlink" href="#module-utilmy.stats.hypothesis.descriptive" title="Permalink to this heading"></a></h2>
<p>Functions for computing correlation and covariance of two variables or a data matrix. Several different
algorithms for the computation of covariance and variance are provided.</p>
<section id="correlation">
<h3>Correlation<a class="headerlink" href="#correlation" title="Permalink to this heading"></a></h3>
</section>
<section id="variance-and-covariance">
<h3>Variance and Covariance<a class="headerlink" href="#variance-and-covariance" title="Permalink to this heading"></a></h3>
</section>
<section id="id1">
<h3>Other Functions<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<dl class="simple">
<dt>Algorithms for calculating variance. (2017, June 24). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Algorithms_for_calculating_variance&amp;oldid=787336827">https://en.wikipedia.org/w/index.php?title=Algorithms_for_calculating_variance&amp;oldid=787336827</a></p>
</dd>
<dt>Chan, T., Golub, G., &amp; LeVeque, R. (1983). Algorithms for Computing the Sample Variance:</dt><dd><p>Analysis and Recommendations. The American Statistician, 37(3), 242-247.
<a class="reference external" href="http://dx.doi.org/10.1080/00031305.1983.10483115">http://dx.doi.org/10.1080/00031305.1983.10483115</a></p>
</dd>
<dt>Chan, T., Golub, G., &amp; LeVeque, R. (1982). Updating Formulae and a Pairwise Algorithm for</dt><dd><p>Computing Sample Variances. COMPSTAT 1982 5Th Symposium Held At Toulouse 1982, 30-41.
<a class="reference external" href="http://dx.doi.org/10.1007/978-3-642-51461-6_3">http://dx.doi.org/10.1007/978-3-642-51461-6_3</a></p>
</dd>
<dt>Pearson correlation coefficient. (2017, July 12). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Pearson_correlation_coefficient&amp;oldid=790217169">https://en.wikipedia.org/w/index.php?title=Pearson_correlation_coefficient&amp;oldid=790217169</a></p>
</dd>
<dt>Press, W., Teukolsky, S., Vetterling, W., &amp; Flannery, B. (2007). Numerical recipes (3rd ed.).</dt><dd><p>Cambridge: Cambridge University Press.</p>
</dd>
<dt>Rencher, A. (n.d.). Methods of Multivariate Analysis (2nd ed.).</dt><dd><p>Brigham Young University: John Wiley &amp; Sons, Inc.</p>
</dd>
<dt>Shift-invariant system. (2017, June 30). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Shift-invariant_system&amp;oldid=788228439">https://en.wikipedia.org/w/index.php?title=Shift-invariant_system&amp;oldid=788228439</a></p>
</dd>
<dt>Spearman’s rank correlation coefficient. (2017, June 24). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Spearman%27s_rank_correlation_coefficient&amp;oldid=787350680">https://en.wikipedia.org/w/index.php?title=Spearman%27s_rank_correlation_coefficient&amp;oldid=787350680</a></p>
</dd>
<dt>Weisstein, Eric W. “Covariance Matrix.” From MathWorld–A Wolfram Web Resource.</dt><dd><p><a class="reference external" href="http://mathworld.wolfram.com/CovarianceMatrix.html">http://mathworld.wolfram.com/CovarianceMatrix.html</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">SimulateCorrelationMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">power</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.constant">
<span class="sig-name descname"><span class="pre">constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.constant" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.hub">
<span class="sig-name descname"><span class="pre">hub</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.hub" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.toepz">
<span class="sig-name descname"><span class="pre">toepz</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.SimulateCorrelationMatrix.toepz" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.add_noise">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">add_noise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.add_noise" title="Permalink to this definition"></a></dt>
<dd><p>function add_noise.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">cor</span><span class="p">:</span>
    <span class="n">epsilon</span><span class="p">:</span>
    <span class="n">m</span><span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.covar">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">covar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.covar" title="Permalink to this definition"></a></dt>
<dd><p>function covar.
Doc:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Args</span><span class="p">:</span>
    <span class="n">x</span><span class="p">:</span>
    <span class="n">y</span><span class="p">:</span>
    <span class="n">method</span><span class="p">:</span>
<span class="n">Returns</span><span class="p">:</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.kurtosis">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">kurtosis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.kurtosis" title="Permalink to this definition"></a></dt>
<dd><p>Computes the kurtosis of an array along a specified axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – One or two-dimensional array of data.</p></li>
<li><p><strong>axis</strong> (<em>int {0</em><em>, </em><em>1}</em>) – Specifies which axis of the data to compute the kurtosis. The default is 0 (column-wise in a 2d-array). Cannot
be greater than 1.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – Raised if <code class="code docutils literal notranslate"><span class="pre">x</span></code> array is not a one or two-dimensional array.</p></li>
<li><p><strong>ValueError</strong> – Raised if the <code class="code docutils literal notranslate"><span class="pre">axis</span></code> parameter is greater than 1.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>k</strong> – If x is one-dimensional, the kurtosis of the data is returned as a float. If x is two-dimensional, the
calculated kurtosis along the specified axis is returned as a numpy array of floats.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float or array-like</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosis</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">-1.4515532544378704</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosis</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([-1.45155325, -1.32230624])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Kurtosis, also known as the fourth moment, is non-dimensionl and measures the comparative ‘flatness’ or ‘peak’
of a given distribution to a normal distribution. Leptokurtic distributions have a positive kurtosis while
platykurtic distributions have a negative kurtosis value. Though less commmon, distributions with a zero
kurtosis value are called mesokurtic.</p>
<p>Kurtosis is typically defined as:</p>
<div class="math notranslate nohighlight">
\[Kurt(x_0, \cdots, x_{n-1}) = \large{\frac{1}{n} \sum^{n-1}_{j=0} \large[\frac{x_j - \bar{x}}{\sigma}
\large]^4 \large} - 3\]</div>
<p>The <span class="math notranslate nohighlight">\(-3\)</span> term is applied so a normal distribution will have a 0 kurtosis value (mesokurtic).</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Press, W., Teukolsky, S., Vetterling, W., &amp; Flannery, B. (2007). Numerical recipes (3rd ed.).</dt><dd><p>Cambridge: Cambridge University Press.</p>
</dd>
<dt>Wikipedia contributors. (2018, August 28). Kurtosis. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:19, September 3, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Kurtosis&amp;oldid=856893890">https://en.wikipedia.org/w/index.php?title=Kurtosis&amp;oldid=856893890</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.mean_absolute_deviation">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">mean_absolute_deviation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.mean_absolute_deviation" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the mean absolute deviation of a data array along a specified axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – One or two-dimensional array of data.</p></li>
<li><p><strong>axis</strong> (<em>{0</em><em>, </em><em>1} int</em>) – Specifies which axis of the data to compute the mean absolute deviation. The default is 0
(column-wise in a 2d-array).</p></li>
<li><p><strong>mean</strong> (<em>bool</em>) – If False (default), the sample median is used to compute the mean absolute deviation. If True, the sample
mean is used.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – Raised if <code class="code docutils literal notranslate"><span class="pre">x</span></code> array is not a one or two-dimensional array.</p></li>
<li><p><strong>ValueError</strong> – Raised if the <code class="code docutils literal notranslate"><span class="pre">axis</span></code> parameter is greater than 1.</p></li>
<li><p><strong>TypeError</strong> – Raised if the <code class="code docutils literal notranslate"><span class="pre">mean</span></code> parameter is not boolean.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>m</strong> – If x is one-dimensional, the mean absolute deviation of the data is returned as a float. If x is
two-dimensional, the calculated mean absolute deviation along the specified axis is returned as a numpy
array of floats.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float or array-like</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p class="rubric">Notes</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Press, W., Teukolsky, S., Vetterling, W., &amp; Flannery, B. (2007). Numerical recipes (3rd ed.).</dt><dd><p>Cambridge: Cambridge University Press.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.pearson">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">pearson</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.pearson" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Pearson product-moment correlation coefficients of the given variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors. The input is concatenated with
the parameter y if given.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>optional</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Pearson product-moment correlation coefficient matrix of the inputted variables.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Pearson’s product-moment correlation coefficient is the covariance of two random variables
divided by the product of their standard deviations and is typically represented by
<span class="math notranslate nohighlight">\(\rho\)</span>:</p>
<div class="math notranslate nohighlight">
\[\rho_{x, y} = \frac{cov(X, Y)}{\sigma_X \sigma_Y}\]</div>
<p>The correlation matrix <span class="math notranslate nohighlight">\(C\)</span> and the covariance matrix <span class="math notranslate nohighlight">\(R\)</span> have the following
relationship.</p>
<div class="math notranslate nohighlight">
\[R_{ij} = \frac{C_{ij}}{\sqrt{C_{ii} * C_{jj}}}\]</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pearson</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="go">array([[ 1.        , -0.47140452, -0.24618298, -0.45732956],</span>
<span class="go">   [-0.47140452,  1.        ,  0.05802589, -0.29643243],</span>
<span class="go">   [-0.24618298,  0.05802589,  1.        ,  0.80218063],</span>
<span class="go">   [-0.45732956, -0.29643243,  0.80218063,  1.        ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pearson</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
<span class="go">array([[ 1.        , -0.47140452, -0.24618298, -0.45732956],</span>
<span class="go">   [-0.47140452,  1.        ,  0.05802589, -0.29643243],</span>
<span class="go">   [-0.24618298,  0.05802589,  1.        ,  0.80218063],</span>
<span class="go">   [-0.45732956, -0.29643243,  0.80218063,  1.        ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pearson</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([[ 1.        ,  0.05802589],</span>
<span class="go">   [ 0.05802589,  1.        ]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#utilmy.stats.hypothesis.descriptive.spearman" title="utilmy.stats.hypothesis.descriptive.spearman"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spearman</span></code></a></dt><dd><p>function for computing the Spearman rank correlation of two vectors or a data matrix.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Pearson correlation coefficient. (2017, July 12). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Pearson_correlation_coefficient&amp;oldid=790217169">https://en.wikipedia.org/w/index.php?title=Pearson_correlation_coefficient&amp;oldid=790217169</a></p>
</dd>
<dt>Rencher, A. (n.d.). Methods of Multivariate Analysis (2nd ed.).</dt><dd><p>Brigham Young University: John Wiley &amp; Sons, Inc.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.skewness">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">skewness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.skewness" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the skewness of a given array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – One or two-dimensional array of data.</p></li>
<li><p><strong>axis</strong> (<em>int {0</em><em>, </em><em>1}</em>) – Specifies which axis of the data to compute the skewness. The default is 0 (column-wise in a 2d-array). Cannot
be greater than 1.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – Raised if <code class="code docutils literal notranslate"><span class="pre">x</span></code> array is not a one or two-dimensional array.</p></li>
<li><p><strong>ValueError</strong> – Raised if the <code class="code docutils literal notranslate"><span class="pre">axis</span></code> parameter is greater than 1.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>s</strong> – If the given array is one-dimensional, a float value is returned. If two dimensional, an array is returned
with the calculated skewness across the given axis.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>float or array-like</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">skewness</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">-0.028285981029545847</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewness</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([-0.02828598, -0.03331004])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The skewness, also known as the third moment, measures the degree of asymmetry of the given distribution around
its mean. Skewness is typically defined as:</p>
<div class="math notranslate nohighlight">
\[Skew (x_0, \cdots, x_{n-1}) = \frac{1}{n} \sum^{n-1}_{j=0} \large[\frac{x_j - \bar{x}}{\sigma} \large]^3\]</div>
<p>A positive skewness signifies an asymmetric distribution with a tail extending in the positive direction of x,
whereas a negative skewness denotes an asymmetric distribution with the tail extending towards negative x.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Press, W., Teukolsky, S., Vetterling, W., &amp; Flannery, B. (2007). Numerical recipes (3rd ed.).</dt><dd><p>Cambridge: Cambridge University Press.</p>
</dd>
<dt>Wikipedia contributors. (2018, August 13). Skewness. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:18, September 3, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Skewness&amp;oldid=854777849">https://en.wikipedia.org/w/index.php?title=Skewness&amp;oldid=854777849</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.spearman">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">spearman</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.spearman" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Spearman correlation coefficients of the given variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors. The input is concatenated with
the parameter y if given.</p></li>
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>optional</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The correlation coefficient matrix of the inputted variables.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Spearman’s <span class="math notranslate nohighlight">\(\rho\)</span>, often denoted <span class="math notranslate nohighlight">\(r_s\)</span> is a nonparametric measure of correlation.
While Pearson’s product-moment correlation coefficient represents the linear relationship between
two variables, Spearman’s correlation measures the monotonicity of two variables. Put more simply,
Spearman’s correlation is Pearson’s correlation performed on ranked variables.</p>
<p>Two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> and their respective observation vectors
<span class="math notranslate nohighlight">\(x_1, x_2, \cdots, x_n\)</span> and <span class="math notranslate nohighlight">\(y_1, y_2, \cdots, y_n\)</span> are converted to ranked variables
(identical values are averaged), often denoted <span class="math notranslate nohighlight">\(rg_X\)</span> and <span class="math notranslate nohighlight">\(rg_Y\)</span>, and the correlation
<span class="math notranslate nohighlight">\(r_s\)</span> is computed as:</p>
<div class="math notranslate nohighlight">
\[r_s = \rho_{rg_X, rg_Y} = \frac{cov(rg_X, rg_Y}{\sigma_{rg_X} \sigma_{rg_Y}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\rho\)</span> is the Pearson correlation coefficient applied to the ranked variables,
<span class="math notranslate nohighlight">\(cov(rg_X, rg_Y)\)</span> is the covariance of the ranked variables and <span class="math notranslate nohighlight">\(\sigma_{rg_X}\)</span> and
<span class="math notranslate nohighlight">\(\sigma_{rg_Y}\)</span> are the standard deviations of the ranked variables.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">16</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spearman</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
<span class="go">array([[ 1.        , -0.33333333, -0.03703704, -0.33333333],</span>
<span class="go">   [-0.33333333,  1.        , -0.03703704, -0.33333333],</span>
<span class="go">   [-0.03703704, -0.03703704,  1.        ,  0.85185185],</span>
<span class="go">   [-0.33333333, -0.33333333,  0.85185185,  1.        ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spearman</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
<span class="go">array([[ 1.        , -0.33333333, -0.03703704, -0.33333333],</span>
<span class="go">   [-0.33333333,  1.        , -0.03703704, -0.33333333],</span>
<span class="go">   [-0.03703704, -0.03703704,  1.        ,  0.85185185],</span>
<span class="go">   [-0.33333333, -0.33333333,  0.85185185,  1.        ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spearman</span><span class="p">(</span><span class="n">h</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">h</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[ 1.        , -0.33333333],</span>
<span class="go">   [-0.33333333,  1.        ]])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#utilmy.stats.hypothesis.descriptive.pearson" title="utilmy.stats.hypothesis.descriptive.pearson"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pearson</span></code></a></dt><dd><p>function for computing the Pearson product-moment correlation of two vectors or a data matrix.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Spearman’s rank correlation coefficient. (2017, June 24). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Spearman%27s_rank_correlation_coefficient&amp;oldid=787350680">https://en.wikipedia.org/w/index.php?title=Spearman%27s_rank_correlation_coefficient&amp;oldid=787350680</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.std_dev">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">std_dev</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.std_dev" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the standard deviation by taking the square root of the variance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>sd</strong> – The computed standard deviation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array or float</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">std_dev</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="go">2.12132034</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">std_dev</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="go">array([2.12132034, 2.12132034])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The standard deviation is defined as the square root of the variance. For example, the corrected two pass
algorithm for computing variance is defined as:</p>
<div class="math notranslate nohighlight">
\[S = \sum^N_{i=1} (x_i - \bar{x})^2 - \frac{1}{N} \left( \sum^N_{i=1} (x_i - \bar{x}) \right)^2\]</div>
<p>Thus, the standard deviation would be defined as:</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{S}\]</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#utilmy.stats.hypothesis.descriptive.var" title="utilmy.stats.hypothesis.descriptive.var"><code class="xref py py-obj docutils literal notranslate"><span class="pre">var</span></code></a></dt><dd><p>function for computing the variance of an observation array.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.var">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">var</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'corrected</span> <span class="pre">two</span> <span class="pre">pass'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.var" title="Permalink to this definition"></a></dt>
<dd><p>Front-end interface function for computing the variance of a sample
or population.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array_like</em>) – One or two-dimensional array of data points. Accepts a numpy array, list, pandas DataFrame, or pandas Series.</p></li>
<li><p><strong>method</strong> (<em>{'corrected_two_pass'</em><em>, </em><em>'textbook_one_pass'</em><em>, </em><em>'standard_two_pass'</em><em>, </em><em>'youngs_cramer'}</em><em>, </em><em>optional.</em>) – Selects algorithm used to calculate variance. Default method is <code class="code docutils literal notranslate"><span class="pre">corrected_two_pass</span></code> which
is generally more computationally stable than other algorithms (with the exception of youngs-cramer,
perhaps).</p></li>
<li><p><strong>correction</strong> (<em>bool</em>) – If True (default), Bessel’s correction, <span class="math notranslate nohighlight">\(n - 1\)</span> is used in computing the variance rather than
<span class="math notranslate nohighlight">\(n\)</span>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>v</strong> – If the input is one-dimensional, the variance is returned as
a float. For a two-dimensional input, the variance is calculated
column-wise and returned as a numpy array or pandas DataFrame.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float or numpy array or numpy structured array or pandas DataFrame</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">var</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">np.array([2, 2.25, 0.666667, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">var</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="go">np.array([2])</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>** Available algorithms**</p>
<p><strong>Corrected Two Pass</strong></p>
<p>The corrected two pass approach, as suggested by Professor Å. Björck in (Chan, Golub, &amp; Leveque, 1983)
is generally more stable numerically compared to other methods and is the default algorithm used in
the var function.</p>
<p>The corrected two pass algorithm takes advantage of increased gains in accuracy by
shifting all the data by the computed mean before computing <span class="math notranslate nohighlight">\(S\)</span>. Even primitive
approximations of <span class="math notranslate nohighlight">\(\bar{x}\)</span> can yield large improvements in accuracy. The
corrected two pass algorithm is defined as:</p>
<div class="math notranslate nohighlight">
\[S = \sum^N_{i=1} (x_i - \bar{x})^2 - \frac{1}{N} \left( \sum^N_{i=1} (x_i - \bar{x}) \right)^2\]</div>
<p>The first term is the standard two pass algorithm while the second acts as an approximation
to the error term of the first term that avoids the problem of catastrophic cancellation.</p>
<p><strong>Textbook One-Pass</strong></p>
<p>The textbook one pass algorithm for calculating variance is so named due to its
prevalence in statistical textbooks and it passes through the data once
(hence ‘one-pass’).</p>
<p>The textbook one pass algorithm is defined as:</p>
<div class="math notranslate nohighlight">
\[S = \sum^N_{i=1} x_i^2 - \frac{1}{N}\left( \sum^N_{i=1} x_i \right)^2\]</div>
<p><strong>Standard Two-Pass</strong></p>
<p>Standard two-pass algorithm defined in (Chan, Golub, &amp; Leveque, 1983) for
computing variance of a 1D or 2D array.</p>
<p>The standard two pass algorithm for computing variance as defined in
(Chan, Golub, &amp; Leveque, 1983) is so named due to the algorithm passing
through the data twice, once to compute the mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and again
for the variance <span class="math notranslate nohighlight">\(S\)</span>. The standard two pass algorithm is defined as:</p>
<div class="math notranslate nohighlight">
\[S = \sum^N_{i=1} (x_i - \bar{x})^2 \qquad \bar{x} = \frac{1}{N} \sum^N_{i=1} x_i\]</div>
<p>Due to the algorithm’s two pass nature, it may not be the most optimal approach
when the data is too large to store in memory or dynamically as data is collected.
The algorithm is mathematically equivalent to the textbook one-pass algorithm.</p>
<p><strong>Youngs-Cramer</strong></p>
<p>Implementation of the Youngs-Cramer updating algorithm for computing the variance
<span class="math notranslate nohighlight">\(S\)</span> as presented in (Chan, Golub, &amp; LeVeque, 1982).</p>
<p>Updating algorithms for computing variance have been proposed by numerous authors as
they are robust to catastrophic cancellation and don’t require several passes through
the data, hence reducing the amount of memory required. The Youngs and Cramer updating
algorithm is generally as performant as the two-pass algorithm. The algorithm proposed by
Youngs and Cramer follows from their investigation of the most performant updating
algorithms for computing variance and is as follows:</p>
<div class="math notranslate nohighlight">
\[t_j = t_{j-1} + x_j
S_n = S_{n-1} + \frac{1}{n(n - 1)} (nx_j - t_j)^2\]</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#utilmy.stats.hypothesis.descriptive.std_dev" title="utilmy.stats.hypothesis.descriptive.std_dev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">std_dev</span></code></a></dt><dd><p>function for computing the standard deviation of an observation array.</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Chan, T., Golub, G., &amp; Leveque, R. (1983). Algorithms for Computing the Sample Variance:</dt><dd><p>Analysis and Recommendations. The American Statistician, 37(3), 242-247.
<a class="reference external" href="http://dx.doi.org/10.1080/00031305.1983.10483115">http://dx.doi.org/10.1080/00031305.1983.10483115</a></p>
</dd>
<dt>Press, W., Teukolsky, S., Vetterling, W., &amp; Flannery, B. (2007). Numerical recipes (3rd ed.).</dt><dd><p>Cambridge: Cambridge University Press.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.descriptive.variance_condition">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.descriptive.</span></span><span class="sig-name descname"><span class="pre">variance_condition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.descriptive.variance_condition" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the condition number, denoted as <span class="math notranslate nohighlight">\(\kappa\)</span> which
measures the sensitivity of the variance <span class="math notranslate nohighlight">\(S\)</span> of a sample
vector <span class="math notranslate nohighlight">\(x\)</span> as defined by Chan and Lewis (as cited in Chan,
Golub, &amp; Leveque, 1983). Given a machine accuracy value of
<span class="math notranslate nohighlight">\(u\)</span>, the value <span class="math notranslate nohighlight">\(\kappa u\)</span> can be used as a measure to
judge the accuracy of the different variance computation algorithms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array_like</em>) – Numpy ndarray, pandas DataFrame or Series, list, or list of lists representing a 1D or 2D array
containing the variables and their respective observation vectors.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>varr</strong> – Depending on the dimension of the input, returns a 1D or 2D array of the
column-wise computed variances.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy ndarray</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The 2-norm is defined as usual:</p>
<div class="math notranslate nohighlight">
\[||x||_2 = \sum^N_{i=1} x^2_i\]</div>
<p>Then the condition number <span class="math notranslate nohighlight">\(\kappa\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\kappa = \frac{||x||_2}{\sqrt{S}} = \sqrt{1 + \bar{x}^2 N / S}\]</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Chan, T., Golub, G., &amp; Leveque, R. (1983). Algorithms for Computing the Sample Variance:</dt><dd><p>Analysis and Recommendations. The American Statistician, 37(3), 242-247.
<a class="reference external" href="http://dx.doi.org/10.1080/00031305.1983.10483115">http://dx.doi.org/10.1080/00031305.1983.10483115</a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.fa">
<span id="utilmy-stats-hypothesis-fa-module"></span><h2>utilmy.stats.hypothesis.fa module<a class="headerlink" href="#module-utilmy.stats.hypothesis.fa" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.fa.FactorAnalysis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.fa.</span></span><span class="sig-name descname"><span class="pre">FactorAnalysis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">covar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'principal_component'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.fa.FactorAnalysis" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>factors</strong> (<em>int</em><em>, </em><em>default None</em>) – Number of underlying hypothesis factors</p></li>
<li><p><strong>rotate</strong> (<em>str</em><em>, </em><em>default None</em>) – Rotation to use when performing the factor analysis. Currently not used.</p></li>
<li><p><strong>covar</strong> (<em>boolean</em><em>, </em><em>default False</em>) – If False (default), perform the factor analysis using the covariance matrix. If
True, the factor analysis is computed with the correlation matrix. It is highly
recommended to use the correlation matrix in the vast majority of cases as
variables with comparatively large variances can dominate the diagonal of the
covariance matrix and the factors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-utilmy.stats.hypothesis.gof">
<span id="utilmy-stats-hypothesis-gof-module"></span><h2>utilmy.stats.hypothesis.gof module<a class="headerlink" href="#module-utilmy.stats.hypothesis.gof" title="Permalink to this heading"></a></h2>
<p>Implementations of goodness-of-fit tests.</p>
<section id="goodness-of-fit">
<h3>Goodness-of-fit<a class="headerlink" href="#goodness-of-fit" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<ol class="upperalpha" start="2">
<li><ol class="upperalpha simple" start="23">
<li><p>Yap &amp; C. H. Sim (2011) Comparisons of various types of normality tests,</p></li>
</ol>
<blockquote>
<div><p>Journal of Statistical Computation and Simulation, 81:12, 2141-2155, DOI: 10.1080/00949655.2010.520163</p>
</div></blockquote>
</li>
</ol>
<dl class="simple">
<dt>Ukponmwan H. Nosakhare, Ajibade F. Bright. Evaluation of Techniques for Univariate Normality Test Using Monte</dt><dd><p>Carlo Simulation. American Journal of Theoretical and Applied Statistics.
Special Issue: Statistical Distributions and Modeling in Applied Mathematics.
Vol. 6, No. 5-1, 2017, pp. 51-61. doi: 10.11648/j.ajtas.s.2017060501.18</p>
</dd>
<dt>Wikipedia contributors. (2018, March 20). Jarque–Bera test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 14:46, September 15, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Jarque%E2%80%93Bera_test&amp;oldid=831439673">https://en.wikipedia.org/w/index.php?title=Jarque%E2%80%93Bera_test&amp;oldid=831439673</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.gof.</span></span><span class="sig-name descname"><span class="pre">ChiSquareTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degrees_freedom</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the one-sample Chi-Square goodness-of-fit test.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observed</strong> (<em>array-like</em>) – One-dimensional array of observed frequencies.</p></li>
<li><p><strong>expected</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array of expected frequencies. If not given, the expected frequencies are computed
as the mean of the observed frequencies (each category is equally likely to occur).</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>optional</em>) – Applies Yates’s continuity correction for approximation error. Defaults to False as the correction can
tend to overcorrect and result in a type II error.</p></li>
<li><p><strong>degrees_freedom</strong> (<em>int</em><em>, </em><em>optional</em>) – Degrees of freedom. The p-value in the chi-square test is computed with degrees of freedom is <span class="math notranslate nohighlight">\(k - 1\)</span>,
where <span class="math notranslate nohighlight">\(k\)</span> is the number of observed frequencies.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.observed">
<span class="sig-name descname"><span class="pre">observed</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.observed" title="Permalink to this definition"></a></dt>
<dd><p>One-dimensional array of observed frequencies.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.expected">
<span class="sig-name descname"><span class="pre">expected</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.expected" title="Permalink to this definition"></a></dt>
<dd><p>One-dimensional array of expected frequencies.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.degrees_of_freedom">
<span class="sig-name descname"><span class="pre">degrees_of_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.degrees_of_freedom" title="Permalink to this definition"></a></dt>
<dd><p>Total degrees of freedom used in the computation of the p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.continuity_correction">
<span class="sig-name descname"><span class="pre">continuity_correction</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.continuity_correction" title="Permalink to this definition"></a></dt>
<dd><p>If True, Yates’s continuity correction is applied when performing the chi-square test</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of observed frequencies.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.chi_square">
<span class="sig-name descname"><span class="pre">chi_square</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.chi_square" title="Permalink to this definition"></a></dt>
<dd><p>The computed test statistic, the chi-square, <span class="math notranslate nohighlight">\(\chi^2\)</span> value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The calculated p-value of the test given the chi-square statistic and degrees of freedom.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.ChiSquareTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.ChiSquareTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing a collection of the resulting test statistics and other information.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If the <code class="code docutils literal notranslate"><span class="pre">expected</span></code> parameter is passed but is not of the same length as the required <code class="code docutils literal notranslate"><span class="pre">observed</span></code>
    parameter, a <code class="code docutils literal notranslate"><span class="pre">ValueError</span></code> is raised.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The chi-squared test, often called the <span class="math notranslate nohighlight">\(\chi^2\)</span> test, is also known as Pearson’s chi-squared test. The
chi-square test is a one-sample goodness-of-fit test that evaluates whether a significant difference exists between
an observed number of frequencies from two or more groups and an expected frequency based on a null hypothesis. A
simple example of a chi-square test is testing whether a six-sided die is ‘fair’, in that all outcomes are equally
likely to occur.</p>
<p>The chi-square test statistic, <span class="math notranslate nohighlight">\(\chi^2\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum^k_{i=1} \frac{O_i - E_i)^2}{E_i}\]</div>
<p>Where <span class="math notranslate nohighlight">\(O_i\)</span> is the observed number of frequencies in the <span class="math notranslate nohighlight">\(i\)</span> is the expected
number of frequencies in the respective <span class="math notranslate nohighlight">\(i\)</span> is the total number of groups or
categories, or ‘cells’.</p>
<p>The p-value can then be found by comparing the calculated <span class="math notranslate nohighlight">\(\chi^2\)</span> statistic to a chi-square distribution.
The degrees of freedom is equal to <span class="math notranslate nohighlight">\(k - 1\)</span> minus any additional reduction in the degrees of freedom, if
specified.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">observed</span> <span class="o">=</span> <span class="p">[</span><span class="mi">29</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">11</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ch</span> <span class="o">=</span> <span class="n">ChiSquareTest</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ch</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;chi-square&#39;: 16.333333333333332,</span>
<span class="go"> &#39;continuity correction&#39;: False,</span>
<span class="go"> &#39;degrees of freedom&#39;: 7,</span>
<span class="go"> &#39;p-value&#39;: 0.022239477462390588}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ch</span> <span class="o">=</span> <span class="n">ChiSquareTest</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ch</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;chi-square&#39;: 16.333333333333332,</span>
<span class="go"> &#39;continuity correction&#39;: False,</span>
<span class="go"> &#39;degrees of freedom&#39;: 7,</span>
<span class="go"> &#39;p-value&#39;: 0.022239477462390588}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Weisstein, Eric W. “Chi-Squared Test.” From MathWorld–A Wolfram Web Resource.</dt><dd><p><a class="reference external" href="http://mathworld.wolfram.com/Chi-SquaredTest.html">http://mathworld.wolfram.com/Chi-SquaredTest.html</a></p>
</dd>
<dt>Wikipedia contributors. (2018, July 5). Chi-squared test. In Wikipedia, The Free Encyclopedia. Retrieved 13:56,</dt><dd><p>August 19, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Chi-squared_test&amp;oldid=848986171">https://en.wikipedia.org/w/index.php?title=Chi-squared_test&amp;oldid=848986171</a></p>
</dd>
<dt>Wikipedia contributors. (2018, April 12). Pearson’s chi-squared test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:55, August 23, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Pearson%27s_chi-squared_test&amp;oldid=836064929">https://en.wikipedia.org/w/index.php?title=Pearson%27s_chi-squared_test&amp;oldid=836064929</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.JarqueBera">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.gof.</span></span><span class="sig-name descname"><span class="pre">JarqueBera</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.JarqueBera" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the Jarque-Bera goodness-of-fit test.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>array-like</em>) – One-dimensional array-like object (list, numpy array, pandas DataFrame or pandas Series) containing
the observed sample values.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.JarqueBera.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.JarqueBera.x" title="Permalink to this definition"></a></dt>
<dd><p>The given sample values</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.JarqueBera.test_statistic">
<span class="sig-name descname"><span class="pre">test_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.JarqueBera.test_statistic" title="Permalink to this definition"></a></dt>
<dd><p>Computed Jarque-Bera test statistic</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.JarqueBera.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.JarqueBera.p_value" title="Permalink to this definition"></a></dt>
<dd><p>p-value of Jarque-Bera test statistic</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.JarqueBera.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.JarqueBera.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the Jarque-Bera test statistic and associated p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p class="rubric">Notes</p>
<p>The Jarque-Bera test is a goodness-of-fit test developed by Carlos Jarque and Anil Bera that tests whether
a sample of data is normally distributed using the sample’s kurtosis and skewness. The Jarque-Bera test
statistic is defined as:</p>
<div class="math notranslate nohighlight">
\[JB = \frac{n}{6} \large( s^2 + \frac{(k-3)^2}{4} \large)\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number of samples in the data, <span class="math notranslate nohighlight">\(s\)</span> is the computed sample’s skewness and <span class="math notranslate nohighlight">\(k\)</span> is
the sample’s kurtosis. The Jarque-Bera test statistic has a chi-square distribution with two degrees of freedom
when the number of samples is adequate. The test statistic is always non-negative and the farther away from zero,
the stronger of an indication the sample data does not follow a normal distribution.</p>
<p>In the case of small samples (‘small’ being somewhat subjective but generally considered to be <span class="math notranslate nohighlight">\(n &lt; 30\)</span>),
the Jarque-Bera test and statistic is overly-sensitive and can lead to large Type 1 error rates.</p>
<p class="rubric">References</p>
<ol class="upperalpha" start="2">
<li><ol class="upperalpha simple" start="23">
<li><p>Yap &amp; C. H. Sim (2011) Comparisons of various types of normality tests,</p></li>
</ol>
<blockquote>
<div><p>Journal of Statistical Computation and Simulation, 81:12, 2141-2155, DOI: 10.1080/00949655.2010.520163</p>
</div></blockquote>
</li>
</ol>
<dl class="simple">
<dt>Jarque, C., &amp; Bera, A. (1987). A Test for Normality of Observations and Regression Residuals.</dt><dd><p>International Statistical Review / Revue Internationale De Statistique, 55(2), 163-172. doi:10.2307/1403192</p>
</dd>
<dt>Ukponmwan H. Nosakhare, Ajibade F. Bright. Evaluation of Techniques for Univariate Normality Test Using Monte</dt><dd><p>Carlo Simulation. American Journal of Theoretical and Applied Statistics.
Special Issue: Statistical Distributions and Modeling in Applied Mathematics.
Vol. 6, No. 5-1, 2017, pp. 51-61. doi: 10.11648/j.ajtas.s.2017060501.18</p>
</dd>
<dt>Wikipedia contributors. (2018, March 20). Jarque–Bera test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 14:46, September 15, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Jarque%E2%80%93Bera_test&amp;oldid=831439673">https://en.wikipedia.org/w/index.php?title=Jarque%E2%80%93Bera_test&amp;oldid=831439673</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.gof.KolmogorovSmirnov">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.gof.</span></span><span class="sig-name descname"><span class="pre">KolmogorovSmirnov</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.gof.KolmogorovSmirnov" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.hypothesis">
<span id="utilmy-stats-hypothesis-hypothesis-module"></span><h2>utilmy.stats.hypothesis.hypothesis module<a class="headerlink" href="#module-utilmy.stats.hypothesis.hypothesis" title="Permalink to this heading"></a></h2>
<p>Functions for performing classical hypothesis testing.</p>
<section id="hypothesis-testing">
<h3>Hypothesis Testing<a class="headerlink" href="#hypothesis-testing" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<p>Rencher, A. C., &amp; Christensen, W. F. (2012). Methods of multivariate analysis (3rd Edition).</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Student’s t-test. (2017, June 20). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Student%27s_t-test&amp;oldid=786562367">https://en.wikipedia.org/w/index.php?title=Student%27s_t-test&amp;oldid=786562367</a></p>
</dd>
<dt>Weisstein, Eric W. “Chi-Squared Test.” From MathWorld–A Wolfram Web Resource.</dt><dd><p><a class="reference external" href="http://mathworld.wolfram.com/Chi-SquaredTest.html">http://mathworld.wolfram.com/Chi-SquaredTest.html</a></p>
</dd>
<dt>Wikipedia contributors. (2018, July 14). Binomial proportion confidence interval.</dt><dd><p>In Wikipedia, The Free Encyclopedia. Retrieved 15:03, August 10, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Binomial_proportion_confidence_interval&amp;oldid=850256725">https://en.wikipedia.org/w/index.php?title=Binomial_proportion_confidence_interval&amp;oldid=850256725</a></p>
</dd>
<dt>Wikipedia contributors. (2018, July 5). Chi-squared test. In Wikipedia, The Free Encyclopedia. Retrieved 13:56,</dt><dd><p>August 19, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Chi-squared_test&amp;oldid=848986171">https://en.wikipedia.org/w/index.php?title=Chi-squared_test&amp;oldid=848986171</a></p>
</dd>
<dt>Wikipedia contributors. (2018, April 12). Pearson’s chi-squared test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:55, August 23, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Pearson%27s_chi-squared_test&amp;oldid=836064929">https://en.wikipedia.org/w/index.php?title=Pearson%27s_chi-squared_test&amp;oldid=836064929</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.hypothesis.</span></span><span class="sig-name descname"><span class="pre">BinomialTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'two-sided'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs a one-sample binomial test.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>int</em>) – Number of successes out of <span class="math notranslate nohighlight">\(n\)</span> trials.</p></li>
<li><p><strong>n</strong> (<em>int</em>) – Number of trials</p></li>
<li><p><strong>p</strong> (<em>float</em><em>, </em><em>optional</em>) – Expected probability of success</p></li>
<li><p><strong>alternative</strong> (<em>str</em><em>, </em><em>{'two-sided'</em><em>, </em><em>'greater'</em><em>, </em><em>'lesser'}</em><em>, </em><em>optional</em>) – Specifies the alternative hypothesis <span class="math notranslate nohighlight">\(H_1\)</span>. Must be one of ‘two-sided’ (default), ‘greater’,
or ‘less’.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Significance level</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the continuity corrected version of the Wilson score interval is used.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.x" title="Permalink to this definition"></a></dt>
<dd><p>Number of successes out of <span class="math notranslate nohighlight">\(n\)</span> trials.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Number of trials</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.p">
<span class="sig-name descname"><span class="pre">p</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.p" title="Permalink to this definition"></a></dt>
<dd><p>Expected probability of success</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.q">
<span class="sig-name descname"><span class="pre">q</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.q" title="Permalink to this definition"></a></dt>
<dd><p>Defined as <span class="math notranslate nohighlight">\(1 - p\)</span></p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.alternative">
<span class="sig-name descname"><span class="pre">alternative</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.alternative" title="Permalink to this definition"></a></dt>
<dd><p>Specifies the alternative hypothesis <span class="math notranslate nohighlight">\(H_1\)</span>. Must be one of ‘two-sided’ (default), ‘greater’,
or ‘less’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.alpha" title="Permalink to this definition"></a></dt>
<dd><p>Significance level</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.continuity" title="Permalink to this definition"></a></dt>
<dd><p>If True, the continuity corrected version of the Wilson score interval is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>Computed p-value</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.z">
<span class="sig-name descname"><span class="pre">z</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.z" title="Permalink to this definition"></a></dt>
<dd><p>z-score used in computation of intervals</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.clopper_pearson_interval">
<span class="sig-name descname"><span class="pre">clopper_pearson_interval</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.clopper_pearson_interval" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of the Clopper-Pearson lower and upper intervals and probability of success.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.wilson_score_interval">
<span class="sig-name descname"><span class="pre">wilson_score_interval</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.wilson_score_interval" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of the Wilson Score lower and upper intervals and probability of success.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.agresti_coull_interval">
<span class="sig-name descname"><span class="pre">agresti_coull_interval</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.agresti_coull_interval" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of the Agresti-Coull lower and upper intervals and probability of success.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.arcsine_transform_interval">
<span class="sig-name descname"><span class="pre">arcsine_transform_interval</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.arcsine_transform_interval" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of the arcsine transformation lower and upper intervals and probability of success.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.BinomialTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.BinomialTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing test summary statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If number of successes <span class="math notranslate nohighlight">\(x\)</span> is greater than the number of trials <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
<li><p><strong>ValueError</strong> – If expected probability <span class="math notranslate nohighlight">\(p\)</span> is greater than 1.</p></li>
<li><p><strong>ValueError</strong> – If parameter <code class="code docutils literal notranslate"><span class="pre">alternative</span></code> is not one of {‘two-sided’, ‘greater’, ‘lesser’}</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The Binomial test is a one-sample test applicable in the case of populations consisting of two classes or groups,
such as male/female, cat/dog, etc. The proportion of the first group is denoted <span class="math notranslate nohighlight">\(p\)</span>, while the second group
is often denoted <span class="math notranslate nohighlight">\(q\)</span>, which we know to be <span class="math notranslate nohighlight">\(1 - p\)</span>. The null hypothesis of the test is that the
proportion of the population is indeed <span class="math notranslate nohighlight">\(p\)</span> and gives the researcher more information to determine if the
random sample that was drawn could have come from a population having a proportion of <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>As the name of the test implies, the binomial distribution is the sampling distribution the of the proportions
that could be observed when drawing random samples from a population. Therefore, the probability of obtaining
<span class="math notranslate nohighlight">\(x\)</span> objects in one category and <span class="math notranslate nohighlight">\(n - x\)</span> in the other category out of a total <span class="math notranslate nohighlight">\(n\)</span> trials is
given by the binomial distribution probability mass function:</p>
<div class="math notranslate nohighlight">
\[p(x) = \binom{n}{x} P^x (1 - P)^{n - x}\]</div>
<p><span class="math notranslate nohighlight">\((1 - P)\)</span> may be substituted for <span class="math notranslate nohighlight">\(Q\)</span>. The binomial coefficient <span class="math notranslate nohighlight">\(\binom{n}{x}\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\binom{n}{x} = \frac{n!}{k!(n - k)!}\]</div>
<p>The p-value of the test is calculated by the binomial distribution’s cumulative distribution function, defined as:</p>
<div class="math notranslate nohighlight">
\[Pr(X \leq x) = \sum^{[k]}_{i=0} \binom{n}{i} P^i (1 - P)^{n - i}\]</div>
<p>There are several confidence intervals that can be computed when performing a binomial test. The most common is
known as the Clopper-Pearson interval, which is an exact interval as it is based on the binomial distribution. The
Clopper-Pearson interval can be defined several ways, one of which uses the relationship between the binomial
distribution nad the beta distribution.</p>
<div class="math notranslate nohighlight">
\[B\left(\frac{\alpha}{2};x,n-x+1\right) &lt; \theta &lt; B\left(1 - \frac{\alpha}{2};x + 1, n - x \right)\]</div>
<p>The Agresti-Coull interval utilizes the standard normal distribution. <span class="math notranslate nohighlight">\(z\)</span> is given as
<span class="math notranslate nohighlight">\(1 - \frac{\alpha}{2}\)</span>. The interval calculation proceeds as:</p>
<p>With <span class="math notranslate nohighlight">\(x\)</span> successes out of a total <span class="math notranslate nohighlight">\(n\)</span> trials, we define <span class="math notranslate nohighlight">\(\tilde{n}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[`\tilde{n} = n + z^2\]</div>
<p>and,</p>
<div class="math notranslate nohighlight">
\[\tilde{p} = \frac{1}{\tilde{n}} \left(x + \frac{z^2}{2} \right)\]</div>
<p>The confidence interval for the probability of success, <span class="math notranslate nohighlight">\(p\)</span>, is then given as:</p>
<div class="math notranslate nohighlight">
\[\tilde{p} \pm z \sqrt{\frac{\tilde{p}}{\tilde{n}} (1 - \tilde{p})}\]</div>
<p>The arcsine transformation confidence interval is defined as:</p>
<div class="math notranslate nohighlight">
\[sin^2 \left(\arcsin{\sqrt{p}} - \frac{z}{2\sqrt{n}} \right) &lt; \theta &lt; sin^2 \left(arcsin{\sqrt{p}} +
\frac{z}{2\sqrt{n}} \right)\]</div>
<p>Where <span class="math notranslate nohighlight">\(z\)</span> is the quantile <span class="math notranslate nohighlight">\(1 - \frac{\alpha}{2}}\)</span> of the standard normal distribution, as before.</p>
<p>Lastly, the Wilson score interval can be computed with or without continuity correction. Without correction, the
Wilson score interval success proability <span class="math notranslate nohighlight">\(p\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\frac{\hat{p} + \frac{z^2}{2n}}{1 + \frac{z^2}{n} \pm \frac{z}{1 + \frac{z^2}{n}}
\sqrt{\frac{\hat{p} (1 - \hat{p}}{n}}{1 + \frac{z^2}{n}}}\]</div>
<p>The Wilson score interval with continuity correction is defined as:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}w^- = max \Bigg\{0, \frac{2n\hat{P} + z^2 -
\Big[z \sqrt{z^2 - \frac{1}{n} + 4n\hat{p}(1 - \hat{p}) + (4\hat{p} - 2) + 1}\Big]}{2(n + z^2)}\Bigg\}\\w^+ = min \Bigg\{1, \frac{2n\hat{P} + z^2 +
\Big[z \sqrt{z^2 - \frac{1}{n} + 4n\hat{p}(1 - \hat{p}) - (4\hat{p} - 2) + 1}\Big]}{2(n + z^2)}\Bigg\}\end{aligned}\end{align} \]</div>
<p>Where <span class="math notranslate nohighlight">\(w^-\)</span> and <span class="math notranslate nohighlight">\(w^+\)</span> are the lower and upper bounds of the Wilson score interval corrected for
contiunity.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="mi">682</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n</span> <span class="o">=</span> <span class="mi">925</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bt</span> <span class="o">=</span> <span class="n">BinomialTest</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bt</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Number of Successes&#39;: 682,</span>
<span class="go"> &#39;Number of Trials&#39;: 925,</span>
<span class="go"> &#39;alpha&#39;: 0.05,</span>
<span class="go"> &#39;intervals&#39;: {&#39;Agresti-Coull&#39;: {&#39;conf level&#39;: 0.95,</span>
<span class="go">   &#39;interval&#39;: (0.7079790581519885, 0.7646527304391209),</span>
<span class="go">   &#39;probability of success&#39;: 0.7363158942955547},</span>
<span class="go">  &#39;Arcsine Transform&#39;: {&#39;conf level&#39;: 0.95,</span>
<span class="go">   &#39;interval&#39;: (0.708462749220724, 0.7651467076803447),</span>
<span class="go">   &#39;probability of success&#39;: 0.7372972972972973,</span>
<span class="go">   &#39;probability variance&#39;: 0.00020939458669772768},</span>
<span class="go">  &#39;Clopper-Pearson&#39;: {&#39;conf level&#39;: 0.95,</span>
<span class="go">   &#39;interval&#39;: (0.7076682640790369, 0.7654065582415227),</span>
<span class="go">   &#39;probability of success&#39;: 0.7372972972972973},</span>
<span class="go">  &#39;Wilson Score&#39;: {&#39;conf level&#39;: 0.95,</span>
<span class="go">   &#39;interval&#39;: (0.46782780413153596, 0.5321721958684641),</span>
<span class="go">   &#39;probability of success&#39;: 0.5}},</span>
<span class="go"> &#39;p-value&#39;: 2.4913404672588513e-13}</span>
<span class="go"> &gt;&gt;&gt; bt.p_value</span>
<span class="go"> 2.4913404672588513e-13</span>
<span class="go"> &gt;&gt;&gt; bt.clopper_pearson_interval</span>
<span class="go">{&#39;conf level&#39;: 0.95,</span>
<span class="go"> &#39;interval&#39;: (0.7076682640790369, 0.7654065582415227),</span>
<span class="go"> &#39;probability of success&#39;: 0.7372972972972973}</span>
<span class="go"> &gt;&gt;&gt; bt2 = BinomialTest(n, x, alternative=&#39;greater&#39;)</span>
<span class="go"> &gt;&gt;&gt; bt2.p_value</span>
<span class="go">1.2569330927920093e-49</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bt2</span><span class="o">.</span><span class="n">clopper_pearson_interval</span>
<span class="go">{&#39;conf level&#39;: 0.95,</span>
<span class="go"> &#39;interval&#39;: (0.7124129244365457, 1.0),</span>
<span class="go"> &#39;probability of success&#39;: 0.7372972972972973}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, July 14). Binomial proportion confidence interval.</dt><dd><p>In Wikipedia, The Free Encyclopedia. Retrieved 15:03, August 10, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Binomial_proportion_confidence_interval&amp;oldid=850256725">https://en.wikipedia.org/w/index.php?title=Binomial_proportion_confidence_interval&amp;oldid=850256725</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.hypothesis.</span></span><span class="sig-name descname"><span class="pre">tTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_equal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paired</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'two-sided'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs one and two-sample t-tests.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>array-like</em>) – One-dimensional array-like object (list, numpy array, pandas DataFrame or pandas Series) containing
the observed sample values.</p></li>
<li><p><strong>y2</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array-like object (list, numpy array, pandas DataFrame or pandas Series) containing
the observed sample values. Not necessary to include when performing one-sample t-tests.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – Optional group vector array denoting class membership. Cannot contain more than two unique groups
and must be the same length as <code class="code docutils literal notranslate"><span class="pre">y1</span></code>.</p></li>
<li><p><strong>mu</strong> (<em>float</em><em>, </em><em>optional</em>) – True mean to test difference when performing a one-sample t-test.</p></li>
<li><p><strong>var_equal</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the two samples are assumed to have equal variances and Student’s t-test is performed.
Defaults to False, which performs Welch’s t-test for unequal sample variances.</p></li>
<li><p><strong>paired</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, performs a paired t-test.</p></li>
<li><p><strong>alternative</strong> (<em>str</em><em>, </em><em>{'two-sided'</em><em>, </em><em>'greater'</em><em>, </em><em>'less'}</em>) – Specifies the alternative hypothesis <span class="math notranslate nohighlight">\(H_1\)</span>. Must be one of ‘two-sided’ (default), ‘greater’,
or ‘less’.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>default 0.05</em>) – The alpha-level for computing the confidence intervals.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.y1">
<span class="sig-name descname"><span class="pre">y1</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.y1" title="Permalink to this definition"></a></dt>
<dd><p>First sample observation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.y2">
<span class="sig-name descname"><span class="pre">y2</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.y2" title="Permalink to this definition"></a></dt>
<dd><p>Second sample observation vector, if passed. Otherwise, <code class="code docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.group">
<span class="sig-name descname"><span class="pre">group</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.group" title="Permalink to this definition"></a></dt>
<dd><p>The corresponding group vector denoting group sample membership. Will return <code class="code docutils literal notranslate"><span class="pre">None</span></code> if not passed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.paired">
<span class="sig-name descname"><span class="pre">paired</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.paired" title="Permalink to this definition"></a></dt>
<dd><p>If True, a paired t-test with the two sample observation vectors is performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.alternative">
<span class="sig-name descname"><span class="pre">alternative</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.alternative" title="Permalink to this definition"></a></dt>
<dd><p>Specifies the alternative hypothesis. Must be one of ‘two-sided’ (default), ‘greater’, or ‘lesser’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str, {‘two-sided’, ‘greater’, ‘less’}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.mu">
<span class="sig-name descname"><span class="pre">mu</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.mu" title="Permalink to this definition"></a></dt>
<dd><p>Specifies the ‘true’ mean of the population being tested if a one-sample test is being performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.var_equal">
<span class="sig-name descname"><span class="pre">var_equal</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.var_equal" title="Permalink to this definition"></a></dt>
<dd><p>If True, treats the sample observation vectors as having equal variances and the Studentized t-test is
performed. Defaults to False, which treats the sample observation vectors as having unequal variances and
Welch’s t-test is performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.method">
<span class="sig-name descname"><span class="pre">method</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.method" title="Permalink to this definition"></a></dt>
<dd><p>String denoting the test performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.sample_statistics">
<span class="sig-name descname"><span class="pre">sample_statistics</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.sample_statistics" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing the pertinent statistics (mean, number of observations, variance) of the
sample observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.parameter">
<span class="sig-name descname"><span class="pre">parameter</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.parameter" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom. If <code class="code docutils literal notranslate"><span class="pre">var_equal</span></code> is False, The Welch-Satterthwaite degrees of freedom approximation
is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.t_statistic">
<span class="sig-name descname"><span class="pre">t_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.t_statistic" title="Permalink to this definition"></a></dt>
<dd><p>Computed t-statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>p-value of the computed t-statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.hypothesis.tTest.confidence_interval">
<span class="sig-name descname"><span class="pre">confidence_interval</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.hypothesis.tTest.confidence_interval" title="Permalink to this definition"></a></dt>
<dd><p>Tuple of the low and high confidence interval.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – If <code class="code docutils literal notranslate"><span class="pre">alternative</span></code> is not one of (‘two-sided’, ‘greater’, or ‘lesser’)</p></li>
<li><p><strong>ValueError</strong> – If <code class="code docutils literal notranslate"><span class="pre">paired</span></code> is True and a second sample, <code class="code docutils literal notranslate"><span class="pre">y2</span></code> is not passed.</p></li>
<li><p><strong>ValueError</strong> – If <code class="code docutils literal notranslate"><span class="pre">paired</span></code> is True and the number of sample observations in <code class="code docutils literal notranslate"><span class="pre">y1</span></code> and <code class="code docutils literal notranslate"><span class="pre">y2</span></code>
    are not equal.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Welch’s t-test is an adaption of Student’s t test and is more performant when the
sample variances and size are unequal. The test still depends on the assumption of
the underlying population distributions being normally distributed.</p>
<p>Welch’s t test is defined as:</p>
<div class="math notranslate nohighlight">
\[t = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{\frac{s_{1}^{2}}{N_1} + \frac{s_{2}^{2}}{N_2}}}\]</div>
<p>where:</p>
<p><span class="math notranslate nohighlight">\(\bar{X}\)</span> is the sample mean, <span class="math notranslate nohighlight">\(s^2\)</span> is the sample variance, <span class="math notranslate nohighlight">\(n\)</span> is the sample size</p>
<p>If the <code class="code docutils literal notranslate"><span class="pre">var_equal</span></code> argument is True, Student’s t-test is used, which assumes the two samples
have equal variance. The t statistic is computed as:</p>
<div class="math notranslate nohighlight">
\[t = \frac{\bar{X}_1 - \bar{X}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\]</div>
<p>where:</p>
<div class="math notranslate nohighlight">
\[s_p = \sqrt{\frac{(n_1 - 1)s^2_{X_1} + (n_2 - 1)s^2_{X_2}}{n_1 + n_2 - 2}\]</div>
<p class="rubric">Examples</p>
<p>Similar to other inference methods, there are generally two ways of performing a t-test. The first is to pass
a group vector with the <code class="code docutils literal notranslate"><span class="pre">group</span></code> parameter and the corresponding observation vector as below.</p>
<p>The data used in this example is a subset of the professor salary dataset found in Fox and
Weisberg (2011).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">professor_discipline</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">professor_salary</span> <span class="o">=</span> <span class="p">[</span><span class="mi">139750</span><span class="p">,</span> <span class="mi">173200</span><span class="p">,</span> <span class="mi">79750</span><span class="p">,</span> <span class="mi">11500</span><span class="p">,</span> <span class="mi">141500</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="mi">103450</span><span class="p">,</span> <span class="mi">124750</span><span class="p">,</span> <span class="mi">137000</span><span class="p">,</span> <span class="mi">89565</span><span class="p">,</span> <span class="mi">102580</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ttest</span> <span class="o">=</span> <span class="n">tTest</span><span class="p">(</span><span class="n">professor_salary</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">professor_discipline</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ttest</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Sample 1 Mean&#39;: 111469.0,</span>
<span class="go"> &#39;Sample 2 Mean&#39;: 109140.0,</span>
<span class="go"> &#39;alternative&#39;: &#39;two-sided&#39;,</span>
<span class="go"> &#39;confidence interval&#39;: (-67873.67468585065, 72531.67468585065),</span>
<span class="go"> &#39;degrees of freedom&#39;: 4.698886994702439,</span>
<span class="go"> &#39;p-value&#39;: 0.9342936060799869,</span>
<span class="go"> &#39;t-statistic&#39;: 0.08695024086399619,</span>
<span class="go"> &#39;test description&#39;: &quot;Two-Sample Welch&#39;s t-test&quot;}</span>
</pre></div>
</div>
<p>The other approach is to pass each group sample vector similar to the below.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sal_a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">139750</span><span class="p">,</span> <span class="mi">173200</span><span class="p">,</span> <span class="mi">79750</span><span class="p">,</span> <span class="mi">11500</span><span class="p">,</span> <span class="mi">141500</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sal_b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">103450</span><span class="p">,</span> <span class="mi">124750</span><span class="p">,</span> <span class="mi">137000</span><span class="p">,</span> <span class="mi">89565</span><span class="p">,</span> <span class="mi">102580</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ttest2</span> <span class="o">=</span> <span class="n">tTest</span><span class="p">(</span><span class="n">sal_a</span><span class="p">,</span> <span class="n">sal_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ttest2</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;Sample 1 Mean&#39;: 109140.0,</span>
<span class="go"> &#39;Sample 2 Mean&#39;: 111469.0,</span>
<span class="go"> &#39;alternative&#39;: &#39;two-sided&#39;,</span>
<span class="go"> &#39;confidence interval&#39;: (-72531.67468585065, 67873.67468585065),</span>
<span class="go"> &#39;degrees of freedom&#39;: 4.698886994702439,</span>
<span class="go"> &#39;p-value&#39;: 0.9342936060799869,</span>
<span class="go"> &#39;t-statistic&#39;: -0.08695024086399619,</span>
<span class="go"> &#39;test description&#39;: &quot;Two-Sample Welch&#39;s t-test&quot;}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<p>Rencher, A. C., &amp; Christensen, W. F. (2012). Methods of multivariate analysis (3rd Edition).</p>
<dl class="simple">
<dt>Student’s t-test. (2017, June 20). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Student%27s_t-test&amp;oldid=786562367">https://en.wikipedia.org/w/index.php?title=Student%27s_t-test&amp;oldid=786562367</a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.nonparametric">
<span id="utilmy-stats-hypothesis-nonparametric-module"></span><h2>utilmy.stats.hypothesis.nonparametric module<a class="headerlink" href="#module-utilmy.stats.hypothesis.nonparametric" title="Permalink to this heading"></a></h2>
<p>Functions for performing nonparametric statistical inference.</p>
<section id="nonparametric-inference-methods">
<h3>Nonparametric Inference Methods<a class="headerlink" href="#nonparametric-inference-methods" title="Permalink to this heading"></a></h3>
</section>
<section id="id2">
<h3>Other Functions<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h3>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
</dl>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<dl class="simple">
<dt>Mann–Whitney U test. (2017, June 20). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Mann%E2%80%93Whitney_U_test&amp;oldid=786593885">https://en.wikipedia.org/w/index.php?title=Mann%E2%80%93Whitney_U_test&amp;oldid=786593885</a></p>
</dd>
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, August 20). Friedman test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:56, August 27, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Friedman_test&amp;oldid=855731754">https://en.wikipedia.org/w/index.php?title=Friedman_test&amp;oldid=855731754</a></p>
</dd>
<dt>Wikipedia contributors. (2018, May 21). Kruskal–Wallis one-way analysis of variance.</dt><dd><p>In Wikipedia, The Free Encyclopedia. From
<a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945">https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945</a></p>
</dd>
<dt>Wikipedia contributors. (2017, June 27). Median test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:23, August 19, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Median_test&amp;oldid=787822318">https://en.wikipedia.org/w/index.php?title=Median_test&amp;oldid=787822318</a></p>
</dd>
<dt>Wikipedia contributors. (2018, August 22). Wald–Wolfowitz runs test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 13:54, September 13, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Wald%E2%80%93Wolfowitz_runs_test&amp;oldid=856082551">https://en.wikipedia.org/w/index.php?title=Wald%E2%80%93Wolfowitz_runs_test&amp;oldid=856082551</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">FriedmanTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the Friedman nonparametric test for multiple matched samples on an ordinal scale.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest.n" title="Permalink to this definition"></a></dt>
<dd><p>The number of samples in the design_matrix,</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of groups in design matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest.xr2">
<span class="sig-name descname"><span class="pre">xr2</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest.xr2" title="Permalink to this definition"></a></dt>
<dd><p>The Friedman test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">p-value</span></span></dt>
<dd><p>Associated p-value of the Friedman test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.FriedmanTest.summary">
<span class="sig-name descname"><span class="pre">summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.FriedmanTest.summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing test summary results including the <span class="math notranslate nohighlight">\(xr2\)</span> and <span class="math notranslate nohighlight">\(p-value\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p class="rubric">Notes</p>
<p>The Friedman test casts the given data into a matrix of <span class="math notranslate nohighlight">\(n\)</span> rows (number of samples in data) and <span class="math notranslate nohighlight">\(k\)</span>
columns (the number of sample groups). The data in each column is then ranked separately, meaning the range of
any row of ranks will be between <span class="math notranslate nohighlight">\(1\)</span> and <span class="math notranslate nohighlight">\(k\)</span> is the number of groups, or ‘treatments’. The Friedman
test then determines whether the sample data is likely to have come from the same population.</p>
<p>The test statistic of the Friedman test is <span class="math notranslate nohighlight">\(\chi_r^2\)</span>. The test statistic’s distribution resembles a
chi-square distribution with degrees of freedom <span class="math notranslate nohighlight">\(k - 1\)</span> when the samples and groups is sufficiently
large (‘sufficiently’ being somewhat arbitrary).</p>
<p>The Friedman test statistic <span class="math notranslate nohighlight">\(\chi_r^2\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[:math:`\chi_r^2` = \frac{12}{Nk(k+1)} \sum^k_{j=1} (R_j)^2 - 3N(k + 1)\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of rows (samples), <span class="math notranslate nohighlight">\(k\)</span> is the number of columns (groups/treatments) and
<span class="math notranslate nohighlight">\(R_j\)</span> is the sum of the ranks in the :math:<a href="#id3"><span class="problematic" id="id4">`</span></a>j^{th} column.</p>
<p>The Friedman test sometimes uses <span class="math notranslate nohighlight">\(Q\)</span> as a test statistic with a slightly different definition:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{12n}{k(k+1)} \sum^k_{j=1} (\bar{r}_j - \frac{k+1}{2})^2\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{r}_j\)</span> is the sum of the ranked data in the <span class="math notranslate nohighlight">\(r^{th}\)</span> row.</p>
<div class="math notranslate nohighlight">
\[\bar{r}_j = \frac{1}{n} \sum^n_{i=1} r_{ij}\]</div>
<p>When ties exist in the data, the <span class="math notranslate nohighlight">\(Q\)</span> definition of the Friedman test statistic changes to:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{(k-1) \sum^k_{i=1} (R_i - \frac{n(k+1){2})^2}{A_1 - C_1}\]</div>
<p>where:</p>
<div class="math notranslate nohighlight">
\[A_1 = \sum^n_{i=1} \sum^k_{j=1} (R(X_{ij}))^2
C_1 = \frac{nk(k+1)^2}{4}\]</div>
<p>Another approach for correcting ties in the data is the following:</p>
<div class="math notranslate nohighlight">
\[Q_{adj} = frac{Q}{C}\]</div>
<p>Where <span class="math notranslate nohighlight">\(C\)</span> is a tie correction factor defined as:</p>
<div class="math notranslate nohighlight">
\[C = 1 - \frac{\sum (t^3 - t_i)}{n(k^3 - k)}\]</div>
<p>Where <span class="math notranslate nohighlight">\(t_i\)</span> is the number of tied scores in the <span class="math notranslate nohighlight">\(i^{th}\)</span> set of ties.</p>
<p class="rubric">References</p>
<p>Gibbons, J. D., &amp; Chakraborti, S. (2010). Nonparametric statistical inference. London: Chapman &amp; Hall.</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, August 20). Friedman test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:56, August 27, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Friedman_test&amp;oldid=855731754">https://en.wikipedia.org/w/index.php?title=Friedman_test&amp;oldid=855731754</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">KruskalWallis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class containing the algorithms and methods used in the construction and conduction of the
Kruskal-Wallis H-test.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.ranked_matrix">
<span class="sig-name descname"><span class="pre">ranked_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.ranked_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix with the ranked observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.alpha" title="Permalink to this definition"></a></dt>
<dd><p>Alpha level for determining significance.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.n" title="Permalink to this definition"></a></dt>
<dd><p>Number of sample observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of treatment groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.dof">
<span class="sig-name descname"><span class="pre">dof</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.dof" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom, defined as <span class="math notranslate nohighlight">\(k - 1\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.H">
<span class="sig-name descname"><span class="pre">H</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.H" title="Permalink to this definition"></a></dt>
<dd><p>Calculated Kruskal-Wallis H-statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.t_value">
<span class="sig-name descname"><span class="pre">t_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.t_value" title="Permalink to this definition"></a></dt>
<dd><p>The critical t-value for computing the Least Significant Difference.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.p_value" title="Permalink to this definition"></a></dt>
<dd><p>Corresponding p-value of the <span class="math notranslate nohighlight">\(H\)</span>-statistic. The distribution of <span class="math notranslate nohighlight">\(H\)</span> is approximated
by the chi-square distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.least_significant_difference">
<span class="sig-name descname"><span class="pre">least_significant_difference</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.least_significant_difference" title="Permalink to this definition"></a></dt>
<dd><p>Calculated Least Significant Difference for determining if treatment group means are significantly
different from each other.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.KruskalWallis.test_description">
<span class="sig-name descname"><span class="pre">test_description</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.KruskalWallis.test_description" title="Permalink to this definition"></a></dt>
<dd><p>String describing the performed test. By default, the test description will be Kruskal-Wallis rank sum test</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>alpha</strong> (<em>float</em>) – Desired alpha level for testing for significance.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – As the Kruskal-Wallis is a univariate test, only one sample observation vector should be passed
    when including a group vector in the <code class="code docutils literal notranslate"><span class="pre">group</span></code> parameter.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The Kruskal-Wallis test extends the Mann-Whitney U test for more than two groups and can be
considered the nonparametric equivalent of the one-way analysis of variance (ANOVA) method.
The test is nonparametric similar to the Mann-Whitney test and as such does not
assume the data are normally distributed and can, therefore, be used when the assumption
of normality is violated.</p>
<p>The Kruskal-Wallis test proceeds by ranking the data from 1 (the smallest) to the largest
with ties replaced by the mean of the ranks the values would have received. The sum of
the ranks for each treatment is typically denoted $T_i$ or $R_i$.</p>
<p>The test statistic is denoted <code class="code docutils literal notranslate"><span class="pre">H</span></code> and can be defined as the following when the
ranked data does not contain ties.</p>
<div class="math notranslate nohighlight">
\[H = \frac{12}{N(N + 1)} \left[ \frac{\sum_{i=1}^k T_{i}^2}{n_i} - 3(N + 1) \right]\]</div>
<p>If the ranked data contains ties, a correction can be used by dividing <code class="code docutils literal notranslate"><span class="pre">H</span></code> by:</p>
<div class="math notranslate nohighlight">
\[1 - \frac{\sum_{t=1}^G (t_i^3 - t_i)}{N^3 - N}\]</div>
<p>Where <code class="code docutils literal notranslate"><span class="pre">G</span></code> is the number of groups of tied ranks and <code class="code docutils literal notranslate"><span class="pre">t_i</span></code> is the number of
tied values within the <code class="code docutils literal notranslate"><span class="pre">i^{th}</span></code> group. The p-value is usually approximated using
a Chi-Square distribution as calculating exact probabilities can be computationally
intensive for larger sample sizes.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">AnovaOneWay</span></code></dt><dd><p>class containing the implementations of the algorithms and methods used in the conduction of the one-way analysis of variance procedure. The Kruskal-Wallis test can be considered the nonparametric equivalent of the one-way analysis of variance method.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>There are several ways to perform the Kruskal-Wallis test with the <code class="code docutils literal notranslate"><span class="pre">kruskal_wallis</span></code> function.
Similar to the parametric one-way ANOVA method implemented by the <code class="code docutils literal notranslate"><span class="pre">anova_one_way</span></code> function,
one approach is to pass a group vector with the <code class="code docutils literal notranslate"><span class="pre">group</span></code> parameter and the corresponding
observation vector as below.</p>
<p>The data used in this example is a subset of the data obtained from the plant growth
dataset given in Dobson (1983).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">group_vector</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ctrl&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;trt1&#39;</span><span class="p">,</span> <span class="s1">&#39;trt1&#39;</span><span class="p">,</span> <span class="s1">&#39;trt1&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="s1">&#39;trt2&#39;</span><span class="p">,</span> <span class="s1">&#39;trt2&#39;</span><span class="p">,</span> <span class="s1">&#39;trt2&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">observation_vec</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.17</span><span class="p">,</span> <span class="mf">5.58</span><span class="p">,</span> <span class="mf">5.18</span><span class="p">,</span>
<span class="gp">... </span>                   <span class="mf">4.81</span><span class="p">,</span> <span class="mf">4.17</span><span class="p">,</span> <span class="mf">4.41</span><span class="p">,</span>
<span class="gp">... </span>                   <span class="mf">5.31</span><span class="p">,</span> <span class="mf">5.12</span><span class="p">,</span> <span class="mf">5.54</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kw</span> <span class="o">=</span> <span class="n">KruskalWallis</span><span class="p">(</span><span class="n">observation_vec</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">group_vector</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kw</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;alpha&#39;: 0.05,</span>
<span class="go"> &#39;critical chisq value&#39;: 3.1148459383753497,</span>
<span class="go"> &#39;degrees of freedom&#39;: 2,</span>
<span class="go"> &#39;least significant difference&#39;: 4.916428084371546,</span>
<span class="go"> &#39;p-value&#39;: 0.21067829669685478,</span>
<span class="go"> &#39;t-value&#39;: 2.4469118487916806,</span>
<span class="go"> &#39;test description&#39;: &#39;Kruskal-Wallis rank sum test&#39;}</span>
</pre></div>
</div>
<p>The other approach is to pass each group sample vector similar to the below.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ctrl</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.17</span><span class="p">,</span> <span class="mf">5.58</span><span class="p">,</span> <span class="mf">5.18</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trt1</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.81</span><span class="p">,</span> <span class="mf">4.17</span><span class="p">,</span> <span class="mf">4.41</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trt2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.31</span><span class="p">,</span> <span class="mf">5.12</span><span class="p">,</span> <span class="mf">5.54</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kw2</span> <span class="o">=</span> <span class="n">KruskalWallis</span><span class="p">(</span><span class="n">ctrl</span><span class="p">,</span> <span class="n">trt1</span><span class="p">,</span> <span class="n">trt2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kw2</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;alpha&#39;: 0.05,</span>
<span class="go"> &#39;critical chisq value&#39;: 3.1148459383753497,</span>
<span class="go"> &#39;degrees of freedom&#39;: 2,</span>
<span class="go"> &#39;least significant difference&#39;: 4.916428084371546,</span>
<span class="go"> &#39;p-value&#39;: 0.21067829669685478,</span>
<span class="go"> &#39;t-value&#39;: 2.4469118487916806,</span>
<span class="go"> &#39;test description&#39;: &#39;Kruskal-Wallis rank sum test&#39;}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, May 21). Kruskal–Wallis one-way analysis of variance.</dt><dd><p>In Wikipedia, The Free Encyclopedia. From
<a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945">https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">MannWhitney</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the nonparametric Mann-Whitney U test of two independent sample groups.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>array-like</em>) – One-dimensional array-like (Pandas Series or DataFrame, Numpy array, or list)
designating first sample observation values.</p></li>
<li><p><strong>y2</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array-like (Pandas Series or DataFrame, Numpy array, or list)
designating second sample observation values.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series or DataFrame, or list) that defines
the group membership of the sample vector(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em>) – If True, apply the continuity correction of <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> to the
mean rank.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.y1">
<span class="sig-name descname"><span class="pre">y1</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.y1" title="Permalink to this definition"></a></dt>
<dd><p>First sample observation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.y2">
<span class="sig-name descname"><span class="pre">y2</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.y2" title="Permalink to this definition"></a></dt>
<dd><p>Second sample observation vector, if passed. Otherwise, will return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.n1">
<span class="sig-name descname"><span class="pre">n1</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.n1" title="Permalink to this definition"></a></dt>
<dd><p>Number of sample observations in the first sample vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.n2">
<span class="sig-name descname"><span class="pre">n2</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.n2" title="Permalink to this definition"></a></dt>
<dd><p>Number of sample observations in the second sample vector. If no second observation vector was
passed, will return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.n" title="Permalink to this definition"></a></dt>
<dd><p>Total number of sample observations (sum of <code class="code docutils literal notranslate"><span class="pre">n1</span></code> and <code class="code docutils literal notranslate"><span class="pre">n2</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.continuity" title="Permalink to this definition"></a></dt>
<dd><p>If True, continuity correction is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.U">
<span class="sig-name descname"><span class="pre">U</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.U" title="Permalink to this definition"></a></dt>
<dd><p>Computed U-statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.meanrank">
<span class="sig-name descname"><span class="pre">meanrank</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.meanrank" title="Permalink to this definition"></a></dt>
<dd><p>The mean of the ranked sample observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.sigma">
<span class="sig-name descname"><span class="pre">sigma</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.sigma" title="Permalink to this definition"></a></dt>
<dd><p>The calculated standard deviation, <span class="math notranslate nohighlight">\(\sigma_U\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.z_value">
<span class="sig-name descname"><span class="pre">z_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.z_value" title="Permalink to this definition"></a></dt>
<dd><p>Standardized <span class="math notranslate nohighlight">\(z\)</span> value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.p_value" title="Permalink to this definition"></a></dt>
<dd><p>Computed p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MannWhitney.effect_size">
<span class="sig-name descname"><span class="pre">effect_size</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MannWhitney.effect_size" title="Permalink to this definition"></a></dt>
<dd><p>Calculated estimated Cohen’s effect size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The Mann-Whitney U test is a nonparametric hypothesis test that tests the null hypothesis that
there is an equally likely chance that a randomly selected observation from one sample will be
less than or greater than a randomly selected observation from a second sample. Nonparametric
methods are so named since they do not rely on the assumption of normality of the data.</p>
<p>The test statistic in the Mann-Whitney setting is denoted as <span class="math notranslate nohighlight">\(U\)</span> and is the minimum of
the summed ranks of the two samples. The null hypothesis is rejected if <span class="math notranslate nohighlight">\(U \leq U_0\)</span>,
where <span class="math notranslate nohighlight">\(U_0\)</span> is found in a table for small sample sizes. For larger sample sizes,
<span class="math notranslate nohighlight">\(U\)</span> is approximately normally distributed.</p>
<p>The test is nonparametric in the sense it uses the ranks of the values rather than the values
themselves. Therefore, the values are ordered then ranked from 1 (smallest value) to the largest
value. Ranks of tied values get the mean of the ranks the values would have received. For example,
for a set of data points <span class="math notranslate nohighlight">\(\{4, 7, 7, 8\}\)</span> the ranks are <span class="math notranslate nohighlight">\(\{1, 2.5, 2.5, 4\}\)</span>. The
<span class="math notranslate nohighlight">\(2.5\)</span> rank comes from <span class="math notranslate nohighlight">\(2 + 3 = 5 / 2\)</span>. The ranks are then added for the values for
both samples. The sum of the ranks for each sample are typically denoted by <span class="math notranslate nohighlight">\(R_k\)</span> where
<span class="math notranslate nohighlight">\(k\)</span> is a sample indicator.</p>
<p><span class="math notranslate nohighlight">\(U\)</span> for the two samples in the test, is given by:</p>
<div class="math notranslate nohighlight">
\[U_1 = R_1 - \frac{n_1(n_1 + 1)}{2}
U_2 = R_2 - \frac{n_2(n_2 + 1)}{2}\]</div>
<p>Where <span class="math notranslate nohighlight">\(R_1\)</span> and <span class="math notranslate nohighlight">\(R_2\)</span> are the sum of the ranks of the two samples.</p>
<p class="rubric">Examples</p>
<p>Similar to the <code class="code docutils literal notranslate"><span class="pre">anova_one_way</span></code> function, there are several ways to perform a Mann-Whitney
U test with the <code class="code docutils literal notranslate"><span class="pre">mann_whitney</span></code> function. One of these approaches is to pass the sample data
vector and a group vector of the same length denoting group membership of the sample observations.</p>
<p>The data used in this example is a subset of the professor salary dataset found in Fox and
Weisberg (2011).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">professor_discipline</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">professor_salary</span> <span class="o">=</span> <span class="p">[</span><span class="mi">139750</span><span class="p">,</span> <span class="mi">173200</span><span class="p">,</span> <span class="mi">79750</span><span class="p">,</span> <span class="mi">11500</span><span class="p">,</span> <span class="mi">141500</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="mi">103450</span><span class="p">,</span> <span class="mi">124750</span><span class="p">,</span> <span class="mi">137000</span><span class="p">,</span> <span class="mi">89565</span><span class="p">,</span> <span class="mi">102580</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mw</span> <span class="o">=</span> <span class="n">MannWhitney</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">professor_discipline</span><span class="p">,</span> <span class="n">y1</span><span class="o">=</span><span class="n">professor_salary</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mw</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;U&#39;: 10.0,</span>
<span class="go"> &#39;continuity&#39;: True,</span>
<span class="go"> &#39;mu meanrank&#39;: 13.0,</span>
<span class="go"> &#39;p-value&#39;: 0.5308693039685082,</span>
<span class="go"> &#39;sigma&#39;: 4.7871355387816905,</span>
<span class="go"> &#39;test description&#39;: &#39;Mann-Whitney U test&#39;,</span>
<span class="go"> &#39;z-value&#39;: 0.6266795614405122}</span>
</pre></div>
</div>
<p>The other approach is to pass each group sample observation vector.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sal_a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">139750</span><span class="p">,</span> <span class="mi">173200</span><span class="p">,</span> <span class="mi">79750</span><span class="p">,</span> <span class="mi">11500</span><span class="p">,</span> <span class="mi">141500</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sal_b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">103450</span><span class="p">,</span> <span class="mi">124750</span><span class="p">,</span> <span class="mi">137000</span><span class="p">,</span> <span class="mi">89565</span><span class="p">,</span> <span class="mi">102580</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mw2</span> <span class="o">=</span> <span class="n">MannWhitney</span><span class="p">(</span><span class="n">sal_a</span><span class="p">,</span> <span class="n">sal_b</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mw2</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;U&#39;: 10.0,</span>
<span class="go"> &#39;continuity&#39;: True,</span>
<span class="go"> &#39;mu meanrank&#39;: 13.0,</span>
<span class="go"> &#39;p-value&#39;: 0.5308693039685082,</span>
<span class="go"> &#39;sigma&#39;: 4.7871355387816905,</span>
<span class="go"> &#39;test description&#39;: &#39;Mann-Whitney U test&#39;,</span>
<span class="go"> &#39;z-value&#39;: 0.6266795614405122}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
</dl>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<dl class="simple">
<dt>Mann–Whitney U test. (2017, June 20). In Wikipedia, The Free Encyclopedia.</dt><dd><p>From <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Mann%E2%80%93Whitney_U_test&amp;oldid=786593885">https://en.wikipedia.org/w/index.php?title=Mann%E2%80%93Whitney_U_test&amp;oldid=786593885</a></p>
</dd>
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">MedianTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ties</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'below'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">posthoc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Mood’s Median test for k samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample1</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample may be of different lengths.</p></li>
<li><p><strong>sample2</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample may be of different lengths.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – One-dimensional array-like objects (numpy array, list, pandas DataFrame or pandas Series) containing the
observed sample data. Each sample may be of different lengths.</p></li>
<li><p><strong>ties</strong> (<em>str</em><em>, </em><em>{'below'</em><em>, </em><em>'above'</em><em>, </em><em>'ignore'}</em>) – Method for handling tied observations when sorting the observations into the above and below rows of the
contingency table. If ‘below’ (default), values less than or equal to the median are added to the bottom
row of the contingency table. If ‘above’, values less than to median are used.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>default True</em>) – If True, a continuity correction was applied when the Median test is performed. If False, no continuity
correction is applied.</p></li>
<li><p><strong>posthoc</strong> (<em>bool</em><em>, </em><em>default False</em>) – </p></li>
<li><p><strong>names</strong> (<em>array-like</em><em>, </em><em>default None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.observation_vectors">
<span class="sig-name descname"><span class="pre">observation_vectors</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.observation_vectors" title="Permalink to this definition"></a></dt>
<dd><p>The passed observation vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.combined_array">
<span class="sig-name descname"><span class="pre">combined_array</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.combined_array" title="Permalink to this definition"></a></dt>
<dd><p>One-dimensional array of all the observation vectors combined.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.grand_median">
<span class="sig-name descname"><span class="pre">grand_median</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.grand_median" title="Permalink to this definition"></a></dt>
<dd><p>Grand median of the arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.n" title="Permalink to this definition"></a></dt>
<dd><p>The total sample size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.degrees_of_freedom">
<span class="sig-name descname"><span class="pre">degrees_of_freedom</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.degrees_of_freedom" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom, defined as the number of observations vectors - 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.ties">
<span class="sig-name descname"><span class="pre">ties</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.ties" title="Permalink to this definition"></a></dt>
<dd><p>The tie decision method.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.continuity" title="Permalink to this definition"></a></dt>
<dd><p>If True, a continuity correction was applied when the Median test was performed. If False, no continuity
correction is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.contingency_table">
<span class="sig-name descname"><span class="pre">contingency_table</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.contingency_table" title="Permalink to this definition"></a></dt>
<dd><p>The computed <span class="math notranslate nohighlight">\(2 \times k\)</span> table of the number of samples above the grand median (in the first row) and
below the grand median (second row).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.test_statistic">
<span class="sig-name descname"><span class="pre">test_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.test_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The computed chi-square test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The associated p-value of the test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.posthoc">
<span class="sig-name descname"><span class="pre">posthoc</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.posthoc" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>pandas DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.MedianTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.MedianTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>A dictionary containing the test summary statistics including the contigency table, grand median, p-value, and
test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ValueError</strong> – Raised if the <code class="code docutils literal notranslate"><span class="pre">ties</span></code> parameter is not one of {‘below’ (default), ‘above’, ‘ignore’}</p></li>
<li><p><strong>ValueError</strong> – Raised the <code class="code docutils literal notranslate"><span class="pre">names</span></code> parameter does not have the same length as the number of observation vectors when
    performing a post-hoc test.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The median test, sometimes referred to as Mood’s median test, is a nonparametric procedure for investigating
whether the median of the populations from which <span class="math notranslate nohighlight">\(k\)</span> sample groups are drawn is equal. The test is a special
case of the chi-square test of dependence. The null and alternative hypotheses when employing the median test may
be written similarly as:</p>
<div class="math notranslate nohighlight">
\[$H_0$: All $k$ populations have the same median.
$H_A$: At least two of the $k$ populations have the different medians.\]</div>
<p>Given <span class="math notranslate nohighlight">\(k\)</span> samples with <span class="math notranslate nohighlight">\(n_1, n_2, \cdots, n_k\)</span> data observations, the median test proceeds by computing
the grand median of the combined observations. A <span class="math notranslate nohighlight">\(2 \times k\)</span> contingency table is then constructed, where
the top row contains the number of total observations above the grand median for each of the <span class="math notranslate nohighlight">\(k\)</span> sample
groups and the bottom row is the number of observations below the grand median. Ties between the individual
observations and the grand median are either put in the top or bottom row, or discarded entirely. A chi-square test
of independence is then performed on the constructed <span class="math notranslate nohighlight">\(2 \times k\)</span> contingency table.</p>
<p>The test statistic of the median test, typically denoted <span class="math notranslate nohighlight">\(T\)</span>, is defined as:</p>
<p>Where <span class="math notranslate nohighlight">\(a\)</span> is the marginal total of the <span class="math notranslate nohighlight">\(2 \times k\)</span> contingency table for observations above the grand
median while $b$ is the marginal total for those observations below the grand median. The test statistic is assumed
to have a chi-square distribution where the degrees of freedom is defined as <span class="math notranslate nohighlight">\(k - 1\)</span>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">g1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">49</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">91</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">99</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">34</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">46</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">67</span><span class="p">,</span> <span class="mi">84</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">MedianTest</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">,</span> <span class="n">g3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;contingency_table&#39;: array([[ 5, 10,  7],</span>
<span class="go">                            [11,  5, 10]]),</span>
<span class="go"> &#39;grand median&#39;: 34.0,</span>
<span class="go"> &#39;p-value&#39;: 0.12609082774093244,</span>
<span class="go"> &#39;test_statistic&#39;: 4.141505553270259}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
<p><a class="reference external" href="https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/meditest.htm">https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/meditest.htm</a></p>
<p><a class="reference external" href="https://psych.unl.edu/psycrs/handcomp/hcmedian.PDF">https://psych.unl.edu/psycrs/handcomp/hcmedian.PDF</a></p>
<dl class="simple">
<dt>Wikipedia contributors. (2017, June 27). Median test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 12:23, August 19, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Median_test&amp;oldid=787822318">https://en.wikipedia.org/w/index.php?title=Median_test&amp;oldid=787822318</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.RunsTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">RunsTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.RunsTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the non-parametric one-sample runs test for determining if a sample is random.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – One-dimensional array-like (Pandas Series or DataFrame, Numpy array, or list)
designating first sample observation values.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>default True</em>) – If True, continuity correction is applied when calculating the z-score.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.RunsTest.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.RunsTest.x" title="Permalink to this definition"></a></dt>
<dd><p>Numpy array of given data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.RunsTest.runs">
<span class="sig-name descname"><span class="pre">runs</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.RunsTest.runs" title="Permalink to this definition"></a></dt>
<dd><p>Count and location of runs in given data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.RunsTest.r">
<span class="sig-name descname"><span class="pre">r</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.RunsTest.r" title="Permalink to this definition"></a></dt>
<dd><p>The number of runs in specified data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.RunsTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.RunsTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing relevant computed test statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The runs test is a non-parametric test that examines the order or sequence of elements in a two-element
(heads/tails, plus/minus, etc.) one-dimensional array to determine if the sample is random. For example, the
following array of coin tosses has eight total ‘runs’.</p>
<div class="math notranslate nohighlight">
\[H T H H T T H H H T H T\]</div>
<p>When testing the randomness of small samples, the critical values of the test are determined from a critical
value table. Small samples are typically defined as samples with each binary response not having equal to or more
than 20 values. For example, the above array has <span class="math notranslate nohighlight">\(n_1 = H = 7\)</span> and <span class="math notranslate nohighlight">\(n_2 = T = 5\)</span> and thus would be
designated as a small sample. Two critical value tables exist for the one-sample runs test. The first table,
typically denoted <span class="math notranslate nohighlight">\(F_1\)</span>, gives values of which are small enough that the probability associated with
their occurrence under the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> is <span class="math notranslate nohighlight">\(p = 0.025\)</span>. The second critical value table,
typically denoted <span class="math notranslate nohighlight">\(F_{11}\)</span> gives values of <span class="math notranslate nohighlight">\(r\)</span> which are large enough that the probability associated
with their occurrence under the null hypothesis is <span class="math notranslate nohighlight">\(p = 0.025\)</span>. Thus, any observed value of the number of
runs, <span class="math notranslate nohighlight">\(r\)</span> is equal to or less than the value shown in <span class="math notranslate nohighlight">\(F_1\)</span> or is equal to or larger than the value
shown in <span class="math notranslate nohighlight">\(F_{11}\)</span> is in the region of rejection. Critical values are given for <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>.</p>
<p>When the number of samples is large enough (each binary response having equal to or more than 20 responses), the
sampling distribution becomes close enough to a normal distribution to use as an approximation.</p>
<p>The mean of the sampling distribution <span class="math notranslate nohighlight">\(\mu_r\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\mu_r = \frac{2n_1 n_2}{n_1 + n_2} + 1\]</div>
<p>with variance of the sampling distribution <span class="math notranslate nohighlight">\(\sigma^2\)</span> defined as:</p>
<div class="math notranslate nohighlight">
\[\sigma^2_r = \frac{2 n_1 n_2 (2n_1 n_2 - n_1 - n_2)}{(n_1 + n_2)^2 (n_1 + n_2 - 1)}\]</div>
<p>Thus, a z-score can be computed to test the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[z = \frac{r - \mu_r}{\sigma_r} = \frac{r - \large(\frac{2n_1 n_2}{n_1 + n_2} + 1 \large)}{\sqrt{\sigma^2_r = \frac{2 n_1 n_2 (2n_1 n_2 - n_1 - n_2)}{(n_1 + n_2)^2 (n_1 + n_2 - 1)}}}\]</div>
<p>As the sample is approximately normally distributed, the critical value of the z-score can be found using the
cumulative normal distribution function.</p>
<p>If continuity correction is applied, the z-score is calculated as:</p>
<div class="math notranslate nohighlight">
\[z = \frac{|r - \mu_r| - 0.5}{\sigma_r}\]</div>
<p>Where <span class="math notranslate nohighlight">\(r\)</span>, <span class="math notranslate nohighlight">\(\mu_r\)</span> and <span class="math notranslate nohighlight">\(\sigma_r\)</span> are defined the same as above.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;f&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">RunsTest</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span><span class="o">.</span><span class="n">r</span>
<span class="go">12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span><span class="o">.</span><span class="n">runs</span>
<span class="go">array([1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;probability&#39;: 0.7672105672105671,</span>
<span class="go"> &#39;r critical value 1&#39;: 4,</span>
<span class="go"> &#39;r critical value 2&#39;: 13}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. “Wald–Wolfowitz runs test.” Wikipedia, The Free Encyclopedia.</dt><dd><p>Wikipedia, The Free Encyclopedia, 8 Jun. 2019. Web. 29 Sep. 2019.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">SignTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'two-sided'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Computes the nonparametric sign test of differences between paired observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – </p></li>
<li><p><strong>y</strong> (<em>array-like</em><em>, </em><em>optional</em>) – </p></li>
<li><p><strong>alternative</strong> (<em>str</em><em>, </em><em>{'two-sided'</em><em>, </em><em>'greater'</em><em>, </em><em>'less'}</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.x" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.y">
<span class="sig-name descname"><span class="pre">y</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.y" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.alternative">
<span class="sig-name descname"><span class="pre">alternative</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.alternative" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str, {‘two-sided’, ‘greater’, ‘less’}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.n" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.sample_differences">
<span class="sig-name descname"><span class="pre">sample_differences</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.sample_differences" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.sample_differences_median">
<span class="sig-name descname"><span class="pre">sample_differences_median</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.sample_differences_median" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.difference_counts">
<span class="sig-name descname"><span class="pre">difference_counts</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.difference_counts" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.p_value" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.SignTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.SignTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">SignTest</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;differences count&#39;: {&#39;negative&#39;: 3, &#39;positive&#39;: 11, &#39;ties&#39;: 3},</span>
<span class="go"> &#39;median difference&#39;: 2.0,</span>
<span class="go"> &#39;p-value&#39;: 0.0286865234375}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, July 25). Sign test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 14:52, August 23, 2018, from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Sign_test&amp;oldid=851943717">https://en.wikipedia.org/w/index.php?title=Sign_test&amp;oldid=851943717</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">VanDerWaerden</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_hoc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the Van Der Waerden (normal scores) test for testing if k groups have the same distribution
function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>default 0.05</em>) – Desired alpha level for testing for significance.</p></li>
<li><p><strong>post-hoc</strong> (<em>bool</em><em>, </em><em>default True</em>) – If True, a post-hoc multiple comparisons test is performed.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.ranked_matrix">
<span class="sig-name descname"><span class="pre">ranked_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.ranked_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix with ranked observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.normal_score_matrix">
<span class="sig-name descname"><span class="pre">normal_score_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.normal_score_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix with ranked observations and computed normal test scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.average_scores">
<span class="sig-name descname"><span class="pre">average_scores</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.average_scores" title="Permalink to this definition"></a></dt>
<dd><p>List of tuples containing each group name and its respective average normal score.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_statistic">
<span class="sig-name descname"><span class="pre">test_statistic</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_statistic" title="Permalink to this definition"></a></dt>
<dd><p>The computed Van Der Waerden test statistic, denoted <span class="math notranslate nohighlight">\(T_1\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.p_value">
<span class="sig-name descname"><span class="pre">p_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.p_value" title="Permalink to this definition"></a></dt>
<dd><p>The p-value of the calculated <span class="math notranslate nohighlight">\(T_1\)</span> test statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.alpha" title="Permalink to this definition"></a></dt>
<dd><p>Desired alpha level for testing for significance.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.group">
<span class="sig-name descname"><span class="pre">group</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.group" title="Permalink to this definition"></a></dt>
<dd><p>One-dimensional numpy array of the passed or coerced group array.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.n" title="Permalink to this definition"></a></dt>
<dd><p>Number of total observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of groups</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_description">
<span class="sig-name descname"><span class="pre">test_description</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_description" title="Permalink to this definition"></a></dt>
<dd><p>Test performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.VanDerWaerden.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The Van der Waerden test is a non-parametric test for testing the assumption that <span class="math notranslate nohighlight">\(k\)</span> sample distribution
functions are equal. Van der Waerden’s test is similar to the Kruskal-Wallis one-way analysis of variance test in
that it converts the data to ranks and then to standard normal distribution quantiles which are designated as the
‘normal scores’.</p>
<p>The benefit of Van der Waerden’s test is that it is performant compared to ANOVA (analysis of variance) when the
samples are normally distributed and the Kruskal-Wallis test when the samples are not normally distributed.</p>
<p>The null and alternative hypotheses of the Van der Waerden test can be stated generally as follows:</p>
<p><span class="math notranslate nohighlight">\(H_0\)</span>: All of the <span class="math notranslate nohighlight">\(k\)</span> population distribution functions are equal
<span class="math notranslate nohighlight">\(H_A\)</span>: At least one of the <span class="math notranslate nohighlight">\(k\)</span> population distribution functions are not equal and tend to yield larger
observations to the other distribution functions.</p>
<p>Let <span class="math notranslate nohighlight">\(n_j\)</span>, be the number of samples for each of the <span class="math notranslate nohighlight">\(k\)</span> groups where <span class="math notranslate nohighlight">\(j\)</span> is the j-th group.
<span class="math notranslate nohighlight">\(N\)</span> is the number of total samples in all groups, while <span class="math notranslate nohighlight">\(X_{ij}\)</span> is the i-th value of the j-th group.
The normal scores used in the Van der Waerden test are calculated as:</p>
<div class="math notranslate nohighlight">
\[A_{ij} = \Phi^{-1} \left( \frac{R \left( X_{ij} \right)}{N + 1} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(R(X_{ij})\)</span> and <span class="math notranslate nohighlight">\(phi^{-1}\)</span> are the ranks of the <span class="math notranslate nohighlight">\(X_{ij}\)</span> observation and the normal
quantile function (percent point function), respectively. The average normal scores can then be calculated as:</p>
<div class="math notranslate nohighlight">
\[\bar{A}_j = \frac{1}{n_j} \sum^{n_j}_{i=1} A_{ij} \qquad j = 1, 2, \cdots, k\]</div>
<p>The variance <span class="math notranslate nohighlight">\(s^2\)</span> of the normal scores is defined as:</p>
<div class="math notranslate nohighlight">
\[s^2 = \frac{1}{N - 1} \sum^k_{i=1} \sum^{n_i}_{j=1} A^2_{ij}\]</div>
<p>The Van der Waerden test statistic, <span class="math notranslate nohighlight">\(T_1\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[T_1 = \frac{1}{s^2} \sum^k_{i=1} n_i (\bar{A}_i)^2\]</div>
<p>As the test is approximate to a chi-square distribution, the critical region for a significance level <span class="math notranslate nohighlight">\(\alpha\)</span>
is:</p>
<div class="math notranslate nohighlight">
\[T_1 = \chi^2_{\alpha, k-1}\]</div>
<p>When the null hypothesis is rejected (p-value within the critical region) and at least one of the sample
distribution functions differs, a post-hoc multiple comparions test can be performed to get a better sense of
which populations differ from the others. Two sample populations, <span class="math notranslate nohighlight">\(j_1\)</span> and <span class="math notranslate nohighlight">\(j_2\)</span>, tend to be different
if the following is true:</p>
<div class="math notranslate nohighlight">
\[| \bar{A}_{j_1} - \bar{A}_{j_2} | &gt; st_{1-\alpha/2} \sqrt{\frac{N-1-T_1}{N-k}} \sqrt{\frac{1}{n_{j_1}} + \frac{1}{n_{j_2}}}\]</div>
<p class="rubric">Examples</p>
<p class="rubric">References</p>
<p>Conover, W. J. (1999). Practical Nonparameteric Statistics (Third ed.). Wiley.</p>
<dl class="simple">
<dt>Wikipedia contributors. “Van der Waerden test.” Wikipedia, The Free Encyclopedia.</dt><dd><p>Wikipedia, The Free Encyclopedia, 8 Feb. 2017. Web. 8 Mar. 2020.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">WaldWolfowitz</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs the Wald-Wolfowitz Two-Sample runs test for two independent samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – First sample observation vector.</p></li>
<li><p><strong>y</strong> (<em>array-like</em>) – Second sample observation vector.</p></li>
<li><p><strong>continuity</strong> (<em>bool</em><em>, </em><em>default True</em>) – If True, continuity correction is applied during the Wald-Wolfowitz test procedure.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.x">
<span class="sig-name descname"><span class="pre">x</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.x" title="Permalink to this definition"></a></dt>
<dd><p>First sample observation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.y">
<span class="sig-name descname"><span class="pre">y</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.y" title="Permalink to this definition"></a></dt>
<dd><p>Second sample observation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.continuity">
<span class="sig-name descname"><span class="pre">continuity</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.continuity" title="Permalink to this definition"></a></dt>
<dd><p>If True, continuity correction is applied during the Wald-Wolfowitz test procedure.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.runs">
<span class="sig-name descname"><span class="pre">runs</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.runs" title="Permalink to this definition"></a></dt>
<dd><p>The number of total runs in the ranked and ordered samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.probability">
<span class="sig-name descname"><span class="pre">probability</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.probability" title="Permalink to this definition"></a></dt>
<dd><p>The estimated proability of getting an observed value of <span class="math notranslate nohighlight">\(r\)</span> or smaller.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.z">
<span class="sig-name descname"><span class="pre">z</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.z" title="Permalink to this definition"></a></dt>
<dd><p>The computed z-score.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WaldWolfowitz.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary containing relevant test summary statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">45</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">14</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">nonparametric</span><span class="o">.</span><span class="n">WaldWolfowitz</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;probability&#39;: 0.051136902411265235,</span>
<span class="go"> &#39;runs&#39;: 6,</span>
<span class="go"> &#39;mean of runs&#39;: 12.586206896551724,</span>
<span class="go"> &#39;standard deviation of runs&#39;: 2.0929642628266922,</span>
<span class="go"> &#39;z-value&#39;: 2.907936367882308,</span>
<span class="go"> &#39;p-value&#39;: 0.0018191117963075613,</span>
<span class="go"> &#39;continuity&#39;: True}</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The Wald-Wolfowitz runs test is used to test the hypothesis that two independent samples have been drawn from the
same population rejects the hypothesis if the two samples differ in any way. The Wald-Wolfowitz test is useful in
that it can be used to test if two samples differ in more than one respect, whether that be central tendency,
variance, skewness, kurtosis, and so on.</p>
<p>Before the test is performed, the two samples are ordered and ranked, keeping their group membership but as a
single array. Depending on the sample sizes of both samples, the test either uses a critical value table or
is approximated using a normal distribution.</p>
<p>The sampling distribution of the observed runs <span class="math notranslate nohighlight">\(r\)</span> stems from when the two samples are ordered into a single
array, the total number of possible arrangements becomes binomial.</p>
<div class="math notranslate nohighlight">
\[\binom{n_1 + n_2}{n_1} = \binom{n_1 + n_2}{n_2}\]</div>
<p>It can then be shown that the probability of getting an observed value of the runs <span class="math notranslate nohighlight">\(r\)</span> or a smaller value
when the value of <span class="math notranslate nohighlight">\(r\)</span> is even is:</p>
<div class="math notranslate nohighlight">
\[p(r \geq r^{\prime}) = \frac{1}{\binom{n_1 + n_2}{n_1}} \sum^{r^{\prime}}_{r=2} (2) \binom{n_1 - 1}{\frac{r}{2} - 1} \binom{n_2 - 1}{\frac{r}{2} - 1}\]</div>
<p>When <span class="math notranslate nohighlight">\(r\)</span> is odd, the probability is defined as:</p>
<div class="math notranslate nohighlight">
\[p(r \geq r^{\prime}) = \frac{1}{\binom{n_1 + n_2}{n_1}} \sum^{r^{\prime}}_{r=2} \Bigg[ \binom{n_1 - 1}{k - 1} \binom{n_2 - 1}{k - 2} + \binom{n_1 - 1}{k - 2} \binom{n_2 - 1}{k - 1} \Bigg]\]</div>
<p>where <span class="math notranslate nohighlight">\(r = 2k - 1\)</span></p>
<p>In the case of small samples, (<span class="math notranslate nohighlight">\(n_1, n_2 \geq 20\)</span>), a critical value table is used to determine the
significance at a alpha of 0.05. For example, if the observed runs value, <span class="math notranslate nohighlight">\(r\)</span> is equal to or less than the
corresponding value in the critical value table, the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> may be rejected at a significance
level of 0.05. Conversely, if the observed <span class="math notranslate nohighlight">\(r\)</span> value is greater than the corresponding value in the table,
then the null hypothesis cannot be rejected.</p>
<p>When the small sample case does not apply, the sampling distribution of <span class="math notranslate nohighlight">\(r\)</span> under the null hypothesis is
approximately normal.</p>
<p>The mean is defined as:</p>
<div class="math notranslate nohighlight">
\[\mu_r = \frac{2n_1 n_2}{n_1 + n_2} + 1\]</div>
<p>With standard deviation:</p>
<div class="math notranslate nohighlight">
\[\sigma_r = \sqrt{\frac{2n_1n_2(2n_1n_2 - n_1 - n_2)}{(n_1 + n_2)^2(n_1 + n_2 - 1)}}\]</div>
<p>The z-score, :math:<a href="#id5"><span class="problematic" id="id6">`</span></a>z = frac{r - mu_r}{sigma_r}, can then be defined as:</p>
<div class="math notranslate nohighlight">
\[z = \frac{r - \large(\frac{2n_1 n_2}{n_1 + n_2} + 1 \large)}{\sqrt{\frac{2n_1n_2(2n_1n_2 - n_1 - n_2)}{(n_1 + n_2)^2(n_1 + n_2 - 1)}}}\]</div>
<p>In the case of large samples, the sampling distribution is normally distributed with zero mean and variance.</p>
<p>When the large sample setting applies but the total sample size <span class="math notranslate nohighlight">\(N = (n_1 + n_2)\)</span> is still not quite large
(large unfortunately still being somewhat subjective; however, generally this implies that the sample size is not
large enough for the assumption of an approximately normally distributed sample to hold), a continuity correction
is recommended (and in some cases required). The continuity correction is performed by subtracting <span class="math notranslate nohighlight">\(0.5\)</span>
from the absolute difference between the observed runs <span class="math notranslate nohighlight">\(r\)</span> and the mean <span class="math notranslate nohighlight">\(\mu_r\)</span> in the z-score computation.</p>
<div class="math notranslate nohighlight">
\[z = \frac{|r - \mu_r| - .5}{\sigma_r}\]</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
<dt>Wikipedia contributors. (2018, August 22). Wald–Wolfowitz runs test. In Wikipedia, The Free Encyclopedia.</dt><dd><p>Retrieved 13:54, September 13, 2018,
from <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Wald%E2%80%93Wolfowitz_runs_test&amp;oldid=856082551">https://en.wikipedia.org/w/index.php?title=Wald%E2%80%93Wolfowitz_runs_test&amp;oldid=856082551</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">WilcoxonTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paired</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alternative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'two-sided'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Wilcoxon Rank Sum tests for matched pairs and independent samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y1</strong> (<em>array-like</em>) – One-dimensional array-like (Pandas Series or DataFrame, Numpy array, or list)
designating first sample observation values.</p></li>
<li><p><strong>y2</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array-like (Pandas Series or DataFrame, Numpy array, or list)
designating second sample observation values.</p></li>
<li><p><strong>paired</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, performs a paired Wilcoxon Rank Sum test.</p></li>
<li><p><strong>mu</strong> (<em>float</em><em>, </em><em>optional</em>) – Optional parameter to specify the value to form the null hypothesis.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.y1">
<span class="sig-name descname"><span class="pre">y1</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.y1" title="Permalink to this definition"></a></dt>
<dd><p>First sample observation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.y2">
<span class="sig-name descname"><span class="pre">y2</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.y2" title="Permalink to this definition"></a></dt>
<dd><p>Second sample observation vector, if passed. Otherwise, will return None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Number of sample observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.V">
<span class="sig-name descname"><span class="pre">V</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.V" title="Permalink to this definition"></a></dt>
<dd><p>Wilcoxon <span class="math notranslate nohighlight">\(V\)</span>-statistic (also denoted <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(U\)</span> in some literature).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.z">
<span class="sig-name descname"><span class="pre">z</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.z" title="Permalink to this definition"></a></dt>
<dd><p>The standardized z-statistic.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.p">
<span class="sig-name descname"><span class="pre">p</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.p" title="Permalink to this definition"></a></dt>
<dd><p>p-value.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.WilcoxonTest.effect_size">
<span class="sig-name descname"><span class="pre">effect_size</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.WilcoxonTest.effect_size" title="Permalink to this definition"></a></dt>
<dd><p>The estimated effect size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The Wilcoxon Rank Sum test is the nonparametric equivalent to a matched pairs or independent sample
t-test and is also closely related to the Mann Whitney U-test for independent samples. In fact, the
Wilcoxon Rank Sum test for two independent samples is equivalent to the Mann Whitney U-test. The
respective test statistics <span class="math notranslate nohighlight">\(W\)</span> (Mann-Whitney) and <span class="math notranslate nohighlight">\(U\)</span> (Wilcoxon Rank Sum) are related
in the following way:</p>
<div class="math notranslate nohighlight">
\[U = W - \frac{n_1 (n_1 + 1)}{2}\]</div>
<p>The test procedure can be summarized into the following steps:</p>
<p>1. If the test is for an independent sample, the observations are subtracted by the true mean of
the null hypothesis <span class="math notranslate nohighlight">\(mu\)</span> to obtain the signed differences. In the case of a paired test, the
signed difference between each matched observation vector is found.
2. The signed differences, typically denoted <span class="math notranslate nohighlight">\(d_i\)</span>, are then ranked. Ties receive the average of
the tied ranks.
3. The test statistic <span class="math notranslate nohighlight">\(V\)</span> (or <span class="math notranslate nohighlight">\(T\)</span> in some literature) is then computed by assigning a
<span class="math notranslate nohighlight">\(1\)</span> for ranked values where the corresponding matched pair difference is positive or a
<span class="math notranslate nohighlight">\(0\)</span> for ranked values with a negative corresponding matched pair difference. These values are then
summed to obtain the test statistic.
4. The calculated test statistic can then be used to determine the significance of the observed value.</p>
<p>When two sample observation vectors are passed into the <code class="code docutils literal notranslate"><span class="pre">wilcoxon_test</span></code> function with the parameter
<code class="code docutils literal notranslate"><span class="pre">paired</span> <span class="pre">=</span> <span class="pre">False</span></code>, the Mann-Whitney U-test is performed.</p>
<p class="rubric">Examples</p>
<p>The data used in this example is a subset of the professor salary dataset found in Fox and
Weisberg (2011).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">professor_salary</span> <span class="o">=</span> <span class="p">[</span><span class="mi">139750</span><span class="p">,</span> <span class="mi">173200</span><span class="p">,</span> <span class="mi">79750</span><span class="p">,</span> <span class="mi">11500</span><span class="p">,</span> <span class="mi">141500</span><span class="p">,</span>
<span class="gp">... </span>                    <span class="mi">103450</span><span class="p">,</span> <span class="mi">124750</span><span class="p">,</span> <span class="mi">137000</span><span class="p">,</span> <span class="mi">89565</span><span class="p">,</span> <span class="mi">102580</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">WilcoxonTest</span><span class="p">(</span><span class="n">professor_salary</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">test_summary</span>
<span class="go">{&#39;V&#39;: 55.0,</span>
<span class="go"> &#39;effect size&#39;: 0.8864052604279182,</span>
<span class="go"> &#39;p-value&#39;: 0.005062032126267768,</span>
<span class="go"> &#39;test description&#39;: &#39;Wilcoxon signed rank test&#39;,</span>
<span class="go"> &#39;z-value&#39;: 2.8030595529069404}</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Corder, G.W.; Foreman, D.I. (2014). Nonparametric Statistics: A Step-by-Step Approach.</dt><dd><p>Wiley. ISBN 978-1118840313.</p>
</dd>
</dl>
<p>Fox J. and Weisberg, S. (2011) An R Companion to Applied Regression, Second Edition Sage.</p>
<dl class="simple">
<dt>Siegel, S. (1956). Nonparametric statistics: For the behavioral sciences.</dt><dd><p>McGraw-Hill. ISBN 07-057348-4</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.count_runs">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">count_runs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.count_runs" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>array-like</em>) – </p></li>
<li><p><strong>index</strong> (<em>int</em><em>, </em><em>default 1</em>) – </p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.nonparametric.tie_correction">
<span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.nonparametric.</span></span><span class="sig-name descname"><span class="pre">tie_correction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rank_array</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.nonparametric.tie_correction" title="Permalink to this definition"></a></dt>
<dd><p>Computes the tie correction factor used in nonparametric statistical tests.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>rank_array</strong> (<em>array-like</em>) – 1-d array (numpy array, list, pandas DataFrame or Series) of ranks.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>corr</strong> – The correction factor for <span class="math notranslate nohighlight">\(H\)</span> (or <span class="math notranslate nohighlight">\(U\)</span> for the Mann-Whitney U-test).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The tie correction factor is defined as:</p>
<div class="math notranslate nohighlight">
\[1 - \frac{\sum_{t=1}^G (t_i^3 - t_i)}{N^3 - N}\]</div>
<p>Where <code class="code docutils literal notranslate"><span class="pre">G</span></code> is the number of groups of tied ranks and <code class="code docutils literal notranslate"><span class="pre">t_i</span></code> is the number of
tied values within the <code class="code docutils literal notranslate"><span class="pre">i^{th}</span></code> group.</p>
<p class="rubric">Examples</p>
<p>The ranked values of an observation vector can be easily found using Scipy’s <code class="code docutils literal notranslate"><span class="pre">tiecorrect</span></code>
function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">obs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.17</span><span class="p">,</span> <span class="mf">5.58</span><span class="p">,</span> <span class="mf">5.18</span><span class="p">,</span> <span class="mf">4.81</span><span class="p">,</span> <span class="mf">4.17</span><span class="p">,</span> <span class="mf">4.41</span><span class="p">,</span> <span class="mf">5.31</span><span class="p">,</span> <span class="mf">5.12</span><span class="p">,</span> <span class="mf">5.54</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ranked_obs</span> <span class="o">=</span> <span class="n">rankdata</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ranked_obs</span>
<span class="go">array([1.5, 9. , 6. , 4. , 1.5, 3. , 7. , 5. , 8. ])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tie_correction</span><span class="p">(</span><span class="n">ranked_obs</span><span class="p">)</span>
<span class="go">0.9916666666666667</span>
</pre></div>
</div>
<p class="rubric">References</p>
<dl class="simple">
<dt>Wikipedia contributors. (2018, May 21). Kruskal–Wallis one-way analysis of variance.</dt><dd><p>In Wikipedia, The Free Encyclopedia. From
<a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945">https://en.wikipedia.org/w/index.php?title=Kruskal%E2%80%93Wallis_one-way_analysis_of_variance&amp;oldid=842351945</a></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis.posthoc">
<span id="utilmy-stats-hypothesis-posthoc-module"></span><h2>utilmy.stats.hypothesis.posthoc module<a class="headerlink" href="#module-utilmy.stats.hypothesis.posthoc" title="Permalink to this heading"></a></h2>
<p>Functions for performing post-hoc analysis.</p>
<section id="post-hoc-analysis">
<h3>Post-Hoc Analysis<a class="headerlink" href="#post-hoc-analysis" title="Permalink to this heading"></a></h3>
<dl>
<dt>..autosummary::</dt><dd><dl class="field-list simple">
<dt class="field-odd">toctree</dt>
<dd class="field-odd"><p>generated/</p>
</dd>
</dl>
<p>GamesHowell
TukeysTest</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>Ruxton, G.D., and Beauchamp, G. (2008) ‘Time for some a priori thinking about post hoc testing’,</dt><dd><p>Behavioral Ecology, 19(3), pp. 690-693. doi: 10.1093/beheco/arn020.
In-text citations: (Ruxton and Beauchamp, 2008)</p>
</dd>
</dl>
<p>Post-hoc (no date) Available at: <a class="reference external" href="http://www.unt.edu/rss/class/Jon/ISSS_SC/Module009/isss_m91_onewayanova/node7.html">http://www.unt.edu/rss/class/Jon/ISSS_SC/Module009/isss_m91_onewayanova/node7.html</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.GamesHowell">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.posthoc.</span></span><span class="sig-name descname"><span class="pre">GamesHowell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.GamesHowell" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Computes the Games-Howell posthoc analysis test for multiple group comparisons.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>default 0.05</em>) – Alpha level for computing upper and lower confidence intervals</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.GamesHowell.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.GamesHowell.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.GamesHowell.group">
<span class="sig-name descname"><span class="pre">group</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.GamesHowell.group" title="Permalink to this definition"></a></dt>
<dd><p>Group vector passed or coerced from sample observation vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.GamesHowell.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.GamesHowell.alpha" title="Permalink to this definition"></a></dt>
<dd><p>Alpha level for computing upper and lower confidence intervals</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float, default 0.05</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.GamesHowell.test_result">
<span class="sig-name descname"><span class="pre">test_result</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.GamesHowell.test_result" title="Permalink to this definition"></a></dt>
<dd><p>pandas DataFrame of test results containing each group comparison’s mean difference,
confidence interval, t-value, p-value and standard error.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The Games-Howell post-hoc test is another nonparametric approach to compare combinations of groups
or treatments. Although rather similar to Tukey’s test in its formulation, the Games-Howell test
does not assume equal variances and sample sizes. The test was designed based on Welch’s degrees of
freedom correction and uses Tukey’s studentized range distribution, denoted <span class="math notranslate nohighlight">\(q\)</span>. The Games-Howell
test is performed on the ranked variables similar to other nonparametric tests. Since the Games-Howell
test does not rely on equal variances and sample sizes, it is often recommended over other approaches
such as Tukey’s test.</p>
<p>The Games-Howell test is defined as:</p>
<div class="math notranslate nohighlight">
\[\large \bar{x}_i - \bar{x}_j &gt; q_{\sigma, k, df}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\sigma\)</span> is equal to standard error:</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{{\frac{1}{2} \left(\frac{s^2_i}{n_i} + \frac{s^2_j}{n_j}\right)}}\]</div>
<p>Degrees of freedom is calculated using Welch’s correction:</p>
<div class="math notranslate nohighlight">
\[\large \frac{\left(\frac{s^2_i}{n_i} +
\frac{s^2_j}{n_j}\right)^2}{\frac{\left(\frac{s_i^2}{n_i}\right)^2}{n_i - 1} +
\frac{\left(\frac{s_j^2}{n_j}\right)^2}{n_j - 1}}\]</div>
<p>Thus, confidence intervals can be formed with:</p>
<div class="math notranslate nohighlight">
\[\bar{x}_i - \bar{x}_j \pm t \sqrt{{\frac{1}{2} \left(\frac{s_i^2}{n_i} + \frac{s_j^2}{n_j}\right)}}\]</div>
<p>p-values are calculated using Tukey’s studentized range:</p>
<div class="math notranslate nohighlight">
\[\large q_{t * \sqrt{2}, k, df}\]</div>
<p>The Games-Howell test and Tukey’s test will often report similar results with data that is assumed to have
equal variance and equal sample sizes.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>Ruxton, G.D., and Beauchamp, G. (2008) ‘Time for some a priori thinking about post hoc testing’,</dt><dd><p>Behavioral Ecology, 19(3), pp. 690-693. doi: 10.1093/beheco/arn020.
In-text citations: (Ruxton and Beauchamp, 2008)</p>
</dd>
</dl>
<p>Post-hoc (no date) Available at: <a class="reference external" href="http://www.unt.edu/rss/class/Jon/ISSS_SC/Module009/isss_m91_onewayanova/node7.html">http://www.unt.edu/rss/class/Jon/ISSS_SC/Module009/isss_m91_onewayanova/node7.html</a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">utilmy.stats.hypothesis.posthoc.</span></span><span class="sig-name descname"><span class="pre">TukeysTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Performs Tukey’s Honestly Significant Difference posthoc analysis test.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>group</strong> (<em>array-like</em><em>, </em><em>optional</em>) – One-dimensional array (Numpy ndarray, Pandas Series, list) that defines the group
membership of the dependent variable(s). Must be the same length as the observation vector.</p></li>
<li><p><strong>group_sample1</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>group_sample2</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>...</strong> (<em>array-like</em>) – Corresponding observation vectors of the group samples. Must be the same length
as the group parameter. If the group parameter is None, each observation vector
will be treated as a group sample vector.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>default 0.05</em>) – Alpha level for computing upper and lower confidence intervals</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.design_matrix">
<span class="sig-name descname"><span class="pre">design_matrix</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.design_matrix" title="Permalink to this definition"></a></dt>
<dd><p>Numpy ndarray representing the data matrix for the analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.group">
<span class="sig-name descname"><span class="pre">group</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.group" title="Permalink to this definition"></a></dt>
<dd><p>Group vector passed or coerced from sample observation vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.alpha" title="Permalink to this definition"></a></dt>
<dd><p>Alpha level for computing upper and lower confidence intervals</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float, default 0.05</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.test_description">
<span class="sig-name descname"><span class="pre">test_description</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.test_description" title="Permalink to this definition"></a></dt>
<dd><p>String denoting the type of procedure performed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str, default ‘Tukey multiple comparison of means’</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.n">
<span class="sig-name descname"><span class="pre">n</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.n" title="Permalink to this definition"></a></dt>
<dd><p>Number of total observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.k">
<span class="sig-name descname"><span class="pre">k</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.k" title="Permalink to this definition"></a></dt>
<dd><p>Number of groups</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.dof">
<span class="sig-name descname"><span class="pre">dof</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.dof" title="Permalink to this definition"></a></dt>
<dd><p>Degrees of freedom</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.tukey_q_value">
<span class="sig-name descname"><span class="pre">tukey_q_value</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.tukey_q_value" title="Permalink to this definition"></a></dt>
<dd><p>The computed q-value used in determining the HSD</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.mse">
<span class="sig-name descname"><span class="pre">mse</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.mse" title="Permalink to this definition"></a></dt>
<dd><p>The mean square error</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.hsd">
<span class="sig-name descname"><span class="pre">hsd</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.hsd" title="Permalink to this definition"></a></dt>
<dd><p>Tukey’s Honestly Significant Difference value</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.group_comparison">
<span class="sig-name descname"><span class="pre">group_comparison</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.group_comparison" title="Permalink to this definition"></a></dt>
<dd><p>pandas DataFrame of group comparison results calculated by Tukey’s HSD test.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>array-like</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="utilmy.stats.hypothesis.posthoc.TukeysTest.test_summary">
<span class="sig-name descname"><span class="pre">test_summary</span></span><a class="headerlink" href="#utilmy.stats.hypothesis.posthoc.TukeysTest.test_summary" title="Permalink to this definition"></a></dt>
<dd><p>Dictionary of test results.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>After a multivariate test, it is often desired to know more about the specific groups to find out if they
are significantly different or similar. This step after analysis is referred to as ‘post-hoc analysis’ and
is a major step in hypothesis testing.</p>
<p>One common and popular method of post-hoc analysis is Tukey’s Test. The test is known by several different names.
Tukey’s test compares the means of all treatments to the mean of every other treatment and is considered the best
available method in cases when confidence intervals are desired or if sample sizes are unequal.</p>
<p>The test statistic used in Tukey’s test is denoted <span class="math notranslate nohighlight">\(q\)</span> and is essentially a modified t-statistic that
corrects for multiple comparisons.</p>
<p><span class="math notranslate nohighlight">\(q\)</span> can be found similarly to the t-statistic:</p>
<div class="math notranslate nohighlight">
\[q_{\alpha,k,N-k}\]</div>
<p>The studentized range distribution of <span class="math notranslate nohighlight">\(q\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[q_s = \frac{Y_{max} - Y_{min}}{SE}\]</div>
<p>Where <span class="math notranslate nohighlight">\(Y_{max}\)</span> and <span class="math notranslate nohighlight">\(Y_{min}\)</span> are the larger and smaller means of the two groups being compared.
<span class="math notranslate nohighlight">\(SE\)</span> is defined as the standard error of the entire design.</p>
<p>The Honestly Significant Difference is defined as the q-value multiplied by the square root of the MSE
divided by the sample size.</p>
<div class="math notranslate nohighlight">
\[HSD = q_{\alpha,k,N-k} \sqrt{\frac{MSE}{n}}\]</div>
<p>If the absolute value of the difference of the two groups’ means is greater than or equal to the HSD,
the difference is significant.</p>
<div class="math notranslate nohighlight">
\[\left|Y_1 - Y_2\right| \geq HSD\]</div>
<p>Intervals for Tukey’s Test can also be estimated. Since the test uses the studentized range, estimation is
similar to the t-test setting. Intervals with <span class="math notranslate nohighlight">\(1 - \alpha\)</span> confidence can be found using the
Tukey-Kramer method. The Tukey-Kramer method allows for unequal sample sizes between the treatments and is,
therefore, more often applicable. The Tukey-Kramer method is defined as:</p>
<div class="math notranslate nohighlight">
\[y_i - y_j \pm q_{\alpha,k,N-k} \sqrt{\left(\frac{MSE}{2}\right) \left(\frac{1}{n_i} + \frac{1}{n_j}\right)}\]</div>
<p class="rubric">Examples</p>
<p class="rubric">References</p>
</dd></dl>

</section>
</section>
<section id="module-utilmy.stats.hypothesis">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-utilmy.stats.hypothesis" title="Permalink to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="utilmy.stats.html" class="btn btn-neutral float-left" title="utilmy.stats package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="utilmy.stats.hypothesis.tests.html" class="btn btn-neutral float-right" title="utilmy.stats.hypothesis.tests package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: zdocs_y23487teg65f6
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      
      <dl>
        <dt>Languages</dt>
        
           <strong> 
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/">en</a></dd>
           </strong> 
        
          
          <dd><a href="/myutil/es/zdocs_y23487teg65f6/">es</a></dd>
          
        
      </dl>
      
      
      <dl>
        <dt>Versions</dt>
        
           <strong> 
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/">zdocs_y23487teg65f6</a></dd>
           </strong> 
        
      </dl>
      
      
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/utilmy-docs_en_zdocs_y23487teg65f6.pdf">pdf</a></dd>
        
          <dd><a href="/myutil/en/zdocs_y23487teg65f6/utilmy-docs_en_zdocs_y23487teg65f6.epub">epub</a></dd>
        
      </dl>
      
      
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.
 
    </div>
  </div>

 <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-XXXXXXXXXX', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>
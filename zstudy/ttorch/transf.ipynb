{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd45d02-5e86-44ce-98f2-e9f318e3d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai.callback.hook import Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec60272-5557-4ab2-9e66-9edc0cf24e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len, d_in = 5, 10, 32\n",
    "x = torch.randn(bs, seq_len, d_in)\n",
    "d_h = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9befa683-4872-4b43-958c-e519f3b7a21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_proj_weight torch.Size([96, 32])\n",
      "out_proj.weight torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "attn = nn.MultiheadAttention(d_h, 4, bias=False, batch_first=True)\n",
    "\n",
    "for n, p in attn.named_parameters():\n",
    "    print(f\"{n:<12} {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5b0bd32-2be7-47dd-a79c-2296109e65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, attn_weights = attn(x, x, x, average_attn_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3e536f7-b6a2-4448-9c2b-20b4ee4ce1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10, 32]), torch.Size([5, 4, 10, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "906bb9e1-c522-4226-8098-fac874a5ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.TransformerEncoderLayer(d_h, 4, 128, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09b1afb2-2771-4d81-acd0-8bfeead06654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn.in_proj_weight     torch.Size([96, 32])\n",
      "self_attn.in_proj_bias       torch.Size([96])\n",
      "self_attn.out_proj.weight    torch.Size([32, 32])\n",
      "self_attn.out_proj.bias      torch.Size([32])\n",
      "linear1.weight               torch.Size([128, 32])\n",
      "linear1.bias                 torch.Size([128])\n",
      "linear2.weight               torch.Size([32, 128])\n",
      "linear2.bias                 torch.Size([32])\n",
      "norm1.weight                 torch.Size([32])\n",
      "norm1.bias                   torch.Size([32])\n",
      "norm2.weight                 torch.Size([32])\n",
      "norm2.bias                   torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for n, p in enc.named_parameters():\n",
    "    print(f\"{n:<28} {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb02d1e5-d714-45a9-a6b1-515653f238ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "out = enc(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7a3f445-ae78-496e-87e2-49947bdb7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn.in_proj_weight         torch.Size([96, 32])\n",
      "self_attn.in_proj_bias           torch.Size([96])\n",
      "self_attn.out_proj.weight        torch.Size([32, 32])\n",
      "self_attn.out_proj.bias          torch.Size([32])\n",
      "multihead_attn.in_proj_weight    torch.Size([96, 32])\n",
      "multihead_attn.in_proj_bias      torch.Size([96])\n",
      "multihead_attn.out_proj.weight   torch.Size([32, 32])\n",
      "multihead_attn.out_proj.bias     torch.Size([32])\n",
      "linear1.weight                   torch.Size([2048, 32])\n",
      "linear1.bias                     torch.Size([2048])\n",
      "linear2.weight                   torch.Size([32, 2048])\n",
      "linear2.bias                     torch.Size([32])\n",
      "norm1.weight                     torch.Size([32])\n",
      "norm1.bias                       torch.Size([32])\n",
      "norm2.weight                     torch.Size([32])\n",
      "norm2.bias                       torch.Size([32])\n",
      "norm3.weight                     torch.Size([32])\n",
      "norm3.bias                       torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dec = nn.TransformerDecoderLayer(d_h, 4, batch_first=True)\n",
    "for n, p in dec.named_parameters():\n",
    "    print(f\"{n:<32} {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689c01f9-5caf-48d5-a4ef-d16ffb162515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (multihead_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  (dropout3): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89dfb6b9-8e91-42a9-ae12-0b1caeadf6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(bs, seq_len-1, d_h)\n",
    "out = dec(x, y)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30782738-bc12-485f-b458-1c84c23af34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(d_h, 4, batch_first=True),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fca618bb-f3cf-4f7a-9e4f-64edbc41e491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "out = enc(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9472c564-3a2f-47cc-a17f-4a384c33fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "      (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "      (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7907ce3-8b78-400d-995f-e750ed0a6aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv] *",
   "language": "python",
   "name": "conda-env-torchenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}